{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.kl import kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first download the Penn Treebank dataset that we will be using for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data files...\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jhcross/span-parser/master/data/\"\n",
    "train_file = \"02-21.10way.clean\"\n",
    "val_file = \"22.auto.clean\"\n",
    "test_file = \"23.auto.clean\"\n",
    "\n",
    "print(\"Downloading data files...\")\n",
    "if not os.path.isfile(train_file):\n",
    "    urllib.request.urlretrieve(url + train_file, filename=train_file)\n",
    "if not os.path.isfile(val_file):\n",
    "    urllib.request.urlretrieve(url + val_file, filename=val_file)\n",
    "if not os.path.isfile(test_file):\n",
    "    urllib.request.urlretrieve(url + test_file, filename=test_file)\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "In order to work with text data, we need to transform the text into something that our algorithms can work with. The first step of this process is converting words into word ids. We do this by constructing a vocabulary from the data, assigning a new word id to each new word it encounters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing vocabulary...\n",
      "Constructed a vocabulary of 45233 word types\n"
     ]
    }
   ],
   "source": [
    "UNK_TOKEN = \"<unk>\"\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "SOS_TOKEN = \"<s>\"\n",
    "EOS_TOKEN = \"</s>\"\n",
    "\n",
    "\"\"\"\n",
    "    Removes the parse trees in the PTB dataset.\n",
    "\"\"\"\n",
    "def tokens_from_treestring(s):\n",
    "    return \" \".join(re.findall(r\"\\([A-Z]* ([^\\(\\)]+)\\)\", s))\n",
    "\n",
    "class Vocabulary:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.idx_to_word = {0: UNK_TOKEN, 1: PAD_TOKEN, 2: SOS_TOKEN, 3: EOS_TOKEN}\n",
    "        self.word_to_idx = {UNK_TOKEN: 0, PAD_TOKEN: 1, SOS_TOKEN: 2, EOS_TOKEN: 3}\n",
    "        self.word_freqs = {}\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.word_to_idx[key] if key in self.word_to_idx else self.word_to_idx[UNK_TOKEN]\n",
    "    \n",
    "    def word(self, idx):\n",
    "        return self.idx_to_word[idx]\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.word_to_idx)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_data(filenames):\n",
    "        \"\"\"\n",
    "            Creates a vocabulary from a list of data files. It assumes that the data files have been\n",
    "            tokenized and pre-processed beforehand.\n",
    "        \"\"\"\n",
    "        vocab = Vocabulary()\n",
    "        for filename in filenames:\n",
    "            with open(filename) as f:\n",
    "                for line in f:\n",
    "                    \n",
    "                    # Strip whitespace and the newline symbol.\n",
    "                    line = tokens_from_treestring(line.strip())\n",
    "                    \n",
    "                    # Split the sentences into words and assign word ids to each\n",
    "                    # new word it encounters.\n",
    "                    for word in line.split():\n",
    "                        if word not in vocab.word_to_idx:\n",
    "                            idx = len(vocab.word_to_idx)\n",
    "                            vocab.word_to_idx[word] = idx\n",
    "                            vocab.idx_to_word[idx] = word\n",
    "                            \n",
    "        return vocab\n",
    "\n",
    "# Construct a vocabulary from the training and validation data.\n",
    "print(\"Constructing vocabulary...\")\n",
    "vocab = Vocabulary.from_data([train_file, val_file])\n",
    "print(\"Constructed a vocabulary of %d word types\" % vocab.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to load the data files into memory. We create a simple class `TextDataset` that stores the data as a list of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from training data: \"Nothing less it seemed could console them for traumas\"\n",
      "Sample from validation data: \"The bill is aimed at addressing the concern that an airline might sacrifice costly safety measures to pay off the debt incurred in a leveraged buy-out\"\n",
      "Sample from test data: \"But these are not the differences that make headlines\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    A simple class that loads a list of sentences into memory from a text file,\n",
    "    split by newlines.\n",
    "\"\"\"\n",
    "class TextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, text_file):\n",
    "        self.data = []\n",
    "        with open(text_file) as f:\n",
    "            for line in f:\n",
    "                self.data.append(tokens_from_treestring(line.strip()))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Load the training, validation, and test datasets into memory.\n",
    "train_dataset = TextDataset(train_file)\n",
    "val_dataset = TextDataset(val_file)\n",
    "test_dataset = TextDataset(test_file)\n",
    "\n",
    "# Print some samples from the data:\n",
    "print(\"Sample from training data: \\\"%s\\\"\" % train_dataset[np.random.choice(len(train_dataset))])\n",
    "print(\"Sample from validation data: \\\"%s\\\"\" % val_dataset[np.random.choice(len(val_dataset))])\n",
    "print(\"Sample from test data: \\\"%s\\\"\" % test_dataset[np.random.choice(len(test_dataset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to write a function that converts a sentence into a list of word ids using the vocabulary we created before. This function is `create_batch` in the code cell below. This function creates a batch from a list of sentences, and makes sure that each sentence starts with a start-of-sentence symbol and ends with an end-of-sentence symbol. Because not all sentences are of equal length in a certain batch, sentences are padded with padding symbols so that they match the length of the largest sentence in the batch. The function returns an input batch, an output batch, a mask of 1s for words and 0s for padding symbols, and the sequence lengths of each sentence in the batch. The output batch is shifted by one word, to reflect the predictions that the model is expected to make. For example, when an input sentence looks like this:\n",
    "\n",
    "Input sentence: SOS The dog runs .\n",
    "\n",
    "the output sentence will look like this:\n",
    "\n",
    "Output sentence: The dog runs . EOS\n",
    "\n",
    "Lastly, we create an inverse function `batch_to_sentences` that recovers the list of sentences from a padded batch of word ids to use during test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Converts a list of sentences to a padded batch of word ids. Returns\n",
    "    an input batch, an output batch shifted by one, a sequence mask over\n",
    "    the input batch, and a tensor containing the sequence length of each\n",
    "    batch element.\n",
    "\"\"\"\n",
    "def create_batch(sentences, vocab, device, word_dropout=0.):\n",
    "    tok = np.array([[SOS_TOKEN] + sen.split() + [EOS_TOKEN] for sen in sentences])\n",
    "    seq_lengths = [len(sen)-1 for sen in tok]\n",
    "    max_len = max(seq_lengths)\n",
    "    pad_id = vocab[PAD_TOKEN]\n",
    "    pad_id_input = [\n",
    "        [vocab[sen[t]] if t < seq_lengths[idx] else pad_id for t in range(max_len)]\n",
    "            for idx, sen in enumerate(tok)]\n",
    "    \n",
    "    # Replace words of the input with <unk> with p = word_dropout.\n",
    "    if word_dropout > 0.:\n",
    "        unk_id = vocab[UNK_TOKEN]\n",
    "        word_drop =  [\n",
    "            [unk_id if (np.random.random() < word_dropout and t < seq_lengths[idx]) else word_ids[t] for t in range(max_len)] \n",
    "                for idx, word_ids in enumerate(pad_id_input)]\n",
    "    \n",
    "    # The output batch is shifted by 1.\n",
    "    pad_id_output = [\n",
    "        [vocab[sen[t+1]] if t < seq_lengths[idx] else pad_id for t in range(max_len)]\n",
    "            for idx, sen in enumerate(tok)]\n",
    "    \n",
    "    # Convert everything to PyTorch tensors.\n",
    "    batch_input = torch.tensor(pad_id_input)\n",
    "    batch_output = torch.tensor(pad_id_output)\n",
    "    seq_mask = (batch_input != vocab[PAD_TOKEN])\n",
    "    seq_length = torch.tensor(seq_lengths)\n",
    "    \n",
    "    # Move all tensors to the given device.\n",
    "    batch_input = batch_input.to(device)\n",
    "    batch_output = batch_output.to(device)\n",
    "    seq_mask = seq_mask.to(device)\n",
    "    seq_length = seq_length.to(device)\n",
    "    \n",
    "    return batch_input, batch_output, seq_mask, seq_length\n",
    "\n",
    "\"\"\"\n",
    "    Converts a batch of word ids back to sentences.\n",
    "\"\"\"\n",
    "def batch_to_sentences(tensors, vocab):\n",
    "    sentences = []\n",
    "    batch_size = tensors.size(0)\n",
    "    for idx in range(batch_size):\n",
    "        sentence = [vocab.word(t.item()) for t in tensors[idx,:]]\n",
    "        \n",
    "        # Filter out the start-of-sentence and padding tokens.\n",
    "        sentence = list(filter(lambda t: t != PAD_TOKEN and t != SOS_TOKEN, sentence))\n",
    "        \n",
    "        # Remove the end-of-sentence token and all tokens following it.\n",
    "        if EOS_TOKEN in sentence:\n",
    "            sentence = sentence[:sentence.index(EOS_TOKEN)]\n",
    "            \n",
    "        sentences.append(\" \".join(sentence))\n",
    "    return np.array(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch the RNN functions expect inputs to be sorted from long sentences to shorter ones. Therefore we create a simple wrapper class for the DataLoader class that sorts sentences from long to short:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    A wrapper for the DataLoader class that sorts a list of sentences by their\n",
    "    lengths in descending order.\n",
    "\"\"\"\n",
    "class SortingTextDataLoader:\n",
    "\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        self.it = iter(dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        sentences = None\n",
    "        for s in self.it:\n",
    "            sentences = s\n",
    "            break\n",
    "\n",
    "        if sentences is None:\n",
    "            self.it = iter(self.dataloader)\n",
    "            raise StopIteration\n",
    "        \n",
    "        sentences = np.array(sentences)\n",
    "        sort_keys = sorted(range(len(sentences)), \n",
    "                           key=lambda idx: len(sentences[idx].split()), \n",
    "                           reverse=True)\n",
    "        sorted_sentences = sentences[sort_keys]\n",
    "        return sorted_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "\\begin{align}\n",
    "    \\log P(x) &= \\log \\int P(x) p(z) dz \\geq\\\\\n",
    "    &\\geq \\mathbb{E}_{q(z|x)}\\left[\\frac{P(x|z)p(z)}{q(z|x)}\\right]\\\\\n",
    "    &= \\mathbb{E}_{q(z|x)}\\left[P(x|z)\\right] - \\text{KL}\\left(q(z|x)||p(z)\\right)\\\\\n",
    "\\end{align}\n",
    "\n",
    "Let's start with the inference model. The inference model infers a diagonal Gaussian distribution from $x$ with scale $\\mu(x)$ and standard deviation $\\sigma(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedder, hidden_size,\n",
    "                 latent_size, pad_idx, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # We borrow the embedder from the generative model, but we don't\n",
    "        # want tobackpropagate through it for the inference model. So we\n",
    "        # need to make sure to call detach on the embeddings later.\n",
    "        self.embedder = embedder\n",
    "        \n",
    "        # Create a (bidirectional) LSTM to encode x.\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, batch_first=True, \n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        # The output of the LSTM doubles if we use a bidirectional encoder.\n",
    "        encoding_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        \n",
    "        # Create two affine layers to project the encoder final state to\n",
    "        # the mean and standard deviation of the diagonal Gaussian that\n",
    "        # we are predicting.\n",
    "        self.mu_layer = nn.Linear(encoding_size, latent_size)\n",
    "        self.sigma_layer = nn.Linear(encoding_size, latent_size)\n",
    "\n",
    "    def forward(self, x, seq_mask, seq_len):\n",
    "        \n",
    "        # Compute word embeddings and detach them so that no gradients\n",
    "        # from the infererence model flow through.\n",
    "        x_embed = self.embedder(x).detach()\n",
    "        \n",
    "        # Encode the sentence using the LSTM.\n",
    "        hidden = None        \n",
    "        packed_seq = pack_padded_sequence(x_embed, seq_len, batch_first=True)\n",
    "        _, final = self.lstm(packed_seq, hidden)        \n",
    "\n",
    "        # Take the final output h_T from the LSTM, concatenate the forward\n",
    "        # and backward directions for the bidirectional case.\n",
    "        h_T = final[0]\n",
    "        if self.bidirectional:\n",
    "            h_T_fwd = h_T[0]\n",
    "            h_T_bwd = h_T[1]\n",
    "            h_T = torch.cat([h_T_fwd, h_T_bwd], dim=-1)\n",
    "        \n",
    "        # Compute the mean and sigma of the diagonal Gaussian distribution.\n",
    "        # Use a softplus activation for the standard deviation to ensure it's\n",
    "        # positive.\n",
    "        mu = self.mu_layer(h_T)\n",
    "        sigma = F.softplus(self.sigma_layer(h_T))\n",
    "        \n",
    "        # Return the inferred Gaussian distribution q(z|x).\n",
    "        qz = Normal(mu, sigma)\n",
    "        return qz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the generative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BowmanLM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, latent_size,\n",
    "                 pad_idx, dropout=0., bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embedder = nn.Embedding(vocab_size, emb_size,\n",
    "                                     padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
    "        self.bridge = nn.Linear(latent_size, hidden_size)\n",
    "        self.projection = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.inference_model = InferenceModel(vocab_size, self.embedder,\n",
    "                                              hidden_size, latent_size, pad_idx, \n",
    "                                              bidirectional=bidirectional)\n",
    "    \n",
    "    \"\"\"\n",
    "        Infers the approximate posterior q(z|x) for a given x.\n",
    "    \"\"\"\n",
    "    def infer(self, x, seq_mask, seq_len):\n",
    "        qz = self.inference_model(x, seq_mask, seq_len)\n",
    "        return qz\n",
    "\n",
    "    \"\"\"\n",
    "        Returns the hidden state of the LSTM initialized with a projection of a given z.\n",
    "    \"\"\"\n",
    "    def init_hidden(self, z):\n",
    "        h = self.bridge(z).unsqueeze(0)\n",
    "        c = self.bridge(z).unsqueeze(0)\n",
    "        return (h, c)\n",
    "\n",
    "    \"\"\"\n",
    "        Performs a single LSTM step for a given previous word and hidden state.\n",
    "        Returns the unnormalized probabilities over the vocabulary for this time step. \n",
    "    \"\"\"\n",
    "    def step(self, prev_x, z, hidden):\n",
    "        x_embed = self.dropout_layer(self.embedder(prev_x))\n",
    "        output, hidden = self.lstm(x_embed, hidden)\n",
    "        scores = self.projection(self.dropout_layer(output))\n",
    "        return scores, hidden\n",
    "    \n",
    "    \"\"\"\n",
    "        Performs an entire forward pass given a sequence of words x and a z.\n",
    "    \"\"\"\n",
    "    def forward(self, x, z):\n",
    "        hidden = self.init_hidden(z)\n",
    "        outputs = []\n",
    "        for t in range(x.size(1)):\n",
    "            prev_x = x[:, t].unsqueeze(-1)\n",
    "            scores, hidden = self.step(prev_x, z, hidden)\n",
    "            outputs.append(scores)\n",
    "        return torch.cat(outputs, dim=1)\n",
    "        \n",
    "    \"\"\"\n",
    "        Computes the loss given the scores (unnormalized probabilities), targets,\n",
    "        the prior distribution p(z), and the approximate posterior distribution q(z|x).\n",
    "        If free_nats is nonzero it will clamp the KL divergence between the posterior\n",
    "        and prior to that value, preventing gradient propagation via the KL if it's\n",
    "        below that value. If evaluation is set to true, the loss will be summed instead\n",
    "        of averaged over the batch. Returns the reconstruction loss and the KL. The loss\n",
    "        can be computed from those as loss = rec_loss - KL.\n",
    "    \"\"\"\n",
    "    def loss(self, scores, targets, pz, qz, free_nats=0., evaluation=False):\n",
    "        \n",
    "        # Approximate E[log P(x|z)].\n",
    "        scores = scores.permute(0, 2, 1)\n",
    "        reconstruction_loss = F.cross_entropy(scores, targets, \n",
    "                                              ignore_index=self.pad_idx, \n",
    "                                              reduction=\"none\")\n",
    "        reconstruction_loss = reconstruction_loss.sum(dim=1)\n",
    "        \n",
    "        # Compute the KL divergence and clamp to at least the given amount of free nats.\n",
    "        KL = kl_divergence(qz, pz).sum(dim=1)\n",
    "        KL = torch.clamp(KL, min=free_nats)\n",
    "        \n",
    "        # For evaluation return the sum of individual components, for\n",
    "        # training return the mean of those components.\n",
    "        if evaluation:\n",
    "            return (reconstruction_loss.sum(), KL.sum())\n",
    "        else:\n",
    "            return (reconstruction_loss.mean(), KL.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics\n",
    "\n",
    "During training we'd like to keep track of some evaluation metrics on the validation data in order to keep track of how our model is doing and to perform early stopping. One simple metric we can compute is the ELBO on all the validation or test data using a single sample from the approximate posterior $q(z|x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Computes a single sample estimate of the ELBO on a given dataset.\n",
    "\"\"\"\n",
    "def eval_elbo(model, eval_dataset, vocab, device, batch_size=128):\n",
    "    dl = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "    sorted_dl = SortingTextDataLoader(dl)\n",
    "    \n",
    "    # Make sure the model is in evaluation mode (i.e. disable dropout).\n",
    "    model.eval()\n",
    "            \n",
    "    total_rec_loss = 0.\n",
    "    total_KL = 0.\n",
    "    num_sentences = 0\n",
    "        \n",
    "    # We don't need to compute gradients for this.\n",
    "    with torch.no_grad():\n",
    "        for sentences in sorted_dl:    \n",
    "            x_in, x_out, seq_mask, seq_len = create_batch(sentences, vocab, device)\n",
    "            \n",
    "            # Infer the approximate posterior and construct the prior.\n",
    "            qz = model.infer(x_in, seq_mask, seq_len)\n",
    "            pz = Normal(torch.zeros_like(qz.mean), \n",
    "                        torch.ones_like(qz.stddev))\n",
    "            \n",
    "            # Compute the unnormalized probabilities using a single sample from the\n",
    "            # approximate posterior.\n",
    "            z = qz.sample()\n",
    "            scores = model(x_in, z)\n",
    "            \n",
    "            # Compute the reconstruction loss and KL divergence.\n",
    "            reconstruction_loss, KL = model.loss(scores, x_out, pz, qz,\n",
    "                                                 free_nats=0.,\n",
    "                                                 evaluation=True)\n",
    "            total_rec_loss += reconstruction_loss\n",
    "            total_KL += KL\n",
    "            num_sentences += x_in.size(0)\n",
    "\n",
    "    # Return the average reconstruction loss and KL.\n",
    "    avg_rec_loss = total_rec_loss / num_sentences\n",
    "    avg_KL = total_KL / num_sentences\n",
    "    return avg_rec_loss, avg_KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common metric to evaluate language models is the perplexity per word. The perplexity per word for a dataset is defined as:\n",
    "\n",
    "\\begin{align}\n",
    "    \\text{ppl}(\\mathcal{D}) = \\exp\\left(-\\frac{1}{\\sum_{k=1}^{|\\mathcal D|} n^{(k)}} \\sum_{k=1}^{|\\mathcal{D}|} \\log P(x^{(k)})\\right) \n",
    "\\end{align}\n",
    "\n",
    "where $n^{(k)}$ is the number of tokens in a sentence and $P(x^{(k)})$ is the probability that our model assigns to the datapoint $x^{(k)}$. In order to compute $\\log P(x)$ for our model we need to solve for the integral:\n",
    "\n",
    "\\begin{align}\n",
    "    P(x) = \\int P(x|z) p(z) dz\n",
    "\\end{align}\n",
    "\n",
    "As this is an integral we cannot compute in closed-form, we have two options: we can use the earlier derived lower-bound on the log-likelihood, which will give us an upper-bound on the perplexity, or we can make an importance sampling estimate using our approximate posterior distribution. The importance sampling estimate can be done as:\n",
    "\n",
    "\\begin{align}\n",
    "    &\\frac{1}{\\sum_{k=1}^{|\\mathcal D|} n^{(k)}}  \\sum_{k=1}^{|\\mathcal D|} \\log p(x^{(k)}) \\\\\n",
    "    &\\approx \\frac{1}{\\sum_{k=1}^{|\\mathcal D|} n^{(k)}}  \\sum_{k=1}^{|\\mathcal D|} \\log \\frac{1}{S} \\sum_{s=1}^{S} \\frac{p(z^{(s)})p(x^{(k)}|z^{(s)})}{q(z^{(s)}|x^{(k)})} \\\\\n",
    "\\end{align}\n",
    "\n",
    "where $S$ is the number of samples, and $z^{(s)} \\sim q(z|x^{k})$. We define the function `eval_perplexity` below that implements this importance sampling estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Estimates the per-word perplexity using importance sampling with the\n",
    "    given number of samples.\n",
    "\"\"\"\n",
    "def eval_perplexity(model, eval_dataset, vocab, device, \n",
    "                    n_samples, batch_size=128):\n",
    "    \n",
    "    dl = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "    sorted_dl = SortingTextDataLoader(dl)\n",
    "    \n",
    "    # Make sure the model is in evaluation mode (i.e. disable dropout).\n",
    "    model.eval()\n",
    "    \n",
    "    log_px = 0.\n",
    "    num_predictions = 0\n",
    "    num_sentences = 0\n",
    "     \n",
    "    # We don't need to compute gradients for this.\n",
    "    with torch.no_grad():\n",
    "        for sentences in sorted_dl:\n",
    "            x_in, x_out, seq_mask, seq_len = create_batch(sentences, vocab, device)\n",
    "            \n",
    "            # Infer the approximate posterior and construct the prior.\n",
    "            qz = model.infer(x_in, seq_mask, seq_len)\n",
    "            pz = Normal(torch.zeros_like(qz.mean), \n",
    "                        torch.ones_like(qz.stddev))\n",
    "\n",
    "            # Create an array to hold all samples for this batch.\n",
    "            batch_size = x_in.size(0)\n",
    "            log_px_samples = torch.zeros(n_samples, batch_size)\n",
    "            \n",
    "            # Sample log P(x) n_samples times.\n",
    "            for s in range(n_samples):\n",
    "                \n",
    "                # Sample a z^s from the posterior.\n",
    "                z = qz.sample()\n",
    "                \n",
    "                # Compute log P(x^k|z^s)\n",
    "                scores = model(x_in, z)\n",
    "                cond_log_prob = F.log_softmax(scores, dim=-1)\n",
    "                cond_log_prob = torch.gather(cond_log_prob, 2, x_out.unsqueeze(-1)).squeeze() # B x T\n",
    "                cond_log_prob = (cond_log_prob * seq_mask.type_as(cond_log_prob)).sum(dim=1) # B\n",
    "                \n",
    "                # Compute log p(z^s) and log q(z^s|x^k)\n",
    "                prior_log_prob = pz.log_prob(z).sum(dim=1) # B\n",
    "                posterior_log_prob = qz.log_prob(z).sum(dim=1) # B\n",
    "                \n",
    "                # Store the sample for log P(x^k) importance weighted with p(z^s)/q(z^s|x^k).\n",
    "                log_px_sample = cond_log_prob + prior_log_prob - posterior_log_prob\n",
    "                log_px_samples[s] = log_px_sample\n",
    "                \n",
    "            # Average over the number of samples and count the number of predictions made this batch.\n",
    "            log_px_batch = torch.logsumexp(log_px_samples, dim=0) - \\\n",
    "                    torch.log(torch.Tensor([n_samples]))\n",
    "            log_px += log_px_batch.sum()\n",
    "            num_predictions += seq_len.sum()\n",
    "            num_sentences += seq_len.size(0)\n",
    "\n",
    "    # Compute and return the perplexity per word.\n",
    "    perplexity = torch.exp(-log_px / num_predictions)\n",
    "    NLL = -log_px / num_sentences\n",
    "    return perplexity, NLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to occasionally qualitatively see the performance of the model during training, by letting it reconstruct a given sentence from the latent space. This gives us an idea of whether the model is using the latent space to encode some semantics about the data. For this we use a deterministic greedy decoding algorithm, that chooses the word with maximum probability at every time step, and feeds that word into the next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Greedily decodes a sentence from a given z, by picking the word with\n",
    "    maximum probability at each time step.\n",
    "\"\"\"\n",
    "def greedy_decode(model, z, vocab, max_len=50):\n",
    "    \n",
    "    # Disable dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    # Don't compute gradients.\n",
    "    with torch.no_grad():\n",
    "        batch_size = z.size(0)\n",
    "        \n",
    "        # We feed the model the start-of-sentence symbol at the first time step.\n",
    "        prev_x = torch.ones(batch_size, 1, dtype=torch.long).fill_(vocab[SOS_TOKEN]).to(z.device)\n",
    "        \n",
    "        # Initialize the hidden state from z.\n",
    "        hidden = model.init_hidden(z)\n",
    "\n",
    "        predictions = []    \n",
    "        for t in range(max_len):\n",
    "            scores, hidden = model.step(prev_x, z, hidden)\n",
    "            \n",
    "            # Choose the argmax of the unnnormalized probabilities as the\n",
    "            # prediction for this time step.\n",
    "            prediction = torch.argmax(scores, dim=-1)\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "            prev_x = prediction.view(batch_size, 1)\n",
    "            \n",
    "        return torch.cat(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Now it's time to train the model. We use early stopping on the validation perplexity for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) step 0: training ELBO (KL) = -224.14 (5.00) -- KL weight = 0.00 -- validation ELBO (KL) = -227.96 (1.70)\n",
      "(1) step 100: training ELBO (KL) = -114.16 (64.58) -- KL weight = 0.01 -- validation ELBO (KL) = -142.30 (13.61)\n",
      "(1) step 200: training ELBO (KL) = -148.93 (11.47) -- KL weight = 0.02 -- validation ELBO (KL) = -142.54 (9.79)\n",
      "(1) step 300: training ELBO (KL) = -146.06 (9.55) -- KL weight = 0.03 -- validation ELBO (KL) = -139.53 (9.81)\n",
      "(1) step 400: training ELBO (KL) = -144.81 (10.23) -- KL weight = 0.04 -- validation ELBO (KL) = -136.62 (10.14)\n",
      "(1) step 500: training ELBO (KL) = -140.78 (10.70) -- KL weight = 0.04 -- validation ELBO (KL) = -134.34 (10.48)\n",
      "(1) step 600: training ELBO (KL) = -140.07 (11.08) -- KL weight = 0.05 -- validation ELBO (KL) = -132.61 (10.40)\n",
      "Finished epoch 1\n",
      "Evaluation epoch 1:\n",
      " - validation perplexity: 1177.80\n",
      " - validation NLL: 151.54\n",
      " - validation ELBO (KL) = -132.32 (10.42)\n",
      "-- Original sentence: \"This initiative is being labeled The Big Green but maybe it should be called The Big Greenback\"\n",
      "-- Model reconstruction: \"In the company 's the company 's the company 's the company 's the company 's the company 's the company 's\"\n",
      "(2) step 700: training ELBO (KL) = -135.53 (11.02) -- KL weight = 0.06 -- validation ELBO (KL) = -130.77 (10.65)\n",
      "(2) step 800: training ELBO (KL) = -136.17 (10.87) -- KL weight = 0.07 -- validation ELBO (KL) = -129.44 (10.75)\n",
      "(2) step 900: training ELBO (KL) = -136.09 (10.49) -- KL weight = 0.08 -- validation ELBO (KL) = -128.95 (10.25)\n",
      "(2) step 1000: training ELBO (KL) = -134.20 (10.41) -- KL weight = 0.09 -- validation ELBO (KL) = -128.21 (10.07)\n",
      "(2) step 1100: training ELBO (KL) = -134.44 (10.29) -- KL weight = 0.10 -- validation ELBO (KL) = -127.05 (10.29)\n",
      "(2) step 1200: training ELBO (KL) = -133.62 (9.99) -- KL weight = 0.11 -- validation ELBO (KL) = -127.09 (9.50)\n",
      "Finished epoch 2\n",
      "Evaluation epoch 2:\n",
      " - validation perplexity: 845.85\n",
      " - validation NLL: 144.45\n",
      " - validation ELBO (KL) = -126.14 (9.86)\n",
      "-- Original sentence: \"If more information is needed the secretary would have authority to extend the review period 20 days\"\n",
      "-- Model reconstruction: \"If the company 's the company 's the company 's the company 's the company 's the company 's\"\n",
      "(3) step 1300: training ELBO (KL) = -130.60 (9.90) -- KL weight = 0.11 -- validation ELBO (KL) = -125.26 (10.20)\n",
      "(3) step 1400: training ELBO (KL) = -129.44 (9.92) -- KL weight = 0.12 -- validation ELBO (KL) = -125.16 (9.74)\n",
      "(3) step 1500: training ELBO (KL) = -131.73 (9.79) -- KL weight = 0.13 -- validation ELBO (KL) = -124.63 (9.59)\n",
      "(3) step 1600: training ELBO (KL) = -129.40 (9.65) -- KL weight = 0.14 -- validation ELBO (KL) = -124.01 (9.56)\n",
      "(3) step 1700: training ELBO (KL) = -130.23 (9.91) -- KL weight = 0.15 -- validation ELBO (KL) = -122.43 (10.22)\n",
      "(3) step 1800: training ELBO (KL) = -131.23 (9.69) -- KL weight = 0.16 -- validation ELBO (KL) = -122.76 (9.56)\n",
      "Finished epoch 3\n",
      "Evaluation epoch 3:\n",
      " - validation perplexity: 690.75\n",
      " - validation NLL: 140.10\n",
      " - validation ELBO (KL) = -122.33 (9.56)\n",
      "-- Original sentence: \"The Business Men 's Assurance unit represented about 288 million of the company 's 488 million in 1988 revenue and the unit 's operating income was about 10 million said the spokesman\"\n",
      "-- Model reconstruction: \"The company said it was a share in the company 's largest of the company 's largest of the company 's largest of the company 's largest\"\n",
      "(4) step 1900: training ELBO (KL) = -127.60 (9.80) -- KL weight = 0.17 -- validation ELBO (KL) = -122.31 (9.46)\n",
      "(4) step 2000: training ELBO (KL) = -126.91 (9.71) -- KL weight = 0.18 -- validation ELBO (KL) = -121.81 (9.60)\n",
      "(4) step 2100: training ELBO (KL) = -126.30 (9.84) -- KL weight = 0.18 -- validation ELBO (KL) = -120.51 (10.03)\n",
      "(4) step 2200: training ELBO (KL) = -126.44 (9.50) -- KL weight = 0.19 -- validation ELBO (KL) = -120.51 (9.65)\n",
      "(4) step 2300: training ELBO (KL) = -126.69 (9.50) -- KL weight = 0.20 -- validation ELBO (KL) = -120.98 (9.40)\n",
      "(4) step 2400: training ELBO (KL) = -126.07 (9.53) -- KL weight = 0.21 -- validation ELBO (KL) = -119.93 (9.44)\n",
      "Finished epoch 4\n",
      "Evaluation epoch 4:\n",
      " - validation perplexity: 600.02\n",
      " - validation NLL: 137.09\n",
      " - validation ELBO (KL) = -119.32 (9.50)\n",
      "-- Original sentence: \"It was assigned a mark of 80 out of a possible 100 compared with scores ranging as low as 69 for the other components\"\n",
      "-- Model reconstruction: \"It is n't a lot of the U.S. of the U.S. and the company 's largest of the U.S. and the company 's largest market\"\n",
      "(5) step 2500: training ELBO (KL) = -125.53 (9.30) -- KL weight = 0.22 -- validation ELBO (KL) = -119.29 (9.65)\n",
      "(5) step 2600: training ELBO (KL) = -124.44 (9.34) -- KL weight = 0.23 -- validation ELBO (KL) = -119.09 (9.46)\n",
      "(5) step 2700: training ELBO (KL) = -123.93 (9.25) -- KL weight = 0.24 -- validation ELBO (KL) = -119.13 (9.20)\n",
      "(5) step 2800: training ELBO (KL) = -125.25 (9.24) -- KL weight = 0.25 -- validation ELBO (KL) = -118.67 (9.16)\n",
      "(5) step 2900: training ELBO (KL) = -123.62 (9.19) -- KL weight = 0.25 -- validation ELBO (KL) = -118.42 (9.21)\n",
      "(5) step 3000: training ELBO (KL) = -122.14 (9.13) -- KL weight = 0.26 -- validation ELBO (KL) = -117.89 (9.23)\n",
      "(5) step 3100: training ELBO (KL) = -123.44 (9.10) -- KL weight = 0.27 -- validation ELBO (KL) = -118.59 (8.86)\n",
      "Finished epoch 5\n",
      "Evaluation epoch 5:\n",
      " - validation perplexity: 544.88\n",
      " - validation NLL: 135.02\n",
      " - validation ELBO (KL) = -117.92 (9.12)\n",
      "-- Original sentence: \"The offer which also includes common and preferred stock purchase rights was to expire last night at midnight\"\n",
      "-- Model reconstruction: \"The company said it expects to be a share in the first quarter of the company 's largest company\"\n",
      "(6) step 3200: training ELBO (KL) = -122.29 (9.00) -- KL weight = 0.28 -- validation ELBO (KL) = -117.51 (9.08)\n",
      "(6) step 3300: training ELBO (KL) = -121.68 (8.92) -- KL weight = 0.29 -- validation ELBO (KL) = -117.53 (8.89)\n",
      "(6) step 3400: training ELBO (KL) = -121.89 (8.91) -- KL weight = 0.30 -- validation ELBO (KL) = -118.18 (8.74)\n",
      "(6) step 3500: training ELBO (KL) = -121.11 (8.80) -- KL weight = 0.31 -- validation ELBO (KL) = -117.50 (8.66)\n",
      "(6) step 3600: training ELBO (KL) = -121.35 (8.72) -- KL weight = 0.32 -- validation ELBO (KL) = -116.88 (8.83)\n",
      "(6) step 3700: training ELBO (KL) = -121.82 (8.64) -- KL weight = 0.32 -- validation ELBO (KL) = -116.94 (8.76)\n",
      "Finished epoch 6\n",
      "Evaluation epoch 6:\n",
      " - validation perplexity: 501.09\n",
      " - validation NLL: 133.23\n",
      " - validation ELBO (KL) = -117.17 (8.60)\n",
      "-- Original sentence: \"Clients are all staying out of the market one Merrill trader says\"\n",
      "-- Model reconstruction: \"Nor is n't likely to be able to be able to be a good\"\n",
      "(7) step 3800: training ELBO (KL) = -121.35 (8.71) -- KL weight = 0.33 -- validation ELBO (KL) = -116.62 (8.77)\n",
      "(7) step 3900: training ELBO (KL) = -120.86 (8.57) -- KL weight = 0.34 -- validation ELBO (KL) = -117.37 (8.36)\n",
      "(7) step 4000: training ELBO (KL) = -120.21 (8.59) -- KL weight = 0.35 -- validation ELBO (KL) = -116.54 (8.53)\n",
      "(7) step 4100: training ELBO (KL) = -118.42 (8.63) -- KL weight = 0.36 -- validation ELBO (KL) = -116.52 (8.47)\n",
      "(7) step 4200: training ELBO (KL) = -120.52 (8.44) -- KL weight = 0.37 -- validation ELBO (KL) = -116.85 (8.20)\n",
      "(7) step 4300: training ELBO (KL) = -120.92 (8.38) -- KL weight = 0.38 -- validation ELBO (KL) = -116.09 (8.55)\n",
      "Finished epoch 7\n",
      "Evaluation epoch 7:\n",
      " - validation perplexity: 470.85\n",
      " - validation NLL: 131.89\n",
      " - validation ELBO (KL) = -116.73 (8.13)\n",
      "-- Original sentence: \"Annualized average rate of return after expenses for the past 30 days not a forecast of future returns\"\n",
      "-- Model reconstruction: \"Each 5,000 bonds were priced to yield from the company 's largest company 's largest company\"\n",
      "(8) step 4400: training ELBO (KL) = -118.67 (8.35) -- KL weight = 0.39 -- validation ELBO (KL) = -116.39 (8.15)\n",
      "(8) step 4500: training ELBO (KL) = -119.42 (8.34) -- KL weight = 0.39 -- validation ELBO (KL) = -116.83 (8.06)\n",
      "(8) step 4600: training ELBO (KL) = -119.58 (8.25) -- KL weight = 0.40 -- validation ELBO (KL) = -116.73 (7.88)\n",
      "(8) step 4700: training ELBO (KL) = -119.58 (8.17) -- KL weight = 0.41 -- validation ELBO (KL) = -116.43 (7.86)\n",
      "(8) step 4800: training ELBO (KL) = -116.73 (8.18) -- KL weight = 0.42 -- validation ELBO (KL) = -115.60 (8.33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8) step 4900: training ELBO (KL) = -119.30 (8.08) -- KL weight = 0.43 -- validation ELBO (KL) = -115.94 (8.16)\n",
      "Finished epoch 8\n",
      "Evaluation epoch 8:\n",
      " - validation perplexity: 453.56\n",
      " - validation NLL: 131.09\n",
      " - validation ELBO (KL) = -115.77 (8.20)\n",
      "-- Original sentence: \"The spokesman further said that at least two more offers are expected from other companies within two weeks\"\n",
      "-- Model reconstruction: \"The company said it will be used to be a new company in the U.S. market\"\n",
      "(9) step 5000: training ELBO (KL) = -119.00 (8.02) -- KL weight = 0.44 -- validation ELBO (KL) = -115.59 (8.33)\n",
      "(9) step 5100: training ELBO (KL) = -117.96 (8.02) -- KL weight = 0.45 -- validation ELBO (KL) = -116.28 (7.76)\n",
      "(9) step 5200: training ELBO (KL) = -117.13 (7.98) -- KL weight = 0.46 -- validation ELBO (KL) = -116.31 (7.78)\n",
      "(9) step 5300: training ELBO (KL) = -116.93 (7.91) -- KL weight = 0.46 -- validation ELBO (KL) = -116.16 (7.76)\n",
      "(9) step 5400: training ELBO (KL) = -118.17 (7.86) -- KL weight = 0.47 -- validation ELBO (KL) = -116.19 (7.58)\n",
      "(9) step 5500: training ELBO (KL) = -117.90 (7.82) -- KL weight = 0.48 -- validation ELBO (KL) = -116.06 (7.62)\n",
      "(9) step 5600: training ELBO (KL) = -118.46 (7.77) -- KL weight = 0.49 -- validation ELBO (KL) = -116.04 (7.43)\n",
      "Finished epoch 9\n",
      "Evaluation epoch 9:\n",
      " - validation perplexity: 440.17\n",
      " - validation NLL: 130.45\n",
      " - validation ELBO (KL) = -115.67 (7.93)\n",
      "-- Original sentence: \"A spokesman for Laidlaw declined to disclose the price the Toronto transportation and waste services concern paid for the additional shares which he said were acquired over the last couple of weeks\"\n",
      "-- Model reconstruction: \"A spokesman said the company 's largest company said it will be able to be sold by the company 's largest company 's largest company said\"\n",
      "(10) step 5700: training ELBO (KL) = -115.97 (7.69) -- KL weight = 0.50 -- validation ELBO (KL) = -116.04 (7.49)\n",
      "(10) step 5800: training ELBO (KL) = -116.95 (7.62) -- KL weight = 0.51 -- validation ELBO (KL) = -116.00 (7.50)\n",
      "(10) step 5900: training ELBO (KL) = -117.03 (7.64) -- KL weight = 0.52 -- validation ELBO (KL) = -115.64 (7.70)\n",
      "(10) step 6000: training ELBO (KL) = -117.05 (7.59) -- KL weight = 0.53 -- validation ELBO (KL) = -115.56 (7.73)\n",
      "(10) step 6100: training ELBO (KL) = -117.08 (7.50) -- KL weight = 0.54 -- validation ELBO (KL) = -116.11 (7.27)\n",
      "(10) step 6200: training ELBO (KL) = -117.01 (7.42) -- KL weight = 0.54 -- validation ELBO (KL) = -115.52 (7.46)\n",
      "Finished epoch 10\n",
      "Evaluation epoch 10:\n",
      " - validation perplexity: 426.02\n",
      " - validation NLL: 129.75\n",
      " - validation ELBO (KL) = -115.27 (7.67)\n",
      "-- Original sentence: \"If you owned it and liked it Friday the true value has n't changed\"\n",
      "-- Model reconstruction: \"If you 're going to be able to be a lot of the company\"\n",
      "(11) step 6300: training ELBO (KL) = -116.85 (7.40) -- KL weight = 0.55 -- validation ELBO (KL) = -116.02 (7.43)\n",
      "(11) step 6400: training ELBO (KL) = -116.06 (7.31) -- KL weight = 0.56 -- validation ELBO (KL) = -116.07 (7.23)\n",
      "(11) step 6500: training ELBO (KL) = -115.85 (7.39) -- KL weight = 0.57 -- validation ELBO (KL) = -115.84 (7.37)\n",
      "(11) step 6600: training ELBO (KL) = -115.68 (7.21) -- KL weight = 0.58 -- validation ELBO (KL) = -115.82 (7.25)\n",
      "(11) step 6700: training ELBO (KL) = -117.04 (7.24) -- KL weight = 0.59 -- validation ELBO (KL) = -116.18 (7.03)\n",
      "(11) step 6800: training ELBO (KL) = -116.17 (7.17) -- KL weight = 0.60 -- validation ELBO (KL) = -116.18 (6.97)\n",
      "Finished epoch 11\n",
      "Evaluation epoch 11:\n",
      " - validation perplexity: 412.84\n",
      " - validation NLL: 129.07\n",
      " - validation ELBO (KL) = -116.16 (6.88)\n",
      "-- Original sentence: \"It therefore makes no sense for each market to adopt different circuit breakers\"\n",
      "-- Model reconstruction: \"It also also has been able to be able to be able to be reached\"\n",
      "(12) step 6900: training ELBO (KL) = -116.09 (7.13) -- KL weight = 0.61 -- validation ELBO (KL) = -116.19 (7.00)\n",
      "(12) step 7000: training ELBO (KL) = -115.26 (7.15) -- KL weight = 0.61 -- validation ELBO (KL) = -116.34 (7.06)\n",
      "(12) step 7100: training ELBO (KL) = -114.84 (7.02) -- KL weight = 0.62 -- validation ELBO (KL) = -116.08 (7.02)\n",
      "(12) step 7200: training ELBO (KL) = -115.51 (7.00) -- KL weight = 0.63 -- validation ELBO (KL) = -115.89 (7.10)\n",
      "(12) step 7300: training ELBO (KL) = -116.40 (6.89) -- KL weight = 0.64 -- validation ELBO (KL) = -116.01 (6.93)\n",
      "(12) step 7400: training ELBO (KL) = -115.69 (6.86) -- KL weight = 0.65 -- validation ELBO (KL) = -116.29 (6.70)\n",
      "Finished epoch 12\n",
      "Evaluation epoch 12:\n",
      " - validation perplexity: 408.75\n",
      " - validation NLL: 128.86\n",
      " - validation ELBO (KL) = -115.85 (6.91)\n",
      "-- Original sentence: \"The players were heckled by a patron during a July 4 1988 game with the Martinsville Phillies\"\n",
      "-- Model reconstruction: \"The company said it will be able to be able to be sold by the company 's largest market\"\n",
      "(13) step 7500: training ELBO (KL) = -115.63 (6.82) -- KL weight = 0.66 -- validation ELBO (KL) = -116.34 (6.85)\n",
      "(13) step 7600: training ELBO (KL) = -114.93 (6.85) -- KL weight = 0.67 -- validation ELBO (KL) = -116.41 (6.79)\n",
      "(13) step 7700: training ELBO (KL) = -115.31 (6.78) -- KL weight = 0.68 -- validation ELBO (KL) = -116.32 (6.78)\n",
      "(13) step 7800: training ELBO (KL) = -115.32 (6.75) -- KL weight = 0.68 -- validation ELBO (KL) = -116.44 (6.63)\n",
      "(13) step 7900: training ELBO (KL) = -115.96 (6.64) -- KL weight = 0.69 -- validation ELBO (KL) = -116.19 (6.70)\n",
      "(13) step 8000: training ELBO (KL) = -114.39 (6.62) -- KL weight = 0.70 -- validation ELBO (KL) = -116.58 (6.47)\n",
      "Finished epoch 13\n",
      "Evaluation epoch 13:\n",
      " - validation perplexity: 407.88\n",
      " - validation NLL: 128.82\n",
      " - validation ELBO (KL) = -116.06 (6.77)\n",
      "-- Original sentence: \"That move along with the return to the Manpower name could bolster the company 's prospects during possibly difficult times for temporary help\"\n",
      "-- Model reconstruction: \"That means that the company 's largest market is n't likely to be able to be a good way to the U.S.\"\n",
      "(14) step 8100: training ELBO (KL) = -114.92 (6.56) -- KL weight = 0.71 -- validation ELBO (KL) = -116.22 (6.81)\n",
      "(14) step 8200: training ELBO (KL) = -112.80 (6.56) -- KL weight = 0.72 -- validation ELBO (KL) = -116.79 (6.40)\n",
      "(14) step 8300: training ELBO (KL) = -115.05 (6.55) -- KL weight = 0.73 -- validation ELBO (KL) = -116.77 (6.44)\n",
      "(14) step 8400: training ELBO (KL) = -114.77 (6.49) -- KL weight = 0.74 -- validation ELBO (KL) = -116.44 (6.58)\n",
      "(14) step 8500: training ELBO (KL) = -115.66 (6.38) -- KL weight = 0.75 -- validation ELBO (KL) = -116.74 (6.46)\n",
      "(14) step 8600: training ELBO (KL) = -114.60 (6.36) -- KL weight = 0.75 -- validation ELBO (KL) = -116.89 (6.31)\n",
      "(14) step 8700: training ELBO (KL) = -115.28 (6.32) -- KL weight = 0.76 -- validation ELBO (KL) = -116.88 (6.21)\n",
      "Finished epoch 14\n",
      "Evaluation epoch 14:\n",
      " - validation perplexity: 400.53\n",
      " - validation NLL: 128.43\n",
      " - validation ELBO (KL) = -116.34 (6.44)\n",
      "-- Original sentence: \"Merrill Lynch 's commission revenue grew 21 % however to 462.8 million on higher share prices and volume and on strong sales of mutual funds\"\n",
      "-- Model reconstruction: \"Ford Motor Co. said it expects to sell the company 's stock market and the company 's stock market\"\n",
      "(15) step 8800: training ELBO (KL) = -112.72 (6.37) -- KL weight = 0.77 -- validation ELBO (KL) = -116.65 (6.35)\n",
      "(15) step 8900: training ELBO (KL) = -112.77 (6.30) -- KL weight = 0.78 -- validation ELBO (KL) = -117.33 (6.17)\n",
      "(15) step 9000: training ELBO (KL) = -115.00 (6.25) -- KL weight = 0.79 -- validation ELBO (KL) = -117.28 (6.22)\n",
      "(15) step 9100: training ELBO (KL) = -114.24 (6.20) -- KL weight = 0.80 -- validation ELBO (KL) = -116.84 (6.25)\n",
      "(15) step 9200: training ELBO (KL) = -114.90 (6.17) -- KL weight = 0.81 -- validation ELBO (KL) = -116.81 (6.16)\n",
      "(15) step 9300: training ELBO (KL) = -114.82 (6.16) -- KL weight = 0.82 -- validation ELBO (KL) = -116.87 (6.17)\n",
      "Finished epoch 15\n",
      "Evaluation epoch 15:\n",
      " - validation perplexity: 401.44\n",
      " - validation NLL: 128.47\n",
      " - validation ELBO (KL) = -116.87 (6.19)\n",
      "-- Original sentence: \"In August Di Giorgio a San Francisco food products and building materials marketing and distribution company rejected Mr. Goldberg 's offer as inadequate\"\n",
      "-- Model reconstruction: \"In addition to the company 's largest company said it expects to be a good bid for the company 's largest company\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16) step 9400: training ELBO (KL) = -113.97 (6.13) -- KL weight = 0.82 -- validation ELBO (KL) = -117.17 (6.15)\n",
      "(16) step 9500: training ELBO (KL) = -113.87 (6.05) -- KL weight = 0.83 -- validation ELBO (KL) = -116.85 (6.24)\n",
      "(16) step 9600: training ELBO (KL) = -112.71 (6.03) -- KL weight = 0.84 -- validation ELBO (KL) = -117.29 (5.99)\n",
      "(16) step 9700: training ELBO (KL) = -114.46 (5.99) -- KL weight = 0.85 -- validation ELBO (KL) = -117.44 (5.88)\n",
      "(16) step 9800: training ELBO (KL) = -113.50 (5.98) -- KL weight = 0.86 -- validation ELBO (KL) = -117.19 (5.83)\n",
      "(16) step 9900: training ELBO (KL) = -113.97 (5.97) -- KL weight = 0.87 -- validation ELBO (KL) = -117.95 (5.74)\n",
      "Finished epoch 16\n",
      "Evaluation epoch 16:\n",
      " - validation perplexity: 399.99\n",
      " - validation NLL: 128.40\n",
      " - validation ELBO (KL) = -116.94 (6.10)\n",
      "-- Original sentence: \"The space agency said it did n't expect weather or protesters to block the liftoff\"\n",
      "-- Model reconstruction: \"The new government is n't likely to be a good way to the U.S.\"\n",
      "(17) step 10000: training ELBO (KL) = -115.25 (5.93) -- KL weight = 0.88 -- validation ELBO (KL) = -117.49 (5.84)\n",
      "(17) step 10100: training ELBO (KL) = -111.15 (5.89) -- KL weight = 0.89 -- validation ELBO (KL) = -117.98 (5.78)\n",
      "(17) step 10200: training ELBO (KL) = -113.96 (5.86) -- KL weight = 0.89 -- validation ELBO (KL) = -117.58 (5.86)\n",
      "(17) step 10300: training ELBO (KL) = -113.08 (5.85) -- KL weight = 0.90 -- validation ELBO (KL) = -117.42 (5.90)\n",
      "(17) step 10400: training ELBO (KL) = -113.84 (5.84) -- KL weight = 0.91 -- validation ELBO (KL) = -117.69 (5.76)\n",
      "(17) step 10500: training ELBO (KL) = -113.81 (5.80) -- KL weight = 0.92 -- validation ELBO (KL) = -117.67 (5.78)\n",
      "Finished epoch 17\n",
      "Evaluation epoch 17:\n",
      " - validation perplexity: 398.50\n",
      " - validation NLL: 128.32\n",
      " - validation ELBO (KL) = -117.98 (5.61)\n",
      "-- Original sentence: \"For the three months ended in September retail sales volume was down 0.5 % from the previous three months and up 1.2 % from a year earlier\"\n",
      "-- Model reconstruction: \"For the nine months ended Sept. 30 1989 rose to 44 million or 72 cents a share from discontinued million or 1.02 a share\"\n",
      "(18) step 10600: training ELBO (KL) = -113.71 (5.75) -- KL weight = 0.93 -- validation ELBO (KL) = -117.84 (5.78)\n",
      "(18) step 10700: training ELBO (KL) = -112.59 (5.74) -- KL weight = 0.94 -- validation ELBO (KL) = -118.12 (5.56)\n",
      "(18) step 10800: training ELBO (KL) = -113.12 (5.73) -- KL weight = 0.95 -- validation ELBO (KL) = -118.01 (5.61)\n",
      "(18) step 10900: training ELBO (KL) = -112.43 (5.69) -- KL weight = 0.96 -- validation ELBO (KL) = -117.98 (5.54)\n",
      "(18) step 11000: training ELBO (KL) = -113.04 (5.67) -- KL weight = 0.96 -- validation ELBO (KL) = -117.69 (5.82)\n",
      "(18) step 11100: training ELBO (KL) = -112.81 (5.69) -- KL weight = 0.97 -- validation ELBO (KL) = -118.34 (5.55)\n",
      "(18) step 11200: training ELBO (KL) = -113.68 (5.64) -- KL weight = 0.98 -- validation ELBO (KL) = -118.16 (5.62)\n",
      "Finished epoch 18\n",
      "Evaluation epoch 18:\n",
      " - validation perplexity: 399.03\n",
      " - validation NLL: 128.35\n",
      " - validation ELBO (KL) = -118.07 (5.53)\n",
      "-- Original sentence: \"The spot October gold price rose 4 to 367.30 an ounce\"\n",
      "-- Model reconstruction: \"The average rate of the company 's stock market\"\n",
      "(19) step 11300: training ELBO (KL) = -111.24 (5.59) -- KL weight = 0.99 -- validation ELBO (KL) = -118.40 (5.52)\n",
      "(19) step 11400: training ELBO (KL) = -113.21 (5.58) -- KL weight = 1.00 -- validation ELBO (KL) = -118.46 (5.61)\n",
      "(19) step 11500: training ELBO (KL) = -112.17 (5.65) -- KL weight = 1.00 -- validation ELBO (KL) = -118.21 (5.62)\n",
      "(19) step 11600: training ELBO (KL) = -113.21 (5.59) -- KL weight = 1.00 -- validation ELBO (KL) = -117.98 (5.70)\n",
      "(19) step 11700: training ELBO (KL) = -112.98 (5.59) -- KL weight = 1.00 -- validation ELBO (KL) = -118.27 (5.44)\n",
      "(19) step 11800: training ELBO (KL) = -113.07 (5.55) -- KL weight = 1.00 -- validation ELBO (KL) = -118.15 (5.63)\n",
      "Finished epoch 19\n",
      "Evaluation epoch 19:\n",
      " - validation perplexity: 402.05\n",
      " - validation NLL: 128.51\n",
      " - validation ELBO (KL) = -118.14 (5.58)\n",
      "-- Original sentence: \"In addition to a general slowing of the computer industry NCR which sells automated teller machines and computerized cash registers is also affected by the retail and financial sectors areas of the economy that have generally not been robust notes Sanjiv G. Hingorani an analyst for Salomon Brothers Inc\"\n",
      "-- Model reconstruction: \"In addition to the U.S. and the company 's largest business and the company 's largest company said it will be able to be able to be able to be able to be able to be able to be able to be a good bid\"\n",
      "(20) step 11900: training ELBO (KL) = -111.14 (5.59) -- KL weight = 1.00 -- validation ELBO (KL) = -118.32 (5.50)\n",
      "(20) step 12000: training ELBO (KL) = -111.36 (5.56) -- KL weight = 1.00 -- validation ELBO (KL) = -118.54 (5.41)\n",
      "(20) step 12100: training ELBO (KL) = -112.33 (5.56) -- KL weight = 1.00 -- validation ELBO (KL) = -118.64 (5.42)\n",
      "(20) step 12200: training ELBO (KL) = -113.49 (5.56) -- KL weight = 1.00 -- validation ELBO (KL) = -118.46 (5.42)\n",
      "(20) step 12300: training ELBO (KL) = -112.84 (5.55) -- KL weight = 1.00 -- validation ELBO (KL) = -118.47 (5.50)\n",
      "(20) step 12400: training ELBO (KL) = -110.78 (5.57) -- KL weight = 1.00 -- validation ELBO (KL) = -118.41 (5.49)\n",
      "Finished epoch 20\n",
      "Evaluation epoch 20:\n",
      " - validation perplexity: 402.67\n",
      " - validation NLL: 128.54\n",
      " - validation ELBO (KL) = -118.27 (5.55)\n",
      "-- Original sentence: \"In composite trading on the New York Stock Exchange CMS Energy closed at 34.375 a share down 62.5 cents from the closing price of 37.375 a share on Thursday before Friday 's plunge\"\n",
      "-- Model reconstruction: \"In addition to the company 's net income rose to 7.93 million or 77 cents a share from discontinued million or 98 cents a share a year earlier\"\n"
     ]
    }
   ],
   "source": [
    "# Define the model hyperparameters.\n",
    "emb_size = 256\n",
    "hidden_size = 256 \n",
    "latent_size = 16\n",
    "bidirectional_encoder = True\n",
    "free_nats = 5.\n",
    "annealing_steps = 11400\n",
    "dropout = 0.6\n",
    "word_dropout = 0.75\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "n_importance_samples = 50\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n",
    "\n",
    "# Create the training data loader.\n",
    "dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "sorted_dl = SortingTextDataLoader(dl)\n",
    "\n",
    "# Create the model.\n",
    "model = BowmanLM(vocab_size=vocab.size(), \n",
    "                  emb_size=emb_size, \n",
    "                  hidden_size=hidden_size, \n",
    "                  latent_size=latent_size, \n",
    "                  pad_idx=vocab[PAD_TOKEN],\n",
    "                  dropout=dropout,\n",
    "                  bidirectional=bidirectional_encoder)\n",
    "model = model.to(device)\n",
    "\n",
    "# Create the optimizer.\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Save the best model (early stopping).\n",
    "best_model = \"./best_model.pt\"\n",
    "best_val_ppl = float(\"inf\")\n",
    "best_epoch = 0\n",
    "\n",
    "# Keep track of some statistics to plot later.\n",
    "train_ELBOs = []\n",
    "train_KLs = []\n",
    "val_ELBOs = []\n",
    "val_KLs = []\n",
    "val_perplexities = []\n",
    "val_NLLs = []\n",
    "\n",
    "step = 0\n",
    "training_ELBO = 0.\n",
    "training_KL = 0.\n",
    "num_batches = 0\n",
    "for epoch_num in range(1, num_epochs+1):    \n",
    "    for sentences in sorted_dl:\n",
    "\n",
    "        # Make sure the model is in training mode (for dropout).\n",
    "        model.train()\n",
    "\n",
    "        # Transform the sentences to input, output, seq_len, seq_mask batches.\n",
    "        x_in, x_out, seq_mask, seq_len = create_batch(sentences, vocab, device,\n",
    "                                                      word_dropout=word_dropout)\n",
    "\n",
    "        # Compute the multiplier for the KL term if we do annealing.\n",
    "        if annealing_steps > 0:\n",
    "            KL_weight = min(1., (1.0 / annealing_steps) * step)\n",
    "        else:\n",
    "            KL_weight = 1.\n",
    "        \n",
    "        # Do a forward pass through the model and compute the training loss. We use\n",
    "        # a reparameterized sample from the approximate posterior during training.\n",
    "        qz = model.infer(x_in, seq_mask, seq_len)\n",
    "        pz = Normal(torch.zeros_like(qz.mean), \n",
    "                    torch.ones_like(qz.stddev))\n",
    "        z = qz.rsample()\n",
    "        scores = model(x_in, z)\n",
    "        rec_loss, KL = model.loss(scores, x_out, pz, qz, free_nats=free_nats)\n",
    "        loss = rec_loss + KL_weight * KL\n",
    "\n",
    "        # Backpropagate and update the model weights.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update some statistics to track for the training loss.\n",
    "        training_ELBO += -(rec_loss - KL)\n",
    "        training_KL += KL\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Every 100 steps we evaluate the model and report progress.\n",
    "        if step % 100 == 0:\n",
    "            val_rec_loss, val_KL = eval_elbo(model, val_dataset, vocab, device)\n",
    "            val_ELBO = -(val_rec_loss - val_KL)\n",
    "            print(\"(%d) step %d: training ELBO (KL) = %.2f (%.2f) --\"\n",
    "                  \" KL weight = %.2f --\"\n",
    "                  \" validation ELBO (KL) = %.2f (%.2f)\" % \n",
    "                  (epoch_num, step, training_ELBO/num_batches, \n",
    "                   training_KL/num_batches, KL_weight, val_ELBO, val_KL))\n",
    "            \n",
    "            # Update some statistics for plotting later.\n",
    "            train_ELBOs.append((step, (training_ELBO/num_batches).item()))\n",
    "            train_KLs.append((step, (training_KL/num_batches).item()))\n",
    "            val_ELBOs.append((step, val_ELBO.item()))\n",
    "            val_KLs.append((step, val_KL.item()))\n",
    "            \n",
    "            # Reset the training statistics.\n",
    "            training_ELBO = 0.\n",
    "            training_KL = 0.\n",
    "            num_batches = 0\n",
    "            \n",
    "        step += 1\n",
    "\n",
    "    # After an epoch we'll compute validation perplexity and save the model\n",
    "    # for early stopping if it's better than previous models.\n",
    "    print(\"Finished epoch %d\" % (epoch_num))\n",
    "    val_perplexity, val_NLL = eval_perplexity(model, val_dataset, vocab, device, \n",
    "                                              n_importance_samples)\n",
    "    val_rec_loss, val_KL = eval_elbo(model, val_dataset, vocab, device)\n",
    "    val_ELBO = -(val_rec_loss - val_KL)\n",
    "    \n",
    "    # Keep track of the validation perplexities / NLL.\n",
    "    val_perplexities.append((epoch_num, val_perplexity.item()))\n",
    "    val_NLLs.append((epoch_num, val_NLL.item()))\n",
    "    \n",
    "    # If validation perplexity is better, store this model for early stopping.\n",
    "    if val_perplexity < best_val_ppl:\n",
    "        best_val_ppl = val_perplexity\n",
    "        best_epoch = epoch_num\n",
    "        torch.save(model.state_dict(), best_model)\n",
    "        \n",
    "    # Print epoch statistics.\n",
    "    print(\"Evaluation epoch %d:\\n\"\n",
    "          \" - validation perplexity: %.2f\\n\"\n",
    "          \" - validation NLL: %.2f\\n\"\n",
    "          \" - validation ELBO (KL) = %.2f (%.2f)\"\n",
    "          % (epoch_num, val_perplexity, val_NLL, val_ELBO, val_KL))\n",
    "\n",
    "    # Also show some qualitative results by reconstructing a sentence from the\n",
    "    # validation data. Use the mean of the approximate posterior and greedy\n",
    "    # decoding.\n",
    "    random_sentence = val_dataset[np.random.choice(len(val_dataset))]\n",
    "    x_in, _, seq_mask, seq_len = create_batch([random_sentence], vocab, device)\n",
    "    qz = model.infer(x_in, seq_mask, seq_len)\n",
    "    z = qz.mean\n",
    "    reconstruction = greedy_decode(model, z, vocab)\n",
    "    reconstruction = batch_to_sentences(reconstruction, vocab)[0]\n",
    "    print(\"-- Original sentence: \\\"%s\\\"\" % random_sentence)\n",
    "    print(\"-- Model reconstruction: \\\"%s\\\"\" % reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot the training and validation statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "steps, training_ELBO = list(zip(*train_ELBOs))\n",
    "_, training_KL = list(zip(*train_KLs))\n",
    "_, val_ELBO = list(zip(*val_ELBOs))\n",
    "_, val_KL = list(zip(*val_KLs))\n",
    "epochs, val_ppl = list(zip(*val_perplexities))\n",
    "_, val_NLL = list(zip(*val_NLLs))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "# Plot training ELBO and KL\n",
    "ax1.set_title(\"Training ELBO\")\n",
    "ax1.plot(steps, training_ELBO, \"-o\")\n",
    "ax2.set_title(\"Training KL\")\n",
    "ax2.plot(steps, training_KL, \"-o\")\n",
    "plt.show()\n",
    "\n",
    "# Plot validation ELBO and KL\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\n",
    "ax1.set_title(\"Validation ELBO\")\n",
    "ax1.plot(steps, val_ELBO, \"-o\", color=\"orange\")\n",
    "ax2.set_title(\"Validation KL\")\n",
    "ax2.plot(steps, val_KL, \"-o\",  color=\"orange\")\n",
    "plt.show()\n",
    "\n",
    "# Plot validation perplexities.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\n",
    "ax1.set_title(\"Validation perplexity\")\n",
    "ax1.plot(epochs, val_ppl, \"-o\", color=\"orange\")\n",
    "ax2.set_title(\"Validation NLL\")\n",
    "ax2.plot(epochs, val_NLL, \"-o\",  color=\"orange\")\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the best model according to validation perplexity and compute its perplexity on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ELBO (KL) = 117.37 (5.55) -- test perplexity = 410.16 -- test NLL = 127.64\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from disk.\n",
    "model = BowmanLM(vocab_size=vocab.size(), \n",
    "                 emb_size=emb_size, \n",
    "                 hidden_size=hidden_size, \n",
    "                 latent_size=latent_size, \n",
    "                 pad_idx=vocab[PAD_TOKEN],\n",
    "                 dropout=dropout,\n",
    "                 bidirectional=bidirectional_encoder)\n",
    "model.load_state_dict(torch.load(best_model))\n",
    "model = model.to(device)\n",
    "\n",
    "# Compute test perplexity and ELBO.\n",
    "test_perplexity, test_NLL = eval_perplexity(model, test_dataset, vocab, \n",
    "                                            device, n_importance_samples)\n",
    "test_rec_loss, test_KL = eval_elbo(model, test_dataset, vocab, device)\n",
    "test_ELBO = test_rec_loss - test_KL\n",
    "print(\"test ELBO (KL) = %.2f (%.2f) -- test perplexity = %.2f -- test NLL = %.2f\" % \n",
    "      (test_ELBO, test_KL, test_perplexity, test_NLL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative analysis\n",
    "\n",
    "Let's have a look at what how our trained model interacts with the learned latent space. First let's greedily decode some samples from the prior to assess the diversity of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: It was n't disclosed that the company 's stock\n",
      "2: Most analysts say they are n't disclosed\n",
      "3: What is n't a good\n",
      "4: The Senate Majority Leader Robert M. R. D. Hart who has been a good veto of the U.S. and the Senate of the U.S. and the U.S. and chief executive officer of the company 's largest division\n",
      "5: Ford 's largest maker of the company 's largest maker of the company 's largest steelmaker of the company 's largest business\n",
      "6: They are n't going to be a lot of the market 's new business\n",
      "7: There are n't going to be a lot of the same time to the U.S. and the best of the country\n",
      "8: But they 're going to be a lot of the company\n",
      "9: A spokesman said it expects to be a good bid for the company 's largest company and the company 's largest company and the company 's largest company\n",
      "10: At the same time the company 's largest business and the company 's largest auto maker of the company 's largest auto maker of the company 's largest auto maker of the company 's largest auto maker of the company 's largest business\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 samples from the standard normal prior.\n",
    "num_prior_samples = 10\n",
    "pz = Normal(torch.zeros(num_prior_samples, latent_size), \n",
    "            torch.ones(num_prior_samples, latent_size))\n",
    "z = pz.sample()\n",
    "z = z.to(device)\n",
    "\n",
    "# Use the greedy decoding algorithm to generate sentences.\n",
    "predictions = greedy_decode(model, z, vocab)\n",
    "predictions = batch_to_sentences(predictions, vocab)\n",
    "for num, prediction in enumerate(predictions):\n",
    "    print(\"%d: %s\" % (num+1, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look how good the model is at reconstructing sentences from the test dataset using the approximate posterior mean and a couple of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \"Rated Baa-1 by Moody 's and triple-B-plus by S&P the issue will be sold through underwriters led by Morgan Stanley & Co\"\n",
      "Posterior mean reconstruction: \"Rated single-A-2 by Moody 's Investors Service Inc. said it expects to sell the company 's largest company said\"\n",
      "Posterior sample reconstruction (1): \"Typical rates are expected to be sold by the company 's largest company and the company 's largest company\"\n",
      "Posterior sample reconstruction (2): \"Rated single-A-2 by Moody 's Investors Service Inc. said it expects to sell the company 's stock market\"\n",
      "Posterior sample reconstruction (3): \"Rated single-A-2 by Moody 's Investors Service Inc. said it expects to sell the company 's largest company said\"\n"
     ]
    }
   ],
   "source": [
    "# Pick a random test sentence.\n",
    "test_sentence = test_dataset[np.random.choice(len(test_dataset))]\n",
    "\n",
    "# Infer q(z|x).\n",
    "x_in, _, seq_mask, seq_len = create_batch([test_sentence], vocab, device)\n",
    "qz = model.infer(x_in, seq_mask, seq_len)\n",
    "\n",
    "# Decode using the mean.\n",
    "z_mean = qz.mean\n",
    "mean_reconstruction = greedy_decode(model, z_mean, vocab)\n",
    "mean_reconstruction = batch_to_sentences(mean_reconstruction, vocab)[0]\n",
    "\n",
    "print(\"Original: \\\"%s\\\"\" % test_sentence)\n",
    "print(\"Posterior mean reconstruction: \\\"%s\\\"\" % mean_reconstruction)\n",
    "\n",
    "# Decode a couple of samples from the approximate posterior.\n",
    "for s in range(3):\n",
    "    z = qz.sample()\n",
    "    sample_reconstruction = greedy_decode(model, z, vocab)\n",
    "    sample_reconstruction = batch_to_sentences(sample_reconstruction, vocab)[0]\n",
    "    print(\"Posterior sample reconstruction (%d): \\\"%s\\\"\" % (s+1, sample_reconstruction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also qualitatively assess the smoothness of the learned latent space by interpolating between two sentences in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: \"And the facts as found by the various courts in these two lawsuits were different\"\n",
      "(1-0.00) * qz1.mean + 0.00 qz2.mean: \"And the company 's biggest business is n't likely to be a good\"\n",
      "(1-0.25) * qz1.mean + 0.25 qz2.mean: \"And the company 's biggest business is n't likely to be a good\"\n",
      "(1-0.50) * qz1.mean + 0.50 qz2.mean: \"If the market is n't likely to be a lot of the company\"\n",
      "(1-0.75) * qz1.mean + 0.75 qz2.mean: \"There are n't going to be a lot of the market\"\n",
      "(1-1.00) * qz1.mean + 1.00 qz2.mean: \"There is a lot of the market 's decision to be a good\"\n",
      "Sentence 2: \"There is nothing wrong with the economy all the indices are up\"\n"
     ]
    }
   ],
   "source": [
    "# Pick a random test sentence.\n",
    "test_sentence_1 = test_dataset[np.random.choice(len(test_dataset))]\n",
    "\n",
    "# Infer q(z|x).\n",
    "x_in, _, seq_mask, seq_len = create_batch([test_sentence_1], vocab, device)\n",
    "qz = model.infer(x_in, seq_mask, seq_len)\n",
    "qz_1 = qz.mean\n",
    "\n",
    "# Pick a random second test sentence.\n",
    "test_sentence_2 = test_dataset[np.random.choice(len(test_dataset))]\n",
    "\n",
    "# Infer q(z|x) again.\n",
    "x_in, _, seq_mask, seq_len = create_batch([test_sentence_2], vocab, device)\n",
    "qz = model.infer(x_in, seq_mask, seq_len)\n",
    "qz_2 = qz.mean\n",
    "\n",
    "# Now interpolate between the two means and generate sentences between those.\n",
    "num_sentences = 5\n",
    "print(\"Sentence 1: \\\"%s\\\"\" % test_sentence_1)\n",
    "for alpha in np.linspace(start=0., stop=1., num=num_sentences):\n",
    "    z = (1-alpha) * qz_1 + alpha * qz_2\n",
    "    reconstruction = greedy_decode(model, z, vocab)\n",
    "    reconstruction = batch_to_sentences(reconstruction, vocab)[0]\n",
    "    print(\"(1-%.2f) * qz1.mean + %.2f qz2.mean: \\\"%s\\\"\" % (alpha, alpha, reconstruction))\n",
    "print(\"Sentence 2: \\\"%s\\\"\" % test_sentence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
