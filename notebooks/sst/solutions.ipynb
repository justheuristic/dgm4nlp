{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to import some helper code, so we need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  #  torch.device('cpu') # \n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoders\n",
    "\n",
    "For us an encoder takes a sequence of input vectors $\\mathbf s_1^n$, each $I$-dimensional, and produces a sequence of output vectors $\\mathbf t_1^n$, each $O$-dimensional and a summary vector $\\mathbf h \\in \\mathbb R^O$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf t_1^n, \\mathbf h = \\text{encoder}(\\mathbf s_1^n)\n",
    "\\end{equation}\n",
    "\n",
    "In practice for a correct batched implementation, our encoders also take a mask matrix and a vector of lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    For you to focus on DGMs and abstract away from certain architecture details, \n",
    "     we will be providing some helper classes.\n",
    "     \n",
    "    An encoder is one of them.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        \"\"\"\n",
    "        The inputs are batch-first tensors\n",
    "        \n",
    "        :param inputs: [B, T, d]\n",
    "        :param mask: [B, T]\n",
    "        :param lengths: [B]\n",
    "        :returns: [B, T, d], [B, d]\n",
    "            where the first tensor is the transformed input\n",
    "            and the second tensor is a summary of all inputs\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Passthrough(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not do anything, it simply passes the input forward and summarises \n",
    "        them via a sum.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Passthrough, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths, **kwargs):\n",
    "        # inputs: [B, T, d]\n",
    "        # mask: [B, T]\n",
    "        # lengths: [B]\n",
    "        \n",
    "        # [B, T, d], [B, d]\n",
    "        return inputs, (inputs * mask.unsqueeze(-1).float()).sum(dim=1) \n",
    "\n",
    "    \n",
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=None, \n",
    "                 hidden_sizes=[], \n",
    "                 aggregator='sum',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super(FFEncoder, self).__init__()\n",
    "        layers = []\n",
    "        if hidden_sizes:                    \n",
    "            for i, size in enumerate(hidden_sizes):\n",
    "                layers.append(('dropout%d' % i, nn.Dropout(p=dropout)))\n",
    "                layers.append(('linear%d' % i, nn.Linear(input_size, size)))\n",
    "                layers.append(('tanh%d' % i, nn.Tanh()))\n",
    "                input_size = size\n",
    "        layers.append(('dropout', nn.Dropout(p=dropout)))\n",
    "        layers.append(('linear', nn.Linear(input_size, output_size)))       \n",
    "        self.layer = nn.Sequential(OrderedDict(layers))     \n",
    "        self.activation = activation\n",
    "        if not aggregator in ['sum', 'avg']:\n",
    "            raise ValueError(\"I can only aggregate outputs using 'sum' or 'avg'\")\n",
    "        self.aggregator = aggregator\n",
    "        \n",
    "    def forward(self, x, mask, lengths):\n",
    "        # [B, T, d]\n",
    "        y = self.layer(x)\n",
    "        if not self.activation is None:\n",
    "            y = self.activation(y)\n",
    "        # [B, d]\n",
    "        s = (y * mask.unsqueeze(-1).float()).sum(dim=1)\n",
    "        if self.aggregator == 'avg':\n",
    "            s /= lengths.unsqueeze(-1).float()\n",
    "        return y, s\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence into a single vector using an LSTM,\n",
    "     it also returns the hidden states at each time step.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, hidden_size: int = 200,\n",
    "                 batch_first: bool = True,\n",
    "                 bidirectional: bool = True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(in_features, hidden_size, batch_first=batch_first,\n",
    "                            bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, E]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        packed_sequence = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        outputs, (hx, cx) = self.lstm(packed_sequence)\n",
    "        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        # classify from concatenation of final states\n",
    "        if self.lstm.bidirectional:\n",
    "            final = torch.cat([hx[-2], hx[-1]], dim=-1)\n",
    "        else:  # classify from final state\n",
    "            final = hx[-1]\n",
    "\n",
    "        return outputs, final\n",
    "    \n",
    "    \n",
    "def get_encoder(layer, in_features, hidden_size, bidirectional=True):\n",
    "    \"\"\"Returns the requested layer.\"\"\"\n",
    "\n",
    "    # TODO: make pass and average layers\n",
    "    if layer == \"pass\":\n",
    "        return Passthrough()\n",
    "    elif layer == 'ff':\n",
    "        return FFEncoder(in_features, 2 * hidden_size, hidden_sizes=[hidden_size], aggregator='sum')\n",
    "    elif layer == \"lstm\":\n",
    "        return LSTMEncoder(in_features, hidden_size,\n",
    "                           bidirectional=bidirectional)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior\n",
    "\n",
    "\n",
    "Our prior is a Bernoulli with fixed parameter $0 < p_1 < 1$:\n",
    "\n",
    "\\begin{align}\n",
    "Z_i & \\sim \\text{Bern}(p_1)\n",
    "\\end{align}\n",
    "\n",
    "As we will be using Bernoulli priors and posteriors, it is a good idea to implement a Bernoulli class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bernoulli:\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) + pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf).    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1/p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        if probs is None and logits is None:\n",
    "            raise ValueError('I need probabilities or logits')        \n",
    "        if logits is None:\n",
    "            self.probs = probs\n",
    "        else:\n",
    "            self.probs = torch.sigmoid(logits)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a sample with the same shape as the parameters\"\"\"\n",
    "        return torch.bernoulli(self.probs)\n",
    "    \n",
    "    def log_prob(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample. \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        return x * torch.log(self.probs) + (1 - x) * torch.log(1. - self.probs)\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        p1 = self.probs\n",
    "        p0 = 1. - self.probs\n",
    "        q1 = other.probs\n",
    "        q0 = 1. - other.probs        \n",
    "        return p1 * (torch.log(p1) - torch.log(q1)) + p0 * (torch.log(p0) - torch.log(q0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference model\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "Q(z|x) \n",
    "    &= \\prod_{i=1}^{|x|} Q(z_i|x; \\lambda) \\\\\n",
    "    &= \\prod_{i=1}^{|x|} \\text{Bern}(z_i|g_i(x; \\lambda)) \n",
    "\\end{align}\n",
    "\n",
    "where $g(x; \\lambda)$ is a NN that maps from $x$ to $|x|$ Bernoulli parameters, each of which, is a probability value (thus $0 < g_i(x; \\lambda) < 1$).\n",
    "\n",
    "Note that though we could condition on $y$ for approximate posterior inference, we are opportunistically leaving it out. This way, $Q$ is directly available at test time for making predictions.\n",
    "\n",
    "Here is an example design for $g$:\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\lambda_{\\text{enc}}) \\\\\n",
    "g_i(x; \\lambda) &= \\sigma(\\text{dense}_1(\\mathbf t_i; \\lambda_{\\text{output}}))\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{glove}$ is a pre-trained embedding function\n",
    "* $\\text{dense}_1$ is a dense layer with a single output\n",
    "* and $\\sigma(\\cdot)$ is the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we implement this product of Bernoulli distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:       nn.Embedding,\n",
    "                 hidden_size: int = 200,\n",
    "                 dropout:     float = 0.1,\n",
    "                 layer:       str = \"lstm\"\n",
    "                 ):\n",
    "\n",
    "        super(ProductOfBernoullis, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "\n",
    "        self.embed_layer = nn.Sequential(embed, nn.Dropout(p=dropout))\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "        self.logit_layer = nn.Linear(enc_size, 1, bias=True)\n",
    "        \n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "\n",
    "        # encode sentence\n",
    "        # [B]\n",
    "        lengths = mask.long().sum(1)\n",
    "        # [B, T, E]\n",
    "        emb = self.embed_layer(x)  \n",
    "        # [B, T, d]\n",
    "        h, _ = self.enc_layer(emb, mask, lengths)\n",
    "\n",
    "        # compute parameters for Bernoulli p(z|x)\n",
    "        # [B, T, 1] Bernoulli distributions\n",
    "        logits = self.logit_layer(h)\n",
    "        # [B, T]\n",
    "        logits = logits.squeeze(-1)\n",
    "        return Bernoulli(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "The classifier encodes only a selection of the input, which we denote $x \\odot z$, and parameterises a Categorical distribution over $5$ outcomes (sentiment levels):\n",
    "\n",
    "\\begin{align}\n",
    "    Z_i & \\sim \\text{Bern}(p_1) \\\\\n",
    "    Y|z,x &\\sim \\text{Cat}(f(x \\odot z; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "Here is an example design for $f$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= z_i \\, \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}}) \\\\\n",
    "f(x \\odot z; \\theta) &= \\text{softmax}(\\text{dense}_5(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "* $z_i$ either leaves $\\mathbf x_i$ unchanged or turns it into a vector of zeros;\n",
    "* the encoder only sees features from selected inputs, i.e. $x_i$ for which $z_i = 1$;\n",
    "* $\\text{dense}_5$ is a linear layer with $5$ outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categorical:\n",
    "    \n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "        \n",
    "    def log_prob(self, y):\n",
    "        \"\"\"\n",
    "        :param y: [B] integers\n",
    "        \"\"\"\n",
    "        return torch.gather(self.log_probs, 1, y.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:        nn.Embedding = None,\n",
    "                 hidden_size:  int = 200,\n",
    "                 output_size:  int = 1,\n",
    "                 dropout:      float = 0.1,\n",
    "                 layer:        str = \"pass\",\n",
    "                 ):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            embed,\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z=None) -> Categorical:\n",
    "\n",
    "        rnn_mask = mask\n",
    "        emb = self.embed_layer(x)\n",
    "\n",
    "        # apply z to inputs\n",
    "        if z is not None:\n",
    "            # [B, T]\n",
    "            rnn_mask = z > 0.\n",
    "            # [B, T, 1]\n",
    "            z_mask = z.unsqueeze(-1).float()\n",
    "            # [B, T, E]\n",
    "            emb = emb * z_mask\n",
    "\n",
    "        lengths = mask.long().sum(1)\n",
    "\n",
    "        # encode the sentence\n",
    "        _, final = self.enc_layer(emb, rnn_mask, lengths)\n",
    "\n",
    "        # predict sentiment from final state(s)\n",
    "        log_probs = self.output_layer(final)        \n",
    "        return Categorical(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softplus\n",
    "#from discrete.util import get_z_stats\n",
    "\n",
    "\n",
    "class RLModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Reimplementation of Lei et al. (2016). Rationalizing Neural Predictions\n",
    "    for Stanford Sentiment.\n",
    "    (Does classfication instead of regression.)\n",
    "\n",
    "    Consists of:\n",
    "    - Encoder that computes p(y | x, z)\n",
    "    - Generator that computes p(z | x) independently or dependently with an RNN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab:       object = None,\n",
    "                 vocab_size:  int = 0,\n",
    "                 emb_size:    int = 200,\n",
    "                 hidden_size: int = 200,\n",
    "                 output_size: int = 1,\n",
    "                 prior_p1:    float = 0.1,\n",
    "                 dropout:     float = 0.1,\n",
    "                 layer_cls:   str = 'pass',\n",
    "                 layer_inf:   str = 'lstm',\n",
    "                 ):\n",
    "\n",
    "        super(RLModel, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.embed = embed = nn.Embedding(vocab_size, emb_size, padding_idx=1)\n",
    "\n",
    "        # TODO: rename to obs_model\n",
    "        self.cls_net = Classifier(\n",
    "            embed=embed, hidden_size=hidden_size, output_size=output_size,\n",
    "            dropout=dropout, layer=layer_cls)\n",
    "        \n",
    "        # TODO: rename to q_z\n",
    "        self.inference_net = ProductOfBernoullis(\n",
    "            embed=embed, hidden_size=hidden_size,\n",
    "            dropout=dropout, layer=layer_inf)\n",
    "        \n",
    "        self.prior_p1 = prior_p1\n",
    "\n",
    "    def predict(self, py, **kwargs):\n",
    "        \"\"\"\n",
    "        Predict deterministically.\n",
    "        :param x:\n",
    "        :return: predictions, optional (dict with optional statistics)\n",
    "        \"\"\"\n",
    "        assert not self.training, \"should be in eval mode for prediction\"\n",
    "        return py.log_probs.argmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Generate a sequence of zs with the Generator.\n",
    "        Then predict with sentence x (zeroed out with z) using Encoder.\n",
    "\n",
    "        :param x: [B, T] (that is, batch-major is assumed)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        mask = (x != 1)  # [B,T]\n",
    "\n",
    "        qz = self.inference_net(x, mask)\n",
    "\n",
    "        if self.training:  # sample\n",
    "            # [B, T]\n",
    "            z = qz.sample()\n",
    "        else:  # deterministic\n",
    "            # [B, T]\n",
    "            # TODO: consider this\n",
    "            z = (qz.probs >= 0.5).float()\n",
    "            #z = q.sample()\n",
    "            \n",
    "        z = torch.where(mask, z, torch.zeros_like(z))\n",
    "        \n",
    "        py_xz = self.cls_net(x, mask, z)\n",
    "        return py_xz, qz, z\n",
    "\n",
    "    def get_loss(self, py, targets, \n",
    "                 q_z: Bernoulli, \n",
    "                 z, \n",
    "                 mask=None,\n",
    "                 iter_i=0, \n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This computes the loss for the whole model.\n",
    "        We stick to the variable names of the original code as much as\n",
    "        possible.\n",
    "\n",
    "        :param logits:\n",
    "        :param targets:\n",
    "        :param sparsity:\n",
    "        :param coherent:\n",
    "        :param mask:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert mask is not None, \"provide mask\"\n",
    "\n",
    "        lengths = mask.sum(1).float()\n",
    "        batch_size = mask.size(0)\n",
    "        terms = OrderedDict()\n",
    "\n",
    "        # shape: [B]\n",
    "        # log p(y|x,z) where z ~ q\n",
    "        #one_hot_target = (targets.unsqueeze(-1) == torch.arange(5, device=device).reshape(1, 5)).float()            \n",
    "        #ll = torch.sum(py.log_probs * one_hot_target, dim=-1)\n",
    "        # [B]\n",
    "        ll = py.log_prob(targets)\n",
    "        \n",
    "        # KL(q||p)\n",
    "        # [B, T]\n",
    "        #p_z = Bernoulli(probs=torch.full_like(q_z.probs, self.prior_p1))\n",
    "        prior_p1 = np.random.beta(0.6, 0.6)\n",
    "        p_z = Bernoulli(probs=torch.full_like(q_z.probs, prior_p1))\n",
    "        kl = q_z.kl(p_z)\n",
    "        kl = torch.where(mask, kl, torch.zeros_like(kl))\n",
    "                \n",
    "        # Compute the log density of the sample\n",
    "        # [B, T]\n",
    "        log_q_z = q_z.log_prob(z)\n",
    "        log_q_z = torch.where(mask, log_q_z, torch.zeros_like(log_q_z))\n",
    "        # We have independent Bernoullis, thus we just sum their log probabilities\n",
    "        # [B]\n",
    "        log_q_z = log_q_z.sum(1)\n",
    "        \n",
    "        # surrogate objective for score function estimator\n",
    "        # [B]\n",
    "        reward = (ll.detach() - torch.full_like(ll, ll_mean)) / torch.full_like(ll, ll_std)\n",
    "        sf_surrogate = (reward * log_q_z)\n",
    "\n",
    "        # Make terms in the ELBO\n",
    "        # []\n",
    "        ll = ll.mean()\n",
    "        sf_surrogate = sf_surrogate.mean()\n",
    "        # KL may require annealing and free-bits\n",
    "        # [B]\n",
    "        kl = kl.sum(dim=-1)\n",
    "        kl_fb = torch.max(torch.full_like(kl, min_kl), kl)\n",
    "        # []\n",
    "        kl = kl.mean() \n",
    "        kl_fb = kl_fb.mean() \n",
    "        kl_fb = kl_fb * kl_weight\n",
    "        \n",
    "        terms['elbo'] = (ll - kl_fb).item()\n",
    "        terms['ll'] = ll.item()\n",
    "        terms['kl_fb'] = kl_fb.item()\n",
    "        terms['kl'] = kl.item()\n",
    "        terms['kl_weight'] = kl_weight\n",
    "        terms['sf'] = sf_surrogate.item()\n",
    "        terms['reward'] = reward.mean().item()\n",
    "        terms['ll_mean'] = ll_mean\n",
    "        terms['ll_std'] = ll_std\n",
    "        terms['selected'] = (z.sum(1) / lengths).mean().item()\n",
    "        terms['prior_p1'] = prior_p1\n",
    "        terms['avg_p1'] = (torch.where(mask, q_z.probs, torch.zeros_like(q_z.probs)).sum() / mask.sum().float()).item()\n",
    "            \n",
    "        return - ll - sf_surrogate + kl_fb, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class MovingStats:\n",
    "    \n",
    "    def __init__(self, memory=-1):\n",
    "        self.data = deque([])\n",
    "        self.memory = memory\n",
    "        \n",
    "    def append(self, value):\n",
    "        if self.memory != 0:\n",
    "            if self.memory > 0 and len(self.data) == self.memory:\n",
    "                self.data.popleft()\n",
    "            self.data.append(value)\n",
    "        \n",
    "    def mean(self):\n",
    "        if len(self.data):\n",
    "            return np.mean([x for x in self.data])\n",
    "        else:\n",
    "            return 0.\n",
    "    \n",
    "    def std(self):\n",
    "        return 1.  # np.std(self.data) if len(self.data) > 1 else 1.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discrete.util import make_kv_string, get_minibatch, prepare_minibatch, print_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Configuration\n",
      "dropout              :        0.5\n",
      "min_phrase_length    :          2\n",
      "layer_cls            : pass      \n",
      "max_grad_norm        :        5.0\n",
      "min_lr               :      1e-05\n",
      "cooldown             :          5\n",
      "prior_p1             :        0.3\n",
      "hidden_size          :        150\n",
      "num_layers           :          1\n",
      "baseline_memory      :       1000\n",
      "lr                   :     0.0002\n",
      "print_every          :        100\n",
      "batch_size           :         25\n",
      "eval_batch_size      :         25\n",
      "word_vectors         : data/sst/glove.840B.300d.filtered.txt\n",
      "lr_decay             :        0.5\n",
      "min_kl               :        0.0\n",
      "layer_inf            : pass      \n",
      "num_iterations       :        -20\n",
      "threshold            :     0.0001\n",
      "kl_weight            :        0.0\n",
      "subphrases           :          0\n",
      "save_path            : data/results\n",
      "weight_decay         :      1e-05\n",
      "lowercase            :          1\n",
      "embed_size           :        300\n",
      "fix_emb              :          1\n",
      "patience             :          5\n",
      "eval_every           :         -1\n",
      "kl_inc               :      1e-05\n",
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "Set eval_every to 341\n",
      "Set num_iterations to 6820\n",
      "\n",
      "# Example\n",
      "First dev example: Example(tokens=['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "from discrete.sstutil import examplereader, Vocabulary, load_glove\n",
    "from collections import OrderedDict\n",
    "import torch.optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "from discrete.evaluate import evaluate\n",
    "#from tensorboardX import SummaryWriter\n",
    "\n",
    "cfg = dict()\n",
    "\n",
    "cfg['num_iterations'] = -20  # use negative for epochs and positive for iterations\n",
    "cfg['print_every'] = 100\n",
    "cfg['eval_every'] = -1\n",
    "cfg['batch_size'] = 25\n",
    "cfg['eval_batch_size'] = 25\n",
    "cfg['subphrases'] = False\n",
    "cfg['min_phrase_length'] = 2\n",
    "cfg['lowercase'] = True\n",
    "cfg['word_vectors'] = 'data/sst/glove.840B.300d.filtered.txt'\n",
    "cfg['fix_emb'] = True\n",
    "cfg['embed_size'] = 300\n",
    "cfg['hidden_size'] = 150\n",
    "cfg['num_layers'] = 1\n",
    "cfg['dropout'] = 0.5\n",
    "cfg['layer_inf'] = 'pass'\n",
    "cfg['layer_cls'] = 'pass'\n",
    "cfg['save_path'] = 'data/results'\n",
    "cfg['baseline_memory'] = 1000\n",
    "cfg['prior_p1'] = 0.3\n",
    "cfg['min_kl'] = 0.\n",
    "cfg['kl_weight'] = 0.\n",
    "cfg['kl_inc'] = 0.00001\n",
    "# Optimisation options: leave as is\n",
    "cfg['lr'] = 0.0002\n",
    "cfg['weight_decay'] = 1e-5\n",
    "cfg['lr_decay'] = 0.5\n",
    "cfg['patience'] = 5\n",
    "cfg['cooldown'] = 5\n",
    "cfg['threshold'] = 1e-4\n",
    "cfg['min_lr'] = 1e-5\n",
    "cfg['max_grad_norm'] = 5.\n",
    "\n",
    "\n",
    "print('# Configuration')\n",
    "for k, v in cfg.items():\n",
    "    print(\"{:20} : {:10}\".format(k, v))\n",
    "    \n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader(\n",
    "    \"data/sst/train.txt\",\n",
    "    lower=cfg['lowercase'], \n",
    "    subphrases=cfg['subphrases'],\n",
    "    min_length=cfg['min_phrase_length']))\n",
    "dev_data = list(examplereader(\"data/sst/dev.txt\", lower=cfg['lowercase']))\n",
    "test_data = list(examplereader(\"data/sst/test.txt\", lower=cfg['lowercase']))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "iters_per_epoch = len(train_data) // cfg[\"batch_size\"]\n",
    "\n",
    "if cfg[\"eval_every\"] == -1:\n",
    "    eval_every = iters_per_epoch\n",
    "    print(\"Set eval_every to {}\".format(iters_per_epoch))\n",
    "\n",
    "if cfg[\"num_iterations\"] < 0:\n",
    "    num_iterations = iters_per_epoch * -1 * cfg[\"num_iterations\"]\n",
    "    print(\"Set num_iterations to {}\".format(num_iterations))\n",
    "\n",
    "print('\\n# Example')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)\n",
    "\n",
    "\n",
    "def train():\n",
    "    vocab = Vocabulary()  # populated by load_glove\n",
    "    glove_path = cfg[\"word_vectors\"]\n",
    "    vectors = load_glove(glove_path, vocab)\n",
    "\n",
    "    #writer = SummaryWriter(log_dir=cfg[\"save_path\"])\n",
    "\n",
    "    # Map the sentiment labels 0-4 to a more readable form (and the opposite)\n",
    "    i2t = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
    "    t2i = OrderedDict({p: i for p, i in zip(i2t, range(len(i2t)))})\n",
    "\n",
    "\n",
    "    print('\\n# Constructing model')\n",
    "    model = RLModel(\n",
    "        vocab_size=len(vocab.w2i), \n",
    "        emb_size=cfg[\"embed_size\"],\n",
    "        hidden_size=cfg[\"hidden_size\"], \n",
    "        output_size=len(t2i),\n",
    "        prior_p1=cfg['prior_p1'],\n",
    "        vocab=vocab, \n",
    "        dropout=cfg[\"dropout\"], \n",
    "        layer_cls=cfg[\"layer_cls\"],\n",
    "        layer_inf=cfg[\"layer_inf\"])\n",
    "\n",
    "    print('\\n# Loading embeddings')\n",
    "    with torch.no_grad():\n",
    "        model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "        if cfg[\"fix_emb\"]:\n",
    "            print(\"fixed word embeddings\")\n",
    "            model.embed.weight.requires_grad = False\n",
    "        model.embed.weight[1] = 0.  # padding zero\n",
    "\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=cfg[\"lr\"],\n",
    "                     weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "    # lagrange optimizer (if there are lagrange lambdas to optimize)\n",
    "    #if len(model.lagrange_parameters()) > 0:\n",
    "    #    lagrange_optimizer = Adam(model.lagrange_parameters(), lr=cfg[\"lr\"])\n",
    "    #else:\n",
    "    #    lagrange_optimizer = None\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "        verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "        min_lr=cfg[\"min_lr\"])\n",
    "\n",
    "    iter_i = 0\n",
    "    train_loss = 0.\n",
    "    print_num = 0\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    best_eval = 1.0e9\n",
    "    best_iter = 0\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # print model\n",
    "    print(model)\n",
    "    print_parameters(model)\n",
    "\n",
    "    batch_size = cfg['batch_size']\n",
    "    eval_batch_size = cfg['eval_batch_size']\n",
    "    print_every = cfg['print_every']\n",
    "\n",
    "    kl_inc = cfg['kl_inc']\n",
    "    kl_weight = cfg['kl_weight']\n",
    "    min_kl = cfg['min_kl']\n",
    "    ll_moving_stats = MovingStats(cfg['baseline_memory'])\n",
    "\n",
    "    while True:  # when we run out of examples, shuffle and continue\n",
    "        for batch in get_minibatch(train_data, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "            epoch = iter_i // iters_per_epoch\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            x, targets, _ = prepare_minibatch(batch, model.vocab, device=device)\n",
    "\n",
    "            # with autograd.detect_anomaly():\n",
    "\n",
    "            py, q_z, z = model(x)\n",
    "\n",
    "            mask = (x != 1)\n",
    "            # \"KL annealing\"\n",
    "            kl_weight += kl_inc\n",
    "            if kl_weight > 1.:\n",
    "                kl_weight = 1.0\n",
    "                \n",
    "                \n",
    "            with autograd.detect_anomaly():\n",
    "                loss, terms = model.get_loss(\n",
    "                    py, \n",
    "                    targets, \n",
    "                    q_z=q_z,\n",
    "                    z=z,\n",
    "                    mask=mask, \n",
    "                    kl_weight=kl_weight,\n",
    "                    min_kl=min_kl,\n",
    "                    ll_mean=ll_moving_stats.mean(),\n",
    "                    ll_std=ll_moving_stats.std(),\n",
    "                    iter_i=iter_i)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            ll_moving_stats.append(terms['ll'])\n",
    "\n",
    "            # backward pass\n",
    "            model.zero_grad()  # erase previous gradients\n",
    "\n",
    "            loss.backward()  # compute new gradients\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['max_grad_norm'])\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            print_num += 1\n",
    "            iter_i += 1\n",
    "\n",
    "            # print info\n",
    "            if iter_i % print_every == 0:\n",
    "\n",
    "                train_loss = train_loss / print_every\n",
    "                #writer.add_scalar('data/train_loss', train_loss, iter_i)\n",
    "                #for k, v in loss_optional.items():\n",
    "                #    writer.add_scalar('data/'+k, v, iter_i)\n",
    "\n",
    "                print_str = make_kv_string(terms)\n",
    "                print(\"Epoch %r Iter %r loss=%.4f %s\" %\n",
    "                      (epoch, iter_i, train_loss, print_str))\n",
    "                losses.append(train_loss)\n",
    "                print_num = 0\n",
    "                train_loss = 0.\n",
    "\n",
    "            # evaluate\n",
    "            if iter_i % eval_every == 0:\n",
    "\n",
    "                dev_eval, rationales = evaluate(\n",
    "                    model, dev_data, \n",
    "                    batch_size=eval_batch_size, \n",
    "                    device=device,\n",
    "                    cfg=cfg, iter_i=iter_i)\n",
    "                accuracies.append(dev_eval[\"acc\"])\n",
    "\n",
    "                #for k, v in dev_eval.items():\n",
    "                #    writer.add_scalar('data/dev/'+k, v, iter_i)\n",
    "\n",
    "                print(\"\\n# epoch %r iter %r: dev %s\" % (\n",
    "                    epoch, iter_i, make_kv_string(dev_eval)))\n",
    "                \n",
    "                for exid in range(3):\n",
    "                    print(' dev%d [gold=%d,pred=%d]:' % (exid, dev_data[exid].label, rationales[exid][1]),  \n",
    "                          ' '.join(rationales[exid][0]))\n",
    "                print()\n",
    "\n",
    "                #test_eval = evaluate(\n",
    "                #    model, test_data, batch_size=eval_batch_size, device=device,\n",
    "                #    cfg=cfg, iter_i=iter_i)\n",
    "                #for k, v in test_eval.items():\n",
    "                #    writer.add_scalar('data/test/'+k, v, iter_i)\n",
    "\n",
    "                #print(\"# epoch %r iter %r: tst %s\" % (\n",
    "                #    epoch, iter_i, make_kv_string(test_eval)))\n",
    "\n",
    "                # adjust learning rate\n",
    "\n",
    "                scheduler.step(dev_eval[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Constructing model\n",
      "Classifier #params: 1505\n",
      "ProductOfBernoullis #params: 301\n",
      "\n",
      "# Loading embeddings\n",
      "fixed word embeddings\n",
      "RLModel(\n",
      "  (embed): Embedding(20727, 300, padding_idx=1)\n",
      "  (cls_net): Classifier(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "      (1): Dropout(p=0.5)\n",
      "    )\n",
      "    (enc_layer): Passthrough()\n",
      "    (output_layer): Sequential(\n",
      "      (0): Dropout(p=0.5)\n",
      "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
      "      (2): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (inference_net): ProductOfBernoullis(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "      (1): Dropout(p=0.5)\n",
      "    )\n",
      "    (enc_layer): Passthrough()\n",
      "    (logit_layer): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "embed.weight             [20727, 300] requires_grad=False\n",
      "cls_net.output_layer.1.weight [5, 300]     requires_grad=True\n",
      "cls_net.output_layer.1.bias [5]          requires_grad=True\n",
      "inference_net.logit_layer.weight [1, 300]     requires_grad=True\n",
      "inference_net.logit_layer.bias [1]          requires_grad=True\n",
      "\n",
      "Total parameters: 6219906\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 0 Iter 100 loss=2.5912 elbo -1.8383 ll -1.8322 kl_fb 0.0061 kl 6.1201 kl_weight 0.0010 sf -4.2706 reward 0.3251 ll_mean -2.1572 ll_std 1.0000 selected 0.4894 prior_p1 0.1603 avg_p1 0.5040\n",
      "Epoch 0 Iter 200 loss=3.6221 elbo -1.5735 ll -1.5713 kl_fb 0.0023 kl 1.1252 kl_weight 0.0020 sf -8.1977 reward 0.5016 ll_mean -2.0729 ll_std 1.0000 selected 0.5521 prior_p1 0.6451 avg_p1 0.5049\n",
      "Epoch 0 Iter 300 loss=4.2010 elbo -1.7629 ll -1.7176 kl_fb 0.0454 kl 15.1227 kl_weight 0.0030 sf -3.4489 reward 0.2807 ll_mean -1.9983 ll_std 1.0000 selected 0.5379 prior_p1 0.9505 avg_p1 0.5008\n",
      "\n",
      "# epoch 0 iter 341: dev loss -6.5748 elbo -13.4897 ll -1.6175 kl_fb 11.8722 kl 11.8722 kl_weight 1.0000 sf 20.0645 reward -1.6175 ll_mean 0.0000 ll_std 1.0000 selected 0.5576 prior_p1 0.4969 avg_p1 0.5013 acc 0.2761\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=1]: **no** **one** goes **unindicted** here , **which** is **probably** for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 1 Iter 400 loss=4.3354 elbo -2.0433 ll -1.9461 kl_fb 0.0972 kl 24.2914 kl_weight 0.0040 sf 0.0817 reward -0.0053 ll_mean -1.9408 ll_std 1.0000 selected 0.4624 prior_p1 0.0299 avg_p1 0.5005\n",
      "Epoch 1 Iter 500 loss=4.3536 elbo -1.6347 ll -1.6310 kl_fb 0.0037 kl 0.7387 kl_weight 0.0050 sf -2.9904 reward 0.2652 ll_mean -1.8962 ll_std 1.0000 selected 0.5345 prior_p1 0.6372 avg_p1 0.4984\n",
      "Epoch 1 Iter 600 loss=4.0928 elbo -2.2503 ll -1.9303 kl_fb 0.3200 kl 53.3267 kl_weight 0.0060 sf 0.9548 reward -0.0674 ll_mean -1.8629 ll_std 1.0000 selected 0.4727 prior_p1 0.9987 avg_p1 0.5088\n",
      "\n",
      "# epoch 1 iter 682: dev loss -7.2258 elbo -11.7655 ll -1.5370 kl_fb 10.2284 kl 10.2284 kl_weight 1.0000 sf 18.9913 reward -1.5370 ll_mean 0.0000 ll_std 1.0000 selected 0.5926 prior_p1 0.5092 avg_p1 0.5067 acc 0.3197\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here , **which** is probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 2 Iter 700 loss=4.1370 elbo -1.4847 ll -1.4808 kl_fb 0.0039 kl 0.5561 kl_weight 0.0070 sf -4.3989 reward 0.3545 ll_mean -1.8352 ll_std 1.0000 selected 0.5596 prior_p1 0.3985 avg_p1 0.5099\n",
      "Epoch 2 Iter 800 loss=4.2735 elbo -1.5031 ll -1.4660 kl_fb 0.0371 kl 4.6407 kl_weight 0.0080 sf -4.7011 reward 0.3429 ll_mean -1.8089 ll_std 1.0000 selected 0.4764 prior_p1 0.2037 avg_p1 0.5053\n",
      "Epoch 2 Iter 900 loss=4.1118 elbo -1.5803 ll -1.5349 kl_fb 0.0455 kl 5.0504 kl_weight 0.0090 sf -3.0155 reward 0.2523 ll_mean -1.7872 ll_std 1.0000 selected 0.5284 prior_p1 0.8291 avg_p1 0.4992\n",
      "Epoch 2 Iter 1000 loss=4.0875 elbo -1.5867 ll -1.4827 kl_fb 0.1040 kl 10.4014 kl_weight 0.0100 sf -3.6096 reward 0.2857 ll_mean -1.7684 ll_std 1.0000 selected 0.5041 prior_p1 0.9074 avg_p1 0.4921\n",
      "\n",
      "# epoch 2 iter 1023: dev loss -7.5621 elbo -10.9379 ll -1.4899 kl_fb 9.4480 kl 9.4480 kl_weight 1.0000 sf 18.5001 reward -1.4899 ll_mean 0.0000 ll_std 1.0000 selected 0.5221 prior_p1 0.5238 avg_p1 0.4974 acc 0.3324\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** lovely **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 3 Iter 1100 loss=3.8504 elbo -1.8740 ll -1.6504 kl_fb 0.2236 kl 20.3296 kl_weight 0.0110 sf -0.7858 reward 0.0597 ll_mean -1.7102 ll_std 1.0000 selected 0.5474 prior_p1 0.9668 avg_p1 0.4948\n",
      "Epoch 3 Iter 1200 loss=3.1536 elbo -2.2792 ll -1.7596 kl_fb 0.5195 kl 43.2942 kl_weight 0.0120 sf 1.0906 reward -0.0907 ll_mean -1.6689 ll_std 1.0000 selected 0.4608 prior_p1 0.0019 avg_p1 0.5036\n",
      "Epoch 3 Iter 1300 loss=2.9532 elbo -1.5786 ll -1.4808 kl_fb 0.0977 kl 7.5189 kl_weight 0.0130 sf -2.0746 reward 0.1588 ll_mean -1.6397 ll_std 1.0000 selected 0.5386 prior_p1 0.8703 avg_p1 0.5031\n",
      "\n",
      "# epoch 3 iter 1364: dev loss -6.6158 elbo -11.6915 ll -1.4783 kl_fb 10.2132 kl 10.2132 kl_weight 1.0000 sf 18.3073 reward -1.4783 ll_mean 0.0000 ll_std 1.0000 selected 0.5972 prior_p1 0.5384 avg_p1 0.5050 acc 0.3515\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here , **which** **is** probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 4 Iter 1400 loss=2.8009 elbo -1.4860 ll -1.4414 kl_fb 0.0446 kl 3.1829 kl_weight 0.0140 sf -2.3156 reward 0.1760 ll_mean -1.6175 ll_std 1.0000 selected 0.4650 prior_p1 0.7618 avg_p1 0.5013\n",
      "Epoch 4 Iter 1500 loss=2.5832 elbo -2.0520 ll -1.4949 kl_fb 0.5571 kl 37.1385 kl_weight 0.0150 sf -1.6691 reward 0.1047 ll_mean -1.5996 ll_std 1.0000 selected 0.4769 prior_p1 0.9883 avg_p1 0.4892\n",
      "Epoch 4 Iter 1600 loss=2.2279 elbo -2.5678 ll -1.4977 kl_fb 1.0700 kl 66.8775 kl_weight 0.0160 sf -0.9991 reward 0.0877 ll_mean -1.5855 ll_std 1.0000 selected 0.5372 prior_p1 0.9999 avg_p1 0.4874\n",
      "Epoch 4 Iter 1700 loss=2.3420 elbo -2.0809 ll -1.4512 kl_fb 0.6298 kl 37.0468 kl_weight 0.0170 sf -1.4616 reward 0.1204 ll_mean -1.5716 ll_std 1.0000 selected 0.4699 prior_p1 0.0041 avg_p1 0.5022\n",
      "\n",
      "# epoch 4 iter 1705: dev loss -5.7878 elbo -12.4723 ll -1.4681 kl_fb 11.0041 kl 11.0041 kl_weight 1.0000 sf 18.2600 reward -1.4681 ll_mean 0.0000 ll_std 1.0000 selected 0.5065 prior_p1 0.4837 avg_p1 0.4998 acc 0.3624\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here , **which** **is** probably for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 5 Iter 1800 loss=2.2308 elbo -1.5708 ll -1.5674 kl_fb 0.0033 kl 0.1839 kl_weight 0.0180 sf 0.0741 reward -0.0067 ll_mean -1.5608 ll_std 1.0000 selected 0.5146 prior_p1 0.5577 avg_p1 0.5005\n",
      "Epoch 5 Iter 1900 loss=2.1193 elbo -1.6142 ll -1.5988 kl_fb 0.0155 kl 0.8141 kl_weight 0.0190 sf 0.6307 reward -0.0469 ll_mean -1.5519 ll_std 1.0000 selected 0.5331 prior_p1 0.6440 avg_p1 0.5132\n",
      "Epoch 5 Iter 2000 loss=2.3615 elbo -1.5554 ll -1.5441 kl_fb 0.0113 kl 0.5663 kl_weight 0.0200 sf 0.0261 reward -0.0020 ll_mean -1.5421 ll_std 1.0000 selected 0.4650 prior_p1 0.6104 avg_p1 0.5026\n",
      "\n",
      "# epoch 5 iter 2046: dev loss -6.7739 elbo -11.1853 ll -1.4459 kl_fb 9.7393 kl 9.7393 kl_weight 1.0000 sf 17.9591 reward -1.4459 ll_mean 0.0000 ll_std 1.0000 selected 0.6601 prior_p1 0.4861 avg_p1 0.5107 acc 0.3778\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here , **which** **is** probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears **by** **a** couple **of** scenes , you 've got **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Iter 2100 loss=2.0847 elbo -1.5017 ll -1.3368 kl_fb 0.1649 kl 7.8519 kl_weight 0.0210 sf -2.6152 reward 0.1998 ll_mean -1.5367 ll_std 1.0000 selected 0.5177 prior_p1 0.1376 avg_p1 0.5166\n",
      "Epoch 6 Iter 2200 loss=2.1827 elbo -1.6340 ll -1.6161 kl_fb 0.0178 kl 0.8108 kl_weight 0.0220 sf 1.3173 reward -0.0877 ll_mean -1.5284 ll_std 1.0000 selected 0.5431 prior_p1 0.3864 avg_p1 0.5123\n",
      "Epoch 6 Iter 2300 loss=2.0484 elbo -1.4581 ll -1.4240 kl_fb 0.0341 kl 1.4824 kl_weight 0.0230 sf -1.3011 reward 0.0993 ll_mean -1.5233 ll_std 1.0000 selected 0.4623 prior_p1 0.6959 avg_p1 0.5130\n",
      "\n",
      "# epoch 6 iter 2387: dev loss -4.3817 elbo -13.6711 ll -1.4459 kl_fb 12.2252 kl 12.2252 kl_weight 1.0000 sf 18.0528 reward -1.4459 ll_mean 0.0000 ll_std 1.0000 selected 0.6400 prior_p1 0.5293 avg_p1 0.5117 acc 0.3669\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here , **which** **is** probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 7 Iter 2400 loss=2.0093 elbo -1.6244 ll -1.6225 kl_fb 0.0019 kl 0.0806 kl_weight 0.0240 sf 1.1408 reward -0.1044 ll_mean -1.5181 ll_std 1.0000 selected 0.5637 prior_p1 0.4962 avg_p1 0.5097\n",
      "Epoch 7 Iter 2500 loss=2.0765 elbo -1.3586 ll -1.3561 kl_fb 0.0026 kl 0.1021 kl_weight 0.0250 sf -1.9743 reward 0.1574 ll_mean -1.5135 ll_std 1.0000 selected 0.5320 prior_p1 0.5338 avg_p1 0.5109\n",
      "Epoch 7 Iter 2600 loss=1.9492 elbo -1.6447 ll -1.6421 kl_fb 0.0026 kl 0.0992 kl_weight 0.0260 sf 1.5838 reward -0.1345 ll_mean -1.5077 ll_std 1.0000 selected 0.5102 prior_p1 0.5362 avg_p1 0.5102\n",
      "Epoch 7 Iter 2700 loss=2.0261 elbo -2.2592 ll -1.4283 kl_fb 0.8308 kl 30.7717 kl_weight 0.0270 sf -0.7755 reward 0.0747 ll_mean -1.5031 ll_std 1.0000 selected 0.5037 prior_p1 0.0041 avg_p1 0.4970\n",
      "\n",
      "# epoch 7 iter 2728: dev loss -7.4243 elbo -10.9038 ll -1.4516 kl_fb 9.4523 kl 9.4523 kl_weight 1.0000 sf 18.3282 reward -1.4516 ll_mean 0.0000 ll_std 1.0000 selected 0.3422 prior_p1 0.5257 avg_p1 0.4962 acc 0.3542\n",
      " dev0 [gold=3,pred=1]: it 's a lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 8 Iter 2800 loss=1.9372 elbo -1.6241 ll -1.3728 kl_fb 0.2513 kl 8.9752 kl_weight 0.0280 sf -1.6954 reward 0.1277 ll_mean -1.5005 ll_std 1.0000 selected 0.5569 prior_p1 0.8888 avg_p1 0.5024\n",
      "Epoch 8 Iter 2900 loss=1.9308 elbo -1.4613 ll -1.3504 kl_fb 0.1110 kl 3.8271 kl_weight 0.0290 sf -2.1490 reward 0.1469 ll_mean -1.4973 ll_std 1.0000 selected 0.5146 prior_p1 0.2435 avg_p1 0.5202\n",
      "Epoch 8 Iter 3000 loss=1.8981 elbo -1.4688 ll -1.4355 kl_fb 0.0333 kl 1.1105 kl_weight 0.0300 sf -0.8268 reward 0.0613 ll_mean -1.4968 ll_std 1.0000 selected 0.5696 prior_p1 0.6784 avg_p1 0.5224\n",
      "\n",
      "# epoch 8 iter 3069: dev loss -5.8660 elbo -12.2277 ll -1.4331 kl_fb 10.7945 kl 10.7945 kl_weight 1.0000 sf 18.0937 reward -1.4331 ll_mean 0.0000 ll_std 1.0000 selected 0.6633 prior_p1 0.4829 avg_p1 0.5112 acc 0.3697\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here , **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** **in** your veins **.**\n",
      "\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Shuffling training data\n",
      "Epoch 9 Iter 3100 loss=2.0652 elbo -1.5160 ll -1.4730 kl_fb 0.0431 kl 1.3890 kl_weight 0.0310 sf -0.2433 reward 0.0197 ll_mean -1.4926 ll_std 1.0000 selected 0.5107 prior_p1 0.3268 avg_p1 0.5129\n",
      "Epoch 9 Iter 3200 loss=2.2790 elbo -1.4234 ll -1.4184 kl_fb 0.0050 kl 0.1557 kl_weight 0.0320 sf -0.8148 reward 0.0705 ll_mean -1.4889 ll_std 1.0000 selected 0.5157 prior_p1 0.5631 avg_p1 0.5083\n",
      "Epoch 9 Iter 3300 loss=1.9297 elbo -1.5512 ll -1.3559 kl_fb 0.1953 kl 5.9194 kl_weight 0.0330 sf -1.6926 reward 0.1307 ll_mean -1.4866 ll_std 1.0000 selected 0.4861 prior_p1 0.8446 avg_p1 0.5069\n",
      "Epoch 9 Iter 3400 loss=1.9164 elbo -2.0497 ll -1.5620 kl_fb 0.4877 kl 14.3442 kl_weight 0.0340 sf 1.0806 reward -0.0769 ll_mean -1.4851 ll_std 1.0000 selected 0.5671 prior_p1 0.0679 avg_p1 0.5044\n",
      "\n",
      "# epoch 9 iter 3410: dev loss -5.8892 elbo -12.2470 ll -1.4242 kl_fb 10.8228 kl 10.8228 kl_weight 1.0000 sf 18.1362 reward -1.4242 ll_mean 0.0000 ll_std 1.0000 selected 0.5245 prior_p1 0.5637 avg_p1 0.5039 acc 0.3778\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** **is** probably for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 10 Iter 3500 loss=1.7930 elbo -1.6565 ll -1.5037 kl_fb 0.1529 kl 4.3679 kl_weight 0.0350 sf 0.2102 reward -0.0189 ll_mean -1.4847 ll_std 1.0000 selected 0.5199 prior_p1 0.1828 avg_p1 0.5086\n",
      "Epoch 10 Iter 3600 loss=1.8923 elbo -1.4875 ll -1.4726 kl_fb 0.0149 kl 0.4144 kl_weight 0.0360 sf -0.1292 reward 0.0100 ll_mean -1.4825 ll_std 1.0000 selected 0.5170 prior_p1 0.5991 avg_p1 0.5029\n",
      "Epoch 10 Iter 3700 loss=1.6715 elbo -1.6745 ll -1.6709 kl_fb 0.0036 kl 0.0976 kl_weight 0.0370 sf 2.4584 reward -0.1873 ll_mean -1.4836 ll_std 1.0000 selected 0.5640 prior_p1 0.5416 avg_p1 0.5119\n",
      "\n",
      "# epoch 10 iter 3751: dev loss -5.6795 elbo -12.1647 ll -1.4141 kl_fb 10.7506 kl 10.7506 kl_weight 1.0000 sf 17.8442 reward -1.4141 ll_mean 0.0000 ll_std 1.0000 selected 0.7304 prior_p1 0.4953 avg_p1 0.5128 acc 0.3824\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** with lovely performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here , **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** nearly moved **to** tears by **a** couple **of** scenes , you 've got **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 11 Iter 3800 loss=2.1011 elbo -1.6730 ll -1.3034 kl_fb 0.3696 kl 9.7265 kl_weight 0.0380 sf -2.4170 reward 0.1776 ll_mean -1.4810 ll_std 1.0000 selected 0.4628 prior_p1 0.9004 avg_p1 0.5113\n",
      "Epoch 11 Iter 3900 loss=1.9937 elbo -2.4497 ll -1.5379 kl_fb 0.9117 kl 23.3777 kl_weight 0.0390 sf 0.7528 reward -0.0598 ll_mean -1.4782 ll_std 1.0000 selected 0.5167 prior_p1 0.0225 avg_p1 0.5164\n",
      "Epoch 11 Iter 4000 loss=1.6554 elbo -1.4335 ll -1.3836 kl_fb 0.0500 kl 1.2493 kl_weight 0.0400 sf -1.3136 reward 0.0941 ll_mean -1.4776 ll_std 1.0000 selected 0.5404 prior_p1 0.6825 avg_p1 0.5184\n",
      "\n",
      "# epoch 11 iter 4092: dev loss -9.7112 elbo -7.9035 ll -1.4162 kl_fb 6.4873 kl 6.4873 kl_weight 1.0000 sf 17.6147 reward -1.4162 ll_mean 0.0000 ll_std 1.0000 selected 0.8079 prior_p1 0.5975 avg_p1 0.5194 acc 0.3760\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely **film** **with** lovely performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're **not** nearly moved **to** tears by **a** couple **of** scenes **,** you 've got **ice** **water** **in** your veins **.**\n",
      "\n",
      "Epoch 12 Iter 4100 loss=2.0644 elbo -2.1851 ll -1.4700 kl_fb 0.7151 kl 17.4420 kl_weight 0.0410 sf -0.0682 reward 0.0062 ll_mean -1.4761 ll_std 1.0000 selected 0.5284 prior_p1 0.9747 avg_p1 0.5212\n",
      "Shuffling training data\n",
      "Epoch 12 Iter 4200 loss=1.8910 elbo -1.6422 ll -1.3248 kl_fb 0.3173 kl 7.5555 kl_weight 0.0420 sf -2.3022 reward 0.1541 ll_mean -1.4789 ll_std 1.0000 selected 0.5458 prior_p1 0.1574 avg_p1 0.5177\n",
      "Epoch 12 Iter 4300 loss=1.8051 elbo -1.6897 ll -1.3332 kl_fb 0.3565 kl 8.2907 kl_weight 0.0430 sf -2.1152 reward 0.1463 ll_mean -1.4795 ll_std 1.0000 selected 0.5405 prior_p1 0.1447 avg_p1 0.5223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Iter 4400 loss=2.0807 elbo -1.4444 ll -1.3191 kl_fb 0.1253 kl 2.8467 kl_weight 0.0440 sf -2.0775 reward 0.1589 ll_mean -1.4780 ll_std 1.0000 selected 0.4905 prior_p1 0.7648 avg_p1 0.5162\n",
      "\n",
      "# epoch 12 iter 4433: dev loss -5.1760 elbo -12.2947 ll -1.4104 kl_fb 10.8843 kl 10.8843 kl_weight 1.0000 sf 17.4707 reward -1.4104 ll_mean 0.0000 ll_std 1.0000 selected 0.8283 prior_p1 0.5592 avg_p1 0.5219 acc 0.3815\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** **film** **with** **lovely** performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** **probably** **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** **if** you 're **not** nearly moved **to** tears by **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 13 Iter 4500 loss=2.1096 elbo -2.0735 ll -1.3621 kl_fb 0.7115 kl 15.8104 kl_weight 0.0450 sf -1.3192 reward 0.1135 ll_mean -1.4755 ll_std 1.0000 selected 0.5212 prior_p1 0.0433 avg_p1 0.5125\n",
      "Epoch 13 Iter 4600 loss=2.1079 elbo -1.4341 ll -1.4314 kl_fb 0.0027 kl 0.0590 kl_weight 0.0460 sf -0.4652 reward 0.0430 ll_mean -1.4744 ll_std 1.0000 selected 0.5248 prior_p1 0.5275 avg_p1 0.5204\n",
      "Epoch 13 Iter 4700 loss=1.8783 elbo -1.6186 ll -1.4952 kl_fb 0.1234 kl 2.6248 kl_weight 0.0470 sf 0.3066 reward -0.0227 ll_mean -1.4725 ll_std 1.0000 selected 0.5240 prior_p1 0.7563 avg_p1 0.5197\n",
      "\n",
      "# epoch 13 iter 4774: dev loss -8.3352 elbo -8.6870 ll -1.3808 kl_fb 7.3061 kl 7.3061 kl_weight 1.0000 sf 17.0222 reward -1.3808 ll_mean 0.0000 ll_std 1.0000 selected 0.8948 prior_p1 0.5579 avg_p1 0.5243 acc 0.4033\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** **film** **with** **lovely** performances **by** **buy** **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** **probably** **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** **if** **you** 're **not** **nearly** moved **to** tears **by** **a** couple **of** scenes **,** **you** **'ve** **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 14 Iter 4800 loss=2.0476 elbo -1.7512 ll -1.7459 kl_fb 0.0053 kl 0.1109 kl_weight 0.0480 sf 3.4760 reward -0.2730 ll_mean -1.4729 ll_std 1.0000 selected 0.5343 prior_p1 0.4814 avg_p1 0.5195\n",
      "Epoch 14 Iter 4900 loss=1.8647 elbo -1.9855 ll -1.6010 kl_fb 0.3845 kl 7.8466 kl_weight 0.0490 sf 1.5375 reward -0.1261 ll_mean -1.4749 ll_std 1.0000 selected 0.5227 prior_p1 0.1236 avg_p1 0.5114\n",
      "Epoch 14 Iter 5000 loss=1.8659 elbo -1.5058 ll -1.4173 kl_fb 0.0884 kl 1.7687 kl_weight 0.0500 sf -0.7569 reward 0.0570 ll_mean -1.4744 ll_std 1.0000 selected 0.5531 prior_p1 0.7131 avg_p1 0.5122\n",
      "Epoch 14 Iter 5100 loss=2.0408 elbo -1.9080 ll -1.6039 kl_fb 0.3041 kl 5.9634 kl_weight 0.0510 sf 1.7343 reward -0.1288 ll_mean -1.4750 ll_std 1.0000 selected 0.4719 prior_p1 0.1649 avg_p1 0.5032\n",
      "\n",
      "# epoch 14 iter 5115: dev loss -5.7156 elbo -12.5418 ll -1.4180 kl_fb 11.1238 kl 11.1238 kl_weight 1.0000 sf 18.2574 reward -1.4180 ll_mean 0.0000 ll_std 1.0000 selected 0.4783 prior_p1 0.5169 avg_p1 0.5031 acc 0.3815\n",
      " dev0 [gold=3,pred=1]: **it** **'s** a lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 15 Iter 5200 loss=1.9101 elbo -1.6495 ll -1.4233 kl_fb 0.2262 kl 4.3500 kl_weight 0.0520 sf -0.6324 reward 0.0508 ll_mean -1.4741 ll_std 1.0000 selected 0.5103 prior_p1 0.1937 avg_p1 0.5038\n",
      "Epoch 15 Iter 5300 loss=2.3216 elbo -1.5248 ll -1.5037 kl_fb 0.0211 kl 0.3990 kl_weight 0.0530 sf 0.3499 reward -0.0324 ll_mean -1.4712 ll_std 1.0000 selected 0.4920 prior_p1 0.6115 avg_p1 0.5058\n",
      "Epoch 15 Iter 5400 loss=2.1970 elbo -1.7856 ll -1.3757 kl_fb 0.4099 kl 7.5906 kl_weight 0.0540 sf -1.3922 reward 0.0961 ll_mean -1.4718 ll_std 1.0000 selected 0.5256 prior_p1 0.1519 avg_p1 0.5155\n",
      "\n",
      "# epoch 15 iter 5456: dev loss -6.5880 elbo -11.4613 ll -1.4059 kl_fb 10.0554 kl 10.0554 kl_weight 1.0000 sf 18.0493 reward -1.4059 ll_mean 0.0000 ll_std 1.0000 selected 0.7138 prior_p1 0.5359 avg_p1 0.5067 acc 0.3778\n",
      " dev0 [gold=3,pred=0]: **it** **'s** **a** lovely **film** with lovely performances by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** nearly moved **to** tears by **a** couple **of** scenes **,** you 've got **ice** **water** **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 16 Iter 5500 loss=1.7271 elbo -1.5646 ll -1.3934 kl_fb 0.1712 kl 3.1124 kl_weight 0.0550 sf -1.0507 reward 0.0806 ll_mean -1.4740 ll_std 1.0000 selected 0.4872 prior_p1 0.7639 avg_p1 0.5009\n",
      "Epoch 16 Iter 5600 loss=2.0074 elbo -1.8711 ll -1.7562 kl_fb 0.1149 kl 2.0527 kl_weight 0.0560 sf 3.9880 reward -0.2809 ll_mean -1.4753 ll_std 1.0000 selected 0.5200 prior_p1 0.2982 avg_p1 0.5097\n",
      "Epoch 16 Iter 5700 loss=2.3508 elbo -1.5779 ll -1.5112 kl_fb 0.0667 kl 1.1707 kl_weight 0.0570 sf 0.4715 reward -0.0374 ll_mean -1.4738 ll_std 1.0000 selected 0.4784 prior_p1 0.3301 avg_p1 0.5010\n",
      "\n",
      "# epoch 16 iter 5797: dev loss -4.4141 elbo -13.8973 ll -1.4351 kl_fb 12.4622 kl 12.4622 kl_weight 1.0000 sf 18.3115 reward -1.4351 ll_mean 0.0000 ll_std 1.0000 selected 0.2580 prior_p1 0.6005 avg_p1 0.4933 acc 0.3815\n",
      " dev0 [gold=3,pred=1]: it 's a lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 17 Iter 5800 loss=2.3259 elbo -1.8226 ll -1.4379 kl_fb 0.3847 kl 6.6328 kl_weight 0.0580 sf -0.4579 reward 0.0357 ll_mean -1.4736 ll_std 1.0000 selected 0.5111 prior_p1 0.8517 avg_p1 0.4923\n",
      "Shuffling training data\n",
      "Epoch 17 Iter 5900 loss=2.0832 elbo -1.3733 ll -1.3680 kl_fb 0.0053 kl 0.0904 kl_weight 0.0590 sf -1.4672 reward 0.1054 ll_mean -1.4734 ll_std 1.0000 selected 0.4912 prior_p1 0.4577 avg_p1 0.4890\n",
      "Epoch 17 Iter 6000 loss=1.9687 elbo -2.0183 ll -1.4077 kl_fb 0.6106 kl 10.1762 kl_weight 0.0600 sf -0.8795 reward 0.0645 ll_mean -1.4722 ll_std 1.0000 selected 0.4636 prior_p1 0.8929 avg_p1 0.4861\n",
      "Epoch 17 Iter 6100 loss=1.9989 elbo -1.5299 ll -1.4657 kl_fb 0.0643 kl 1.0535 kl_weight 0.0610 sf -0.1290 reward 0.0086 ll_mean -1.4743 ll_std 1.0000 selected 0.5217 prior_p1 0.6422 avg_p1 0.4926\n",
      "\n",
      "# epoch 17 iter 6138: dev loss -8.8494 elbo -9.7517 ll -1.4591 kl_fb 8.2926 kl 8.2926 kl_weight 1.0000 sf 18.6011 reward -1.4591 ll_mean 0.0000 ll_std 1.0000 selected 0.2076 prior_p1 0.5014 avg_p1 0.4910 acc 0.3724\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 18 Iter 6200 loss=2.2951 elbo -1.6109 ll -1.6061 kl_fb 0.0048 kl 0.0767 kl_weight 0.0620 sf 1.5637 reward -0.1334 ll_mean -1.4727 ll_std 1.0000 selected 0.4857 prior_p1 0.4565 avg_p1 0.4908\n",
      "Epoch 18 Iter 6300 loss=2.1631 elbo -1.3421 ll -1.3345 kl_fb 0.0076 kl 0.1202 kl_weight 0.0630 sf -2.0714 reward 0.1396 ll_mean -1.4741 ll_std 1.0000 selected 0.4976 prior_p1 0.5396 avg_p1 0.4985\n",
      "Epoch 18 Iter 6400 loss=2.0151 elbo -1.5975 ll -1.4713 kl_fb 0.1263 kl 1.9728 kl_weight 0.0640 sf -0.0546 reward 0.0043 ll_mean -1.4756 ll_std 1.0000 selected 0.5050 prior_p1 0.2764 avg_p1 0.4932\n",
      "\n",
      "# epoch 18 iter 6479: dev loss -8.7549 elbo -9.8306 ll -1.4588 kl_fb 8.3718 kl 8.3718 kl_weight 1.0000 sf 18.5855 reward -1.4588 ll_mean 0.0000 ll_std 1.0000 selected 0.2013 prior_p1 0.4978 avg_p1 0.4901 acc 0.3669\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 19 Iter 6500 loss=2.2537 elbo -3.7400 ll -1.5289 kl_fb 2.2111 kl 34.0168 kl_weight 0.0650 sf 0.7578 reward -0.0551 ll_mean -1.4738 ll_std 1.0000 selected 0.4726 prior_p1 0.9908 avg_p1 0.4892\n",
      "Epoch 19 Iter 6600 loss=2.4892 elbo -1.9896 ll -1.3776 kl_fb 0.6120 kl 9.2722 kl_weight 0.0660 sf -1.2270 reward 0.0959 ll_mean -1.4735 ll_std 1.0000 selected 0.5122 prior_p1 0.8935 avg_p1 0.4928\n",
      "Epoch 19 Iter 6700 loss=2.3402 elbo -2.9910 ll -1.5508 kl_fb 1.4403 kl 21.4968 kl_weight 0.0670 sf 0.9883 reward -0.0759 ll_mean -1.4749 ll_std 1.0000 selected 0.4866 prior_p1 0.0248 avg_p1 0.4907\n",
      "Epoch 19 Iter 6800 loss=2.2215 elbo -2.0362 ll -1.5903 kl_fb 0.4459 kl 6.5571 kl_weight 0.0680 sf 1.5986 reward -0.1156 ll_mean -1.4748 ll_std 1.0000 selected 0.5129 prior_p1 0.1490 avg_p1 0.4937\n",
      "\n",
      "# epoch 19 iter 6820: dev loss -6.6602 elbo -11.6585 ll -1.4160 kl_fb 10.2425 kl 10.2425 kl_weight 1.0000 sf 18.3187 reward -1.4160 ll_mean 0.0000 ll_std 1.0000 selected 0.3162 prior_p1 0.5109 avg_p1 0.4985 acc 0.3933\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch    19: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Shuffling training data\n",
      "Epoch 20 Iter 6900 loss=2.3770 elbo -1.5816 ll -1.5024 kl_fb 0.0792 kl 1.1473 kl_weight 0.0690 sf 0.3834 reward -0.0293 ll_mean -1.4731 ll_std 1.0000 selected 0.4685 prior_p1 0.6615 avg_p1 0.4958\n",
      "Epoch 20 Iter 7000 loss=2.2750 elbo -2.0156 ll -1.3804 kl_fb 0.6352 kl 9.0743 kl_weight 0.0700 sf -1.0751 reward 0.0917 ll_mean -1.4721 ll_std 1.0000 selected 0.5397 prior_p1 0.9041 avg_p1 0.4996\n",
      "Epoch 20 Iter 7100 loss=2.1611 elbo -2.3138 ll -1.3901 kl_fb 0.9237 kl 13.0099 kl_weight 0.0710 sf -1.1252 reward 0.0798 ll_mean -1.4699 ll_std 1.0000 selected 0.5209 prior_p1 0.9256 avg_p1 0.5052\n",
      "\n",
      "# epoch 20 iter 7161: dev loss -4.0645 elbo -14.0783 ll -1.4037 kl_fb 12.6746 kl 12.6746 kl_weight 1.0000 sf 18.1428 reward -1.4037 ll_mean 0.0000 ll_std 1.0000 selected 0.7231 prior_p1 0.4553 avg_p1 0.5058 acc 0.3924\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** film with **lovely** performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** nearly moved **to** tears by **a** couple **of** scenes **,** you 've **got** **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 21 Iter 7200 loss=2.5198 elbo -1.6141 ll -1.3629 kl_fb 0.2512 kl 3.4889 kl_weight 0.0720 sf -1.4868 reward 0.1070 ll_mean -1.4699 ll_std 1.0000 selected 0.5275 prior_p1 0.2359 avg_p1 0.5053\n",
      "Epoch 21 Iter 7300 loss=2.3627 elbo -1.5277 ll -1.5104 kl_fb 0.0174 kl 0.2377 kl_weight 0.0730 sf 0.5290 reward -0.0414 ll_mean -1.4690 ll_std 1.0000 selected 0.4761 prior_p1 0.5785 avg_p1 0.5058\n",
      "Epoch 21 Iter 7400 loss=2.3873 elbo -2.3485 ll -1.4852 kl_fb 0.8633 kl 11.6657 kl_weight 0.0740 sf 0.2431 reward -0.0184 ll_mean -1.4668 ll_std 1.0000 selected 0.5319 prior_p1 0.9210 avg_p1 0.5021\n",
      "Epoch 21 Iter 7500 loss=2.3066 elbo -2.4121 ll -1.4417 kl_fb 0.9704 kl 12.9381 kl_weight 0.0750 sf -0.2704 reward 0.0243 ll_mean -1.4660 ll_std 1.0000 selected 0.4941 prior_p1 0.9477 avg_p1 0.5028\n",
      "\n",
      "# epoch 21 iter 7502: dev loss -7.2694 elbo -10.8641 ll -1.4006 kl_fb 9.4635 kl 9.4635 kl_weight 1.0000 sf 18.1335 reward -1.4006 ll_mean 0.0000 ll_std 1.0000 selected 0.6662 prior_p1 0.4547 avg_p1 0.5049 acc 0.3860\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** **lovely** film with **lovely** performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** here **,** **which** is probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** nearly moved **to** tears by **a** couple **of** scenes **,** you 've **got** **ice** **water** in your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 22 Iter 7600 loss=1.7815 elbo -1.8636 ll -1.6294 kl_fb 0.2342 kl 3.0813 kl_weight 0.0760 sf 2.1110 reward -0.1620 ll_mean -1.4674 ll_std 1.0000 selected 0.5298 prior_p1 0.7716 avg_p1 0.5130\n",
      "Epoch 22 Iter 7700 loss=2.4236 elbo -2.3516 ll -1.4693 kl_fb 0.8822 kl 11.4575 kl_weight 0.0770 sf 0.0388 reward -0.0033 ll_mean -1.4661 ll_std 1.0000 selected 0.4961 prior_p1 0.9341 avg_p1 0.5127\n",
      "Epoch 22 Iter 7800 loss=2.2038 elbo -2.3591 ll -1.3443 kl_fb 1.0149 kl 13.0111 kl_weight 0.0780 sf -1.6923 reward 0.1229 ll_mean -1.4672 ll_std 1.0000 selected 0.5045 prior_p1 0.0776 avg_p1 0.5104\n",
      "\n",
      "# epoch 22 iter 7843: dev loss -6.2955 elbo -11.5975 ll -1.3987 kl_fb 10.1988 kl 10.1988 kl_weight 1.0000 sf 17.8930 reward -1.3987 ll_mean 0.0000 ll_std 1.0000 selected 0.8011 prior_p1 0.4576 avg_p1 0.5110 acc 0.3869\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** **film** **with** **lovely** performances **by** **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears **by** **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 23 Iter 7900 loss=2.3885 elbo -2.4953 ll -1.4010 kl_fb 1.0942 kl 13.8513 kl_weight 0.0790 sf -0.8208 reward 0.0662 ll_mean -1.4673 ll_std 1.0000 selected 0.4490 prior_p1 0.0607 avg_p1 0.5121\n",
      "Epoch 23 Iter 8000 loss=2.2390 elbo -1.7595 ll -1.6565 kl_fb 0.1030 kl 1.2871 kl_weight 0.0800 sf 2.6261 reward -0.1877 ll_mean -1.4689 ll_std 1.0000 selected 0.4654 prior_p1 0.3365 avg_p1 0.5078\n",
      "Epoch 23 Iter 8100 loss=2.4153 elbo -2.1346 ll -1.7892 kl_fb 0.3454 kl 4.2642 kl_weight 0.0810 sf 4.4667 reward -0.3206 ll_mean -1.4686 ll_std 1.0000 selected 0.5124 prior_p1 0.8006 avg_p1 0.5111\n",
      "\n",
      "# epoch 23 iter 8184: dev loss -4.9772 elbo -12.6627 ll -1.3879 kl_fb 11.2748 kl 11.2748 kl_weight 1.0000 sf 17.6399 reward -1.3879 ll_mean 0.0000 ll_std 1.0000 selected 0.8205 prior_p1 0.4667 avg_p1 0.5140 acc 0.3987\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** **film** **with** **lovely** performances **by** **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if **you** 're **not** **nearly** moved **to** tears **by** **a** couple **of** scenes **,** **you** **'ve** **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Epoch 24 Iter 8200 loss=2.4248 elbo -1.6409 ll -1.3338 kl_fb 0.3072 kl 3.7461 kl_weight 0.0820 sf -1.6524 reward 0.1355 ll_mean -1.4692 ll_std 1.0000 selected 0.4928 prior_p1 0.2199 avg_p1 0.5165\n",
      "Shuffling training data\n",
      "Epoch 24 Iter 8300 loss=2.6228 elbo -1.8403 ll -1.5921 kl_fb 0.2481 kl 2.9894 kl_weight 0.0830 sf 1.8502 reward -0.1240 ll_mean -1.4682 ll_std 1.0000 selected 0.4883 prior_p1 0.7549 avg_p1 0.5121\n",
      "Epoch 24 Iter 8400 loss=2.3578 elbo -1.7620 ll -1.4447 kl_fb 0.3173 kl 3.7769 kl_weight 0.0840 sf -0.3163 reward 0.0247 ll_mean -1.4695 ll_std 1.0000 selected 0.5277 prior_p1 0.2188 avg_p1 0.5096\n",
      "Epoch 24 Iter 8500 loss=2.3422 elbo -5.5206 ll -1.5303 kl_fb 3.9902 kl 46.9440 kl_weight 0.0850 sf 0.7236 reward -0.0602 ll_mean -1.4702 ll_std 1.0000 selected 0.5105 prior_p1 0.0013 avg_p1 0.5114\n",
      "\n",
      "# epoch 24 iter 8525: dev loss -7.9574 elbo -9.5606 ll -1.3795 kl_fb 8.1811 kl 8.1811 kl_weight 1.0000 sf 17.5180 reward -1.3795 ll_mean 0.0000 ll_std 1.0000 selected 0.8266 prior_p1 0.4911 avg_p1 0.5144 acc 0.3887\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** **film** **with** **lovely** performances **by** **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** **if** **you** 're **not** **nearly** moved **to** tears **by** **a** couple **of** scenes **,** **you** **'ve** **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 25 Iter 8600 loss=2.6253 elbo -3.3209 ll -1.3817 kl_fb 1.9392 kl 22.5493 kl_weight 0.0860 sf -1.3445 reward 0.0870 ll_mean -1.4687 ll_std 1.0000 selected 0.5296 prior_p1 0.0375 avg_p1 0.5118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Iter 8700 loss=2.3865 elbo -1.8503 ll -1.3377 kl_fb 0.5126 kl 5.8922 kl_weight 0.0870 sf -1.5905 reward 0.1317 ll_mean -1.4694 ll_std 1.0000 selected 0.5075 prior_p1 0.1580 avg_p1 0.5116\n",
      "Epoch 25 Iter 8800 loss=2.4643 elbo -8.3842 ll -1.4520 kl_fb 6.9322 kl 78.7748 kl_weight 0.0880 sf -0.1934 reward 0.0150 ll_mean -1.4671 ll_std 1.0000 selected 0.5187 prior_p1 0.0001 avg_p1 0.5121\n",
      "\n",
      "# epoch 25 iter 8866: dev loss -2.9886 elbo -14.8390 ll -1.3897 kl_fb 13.4493 kl 13.4493 kl_weight 1.0000 sf 17.8276 reward -1.3897 ll_mean 0.0000 ll_std 1.0000 selected 0.7920 prior_p1 0.4816 avg_p1 0.5103 acc 0.3906\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** film **with** **lovely** performances **by** **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears **by** **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 26 Iter 8900 loss=2.1187 elbo -1.5787 ll -1.5557 kl_fb 0.0230 kl 0.2584 kl_weight 0.0890 sf 1.2395 reward -0.0885 ll_mean -1.4672 ll_std 1.0000 selected 0.5488 prior_p1 0.4360 avg_p1 0.5091\n",
      "Epoch 26 Iter 9000 loss=2.5805 elbo -1.9741 ll -1.3208 kl_fb 0.6533 kl 7.2585 kl_weight 0.0900 sf -2.1553 reward 0.1463 ll_mean -1.4671 ll_std 1.0000 selected 0.5050 prior_p1 0.1567 avg_p1 0.5116\n",
      "Epoch 26 Iter 9100 loss=2.6736 elbo -1.7104 ll -1.5044 kl_fb 0.2059 kl 2.2629 kl_weight 0.0910 sf 0.4721 reward -0.0394 ll_mean -1.4650 ll_std 1.0000 selected 0.5521 prior_p1 0.2679 avg_p1 0.5077\n",
      "Epoch 26 Iter 9200 loss=2.1873 elbo -1.6975 ll -1.4933 kl_fb 0.2041 kl 2.2186 kl_weight 0.0920 sf 0.3338 reward -0.0274 ll_mean -1.4659 ll_std 1.0000 selected 0.5165 prior_p1 0.2754 avg_p1 0.5103\n",
      "\n",
      "# epoch 26 iter 9207: dev loss -4.5785 elbo -13.1242 ll -1.3867 kl_fb 11.7375 kl 11.7375 kl_weight 1.0000 sf 17.7027 reward -1.3867 ll_mean 0.0000 ll_std 1.0000 selected 0.8551 prior_p1 0.4651 avg_p1 0.5126 acc 0.4015\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** film **with** **lovely** performances **by** **buy** **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears **by** **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 27 Iter 9300 loss=2.2814 elbo -1.4298 ll -1.4021 kl_fb 0.0277 kl 0.2982 kl_weight 0.0930 sf -0.9266 reward 0.0659 ll_mean -1.4680 ll_std 1.0000 selected 0.5015 prior_p1 0.5959 avg_p1 0.5162\n",
      "Epoch 27 Iter 9400 loss=2.2558 elbo -1.5823 ll -1.5441 kl_fb 0.0382 kl 0.4065 kl_weight 0.0940 sf 0.9167 reward -0.0757 ll_mean -1.4684 ll_std 1.0000 selected 0.4933 prior_p1 0.6156 avg_p1 0.5140\n",
      "Epoch 27 Iter 9500 loss=2.3402 elbo -1.6838 ll -1.3674 kl_fb 0.3163 kl 3.3297 kl_weight 0.0950 sf -1.2678 reward 0.1005 ll_mean -1.4679 ll_std 1.0000 selected 0.5279 prior_p1 0.7841 avg_p1 0.5113\n",
      "\n",
      "# epoch 27 iter 9548: dev loss -7.0969 elbo -10.5867 ll -1.3820 kl_fb 9.2047 kl 9.2047 kl_weight 1.0000 sf 17.6836 reward -1.3820 ll_mean 0.0000 ll_std 1.0000 selected 0.8133 prior_p1 0.4490 avg_p1 0.5118 acc 0.3987\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** **film** **with** **lovely** performances **by** **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears **by** **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 28 Iter 9600 loss=2.7517 elbo -1.7026 ll -1.3852 kl_fb 0.3174 kl 3.3063 kl_weight 0.0960 sf -0.8938 reward 0.0810 ll_mean -1.4662 ll_std 1.0000 selected 0.4878 prior_p1 0.2188 avg_p1 0.5105\n",
      "Epoch 28 Iter 9700 loss=2.7488 elbo -3.1428 ll -1.4591 kl_fb 1.6838 kl 17.3584 kl_weight 0.0970 sf -0.0744 reward 0.0059 ll_mean -1.4649 ll_std 1.0000 selected 0.5211 prior_p1 0.0429 avg_p1 0.5128\n",
      "Epoch 28 Iter 9800 loss=2.4900 elbo -2.8306 ll -1.4703 kl_fb 1.3603 kl 13.8807 kl_weight 0.0980 sf 0.0552 reward -0.0042 ll_mean -1.4661 ll_std 1.0000 selected 0.5595 prior_p1 0.9421 avg_p1 0.5112\n",
      "\n",
      "# epoch 28 iter 9889: dev loss -6.8341 elbo -11.0508 ll -1.3887 kl_fb 9.6621 kl 9.6621 kl_weight 1.0000 sf 17.8849 reward -1.3887 ll_mean 0.0000 ll_std 1.0000 selected 0.7849 prior_p1 0.5192 avg_p1 0.5091 acc 0.3987\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** film **with** **lovely** performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Epoch 29 Iter 9900 loss=2.5545 elbo -4.0458 ll -1.4718 kl_fb 2.5740 kl 26.0002 kl_weight 0.0990 sf 0.0899 reward -0.0067 ll_mean -1.4651 ll_std 1.0000 selected 0.5097 prior_p1 0.0186 avg_p1 0.5072\n",
      "Shuffling training data\n",
      "Epoch 29 Iter 10000 loss=2.6750 elbo -1.5618 ll -1.4706 kl_fb 0.0912 kl 0.9119 kl_weight 0.1000 sf 0.1026 reward -0.0079 ll_mean -1.4627 ll_std 1.0000 selected 0.4741 prior_p1 0.6591 avg_p1 0.5100\n",
      "Epoch 29 Iter 10100 loss=2.4987 elbo -3.1873 ll -1.5016 kl_fb 1.6857 kl 16.6904 kl_weight 0.1010 sf 0.5265 reward -0.0366 ll_mean -1.4650 ll_std 1.0000 selected 0.4679 prior_p1 0.9489 avg_p1 0.5055\n",
      "Epoch 29 Iter 10200 loss=2.5902 elbo -1.6254 ll -1.3523 kl_fb 0.2730 kl 2.6767 kl_weight 0.1020 sf -1.5130 reward 0.1106 ll_mean -1.4629 ll_std 1.0000 selected 0.5174 prior_p1 0.2612 avg_p1 0.5044\n",
      "\n",
      "# epoch 29 iter 10230: dev loss -11.1529 elbo -6.8624 ll -1.3885 kl_fb 5.4740 kl 5.4740 kl_weight 1.0000 sf 18.0153 reward -1.3885 ll_mean 0.0000 ll_std 1.0000 selected 0.7292 prior_p1 0.5238 avg_p1 0.5055 acc 0.4015\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** **lovely** film with **lovely** performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 30 Iter 10300 loss=2.5873 elbo -5.0551 ll -1.4992 kl_fb 3.5560 kl 34.5238 kl_weight 0.1030 sf 0.4957 reward -0.0372 ll_mean -1.4620 ll_std 1.0000 selected 0.5468 prior_p1 0.0074 avg_p1 0.5038\n",
      "Epoch 30 Iter 10400 loss=2.1984 elbo -1.6707 ll -1.3889 kl_fb 0.2818 kl 2.7100 kl_weight 0.1040 sf -1.1011 reward 0.0733 ll_mean -1.4621 ll_std 1.0000 selected 0.4799 prior_p1 0.7350 avg_p1 0.5015\n",
      "Epoch 30 Iter 10500 loss=2.4665 elbo -1.5692 ll -1.4220 kl_fb 0.1473 kl 1.4025 kl_weight 0.1050 sf -0.5437 reward 0.0404 ll_mean -1.4624 ll_std 1.0000 selected 0.4870 prior_p1 0.6813 avg_p1 0.4999\n",
      "\n",
      "# epoch 30 iter 10571: dev loss -8.8445 elbo -9.1168 ll -1.3828 kl_fb 7.7340 kl 7.7340 kl_weight 1.0000 sf 17.9613 reward -1.3828 ll_mean 0.0000 ll_std 1.0000 selected 0.7688 prior_p1 0.4911 avg_p1 0.5053 acc 0.3996\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** **lovely** film with **lovely** performances by **buy** **and** **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Epoch 31 Iter 10600 loss=2.7343 elbo -2.1149 ll -1.2032 kl_fb 0.9116 kl 8.6003 kl_weight 0.1060 sf -3.3519 reward 0.2594 ll_mean -1.4626 ll_std 1.0000 selected 0.4992 prior_p1 0.1156 avg_p1 0.5048\n",
      "Shuffling training data\n",
      "Epoch 31 Iter 10700 loss=2.6009 elbo -3.2753 ll -1.3764 kl_fb 1.8989 kl 17.7470 kl_weight 0.1070 sf -1.1536 reward 0.0874 ll_mean -1.4638 ll_std 1.0000 selected 0.4753 prior_p1 0.9600 avg_p1 0.5008\n",
      "Epoch 31 Iter 10800 loss=2.6326 elbo -1.9240 ll -1.4743 kl_fb 0.4497 kl 4.1638 kl_weight 0.1080 sf 0.1474 reward -0.0111 ll_mean -1.4632 ll_std 1.0000 selected 0.4995 prior_p1 0.2046 avg_p1 0.5005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Iter 10900 loss=2.4430 elbo -5.0897 ll -1.4887 kl_fb 3.6010 kl 33.0369 kl_weight 0.1090 sf 0.3278 reward -0.0254 ll_mean -1.4633 ll_std 1.0000 selected 0.5185 prior_p1 0.0075 avg_p1 0.5005\n",
      "\n",
      "# epoch 31 iter 10912: dev loss -8.6559 elbo -9.6850 ll -1.4050 kl_fb 8.2800 kl 8.2800 kl_weight 1.0000 sf 18.3409 reward -1.4050 ll_mean 0.0000 ll_std 1.0000 selected 0.3923 prior_p1 0.5389 avg_p1 0.5002 acc 0.3987\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved **to** tears by **a** couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 32 Iter 11000 loss=2.1783 elbo -1.3947 ll -1.3790 kl_fb 0.0156 kl 0.1422 kl_weight 0.1100 sf -1.1954 reward 0.0860 ll_mean -1.4651 ll_std 1.0000 selected 0.5294 prior_p1 0.4474 avg_p1 0.5007\n",
      "Epoch 32 Iter 11100 loss=2.5279 elbo -2.2421 ll -1.5624 kl_fb 0.6797 kl 6.1233 kl_weight 0.1110 sf 1.0652 reward -0.0971 ll_mean -1.4653 ll_std 1.0000 selected 0.4623 prior_p1 0.1348 avg_p1 0.4996\n",
      "Epoch 32 Iter 11200 loss=2.2956 elbo -1.5607 ll -1.5356 kl_fb 0.0251 kl 0.2244 kl_weight 0.1120 sf 0.8919 reward -0.0679 ll_mean -1.4677 ll_std 1.0000 selected 0.4792 prior_p1 0.4283 avg_p1 0.4990\n",
      "\n",
      "# epoch 32 iter 11253: dev loss -3.5321 elbo -14.9033 ll -1.4146 kl_fb 13.4887 kl 13.4887 kl_weight 1.0000 sf 18.4355 reward -1.4146 ll_mean 0.0000 ll_std 1.0000 selected 0.3054 prior_p1 0.4736 avg_p1 0.4979 acc 0.3960\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 33 Iter 11300 loss=2.4362 elbo -1.7132 ll -1.4344 kl_fb 0.2788 kl 2.4672 kl_weight 0.1130 sf -0.4408 reward 0.0347 ll_mean -1.4691 ll_std 1.0000 selected 0.5037 prior_p1 0.2548 avg_p1 0.4962\n",
      "Epoch 33 Iter 11400 loss=2.6092 elbo -1.4606 ll -1.4192 kl_fb 0.0415 kl 0.3638 kl_weight 0.1140 sf -0.5540 reward 0.0483 ll_mean -1.4674 ll_std 1.0000 selected 0.4606 prior_p1 0.5959 avg_p1 0.4954\n",
      "Epoch 33 Iter 11500 loss=2.7923 elbo -3.6609 ll -1.3384 kl_fb 2.3225 kl 20.1960 kl_weight 0.1150 sf -1.7772 reward 0.1290 ll_mean -1.4674 ll_std 1.0000 selected 0.4974 prior_p1 0.9652 avg_p1 0.4979\n",
      "\n",
      "# epoch 33 iter 11594: dev loss -3.7953 elbo -14.6632 ll -1.4153 kl_fb 13.2480 kl 13.2480 kl_weight 1.0000 sf 18.4585 reward -1.4153 ll_mean 0.0000 ll_std 1.0000 selected 0.3110 prior_p1 0.5828 avg_p1 0.4982 acc 0.3978\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 34 Iter 11600 loss=2.7717 elbo -2.3402 ll -1.3020 kl_fb 1.0381 kl 8.9495 kl_weight 0.1160 sf -2.4402 reward 0.1665 ll_mean -1.4685 ll_std 1.0000 selected 0.5098 prior_p1 0.1231 avg_p1 0.4992\n",
      "Shuffling training data\n",
      "Epoch 34 Iter 11700 loss=2.5215 elbo -1.6796 ll -1.3982 kl_fb 0.2813 kl 2.4045 kl_weight 0.1170 sf -0.9526 reward 0.0706 ll_mean -1.4689 ll_std 1.0000 selected 0.4788 prior_p1 0.7356 avg_p1 0.5031\n",
      "Epoch 34 Iter 11800 loss=2.9782 elbo -1.5569 ll -1.4888 kl_fb 0.0681 kl 0.5774 kl_weight 0.1180 sf 0.2818 reward -0.0202 ll_mean -1.4687 ll_std 1.0000 selected 0.4920 prior_p1 0.6177 avg_p1 0.5026\n",
      "Epoch 34 Iter 11900 loss=2.7392 elbo -3.2348 ll -1.4845 kl_fb 1.7502 kl 14.7078 kl_weight 0.1190 sf 0.1853 reward -0.0138 ll_mean -1.4708 ll_std 1.0000 selected 0.5425 prior_p1 0.9419 avg_p1 0.5021\n",
      "\n",
      "# epoch 34 iter 11935: dev loss -7.2868 elbo -10.7953 ll -1.3902 kl_fb 9.4051 kl 9.4051 kl_weight 1.0000 sf 18.0821 reward -1.3902 ll_mean 0.0000 ll_std 1.0000 selected 0.7200 prior_p1 0.4431 avg_p1 0.5046 acc 0.3806\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** **lovely** film with **lovely** performances by **buy** **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** **is** probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by **a** couple **of** scenes **,** you 've **got** **ice** **water** **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 35 Iter 12000 loss=2.5237 elbo -1.6530 ll -1.4971 kl_fb 0.1559 kl 1.2993 kl_weight 0.1200 sf 0.4068 reward -0.0276 ll_mean -1.4695 ll_std 1.0000 selected 0.4555 prior_p1 0.6707 avg_p1 0.5034\n",
      "Epoch 35 Iter 12100 loss=2.5701 elbo -1.4612 ll -1.4431 kl_fb 0.0181 kl 0.1499 kl_weight 0.1210 sf -0.3632 reward 0.0277 ll_mean -1.4708 ll_std 1.0000 selected 0.4728 prior_p1 0.4469 avg_p1 0.5039\n",
      "Epoch 35 Iter 12200 loss=2.9861 elbo -1.9861 ll -1.6331 kl_fb 0.3530 kl 2.8936 kl_weight 0.1220 sf 2.1438 reward -0.1632 ll_mean -1.4699 ll_std 1.0000 selected 0.5205 prior_p1 0.2457 avg_p1 0.5014\n",
      "\n",
      "# epoch 35 iter 12276: dev loss -6.6922 elbo -11.6457 ll -1.4035 kl_fb 10.2422 kl 10.2422 kl_weight 1.0000 sf 18.3379 reward -1.4035 ll_mean 0.0000 ll_std 1.0000 selected 0.4345 prior_p1 0.4969 avg_p1 0.5004 acc 0.3969\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by **a** couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch    35: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 36 Iter 12300 loss=2.8595 elbo -2.0315 ll -1.4340 kl_fb 0.5975 kl 4.8576 kl_weight 0.1230 sf -0.4439 reward 0.0343 ll_mean -1.4683 ll_std 1.0000 selected 0.4523 prior_p1 0.8191 avg_p1 0.5023\n",
      "Shuffling training data\n",
      "Epoch 36 Iter 12400 loss=2.8650 elbo -1.9546 ll -1.5734 kl_fb 0.3812 kl 3.0744 kl_weight 0.1240 sf 1.5540 reward -0.1064 ll_mean -1.4670 ll_std 1.0000 selected 0.4728 prior_p1 0.2479 avg_p1 0.4977\n",
      "Epoch 36 Iter 12500 loss=2.7493 elbo -1.4666 ll -1.3920 kl_fb 0.0746 kl 0.5966 kl_weight 0.1250 sf -1.0297 reward 0.0763 ll_mean -1.4684 ll_std 1.0000 selected 0.5118 prior_p1 0.3774 avg_p1 0.4971\n",
      "Epoch 36 Iter 12600 loss=3.2137 elbo -1.7060 ll -1.3275 kl_fb 0.3785 kl 3.0038 kl_weight 0.1260 sf -2.0428 reward 0.1403 ll_mean -1.4678 ll_std 1.0000 selected 0.4631 prior_p1 0.7439 avg_p1 0.4948\n",
      "\n",
      "# epoch 36 iter 12617: dev loss -4.6687 elbo -13.9894 ll -1.4334 kl_fb 12.5559 kl 12.5559 kl_weight 1.0000 sf 18.6581 reward -1.4334 ll_mean 0.0000 ll_std 1.0000 selected 0.2778 prior_p1 0.4770 avg_p1 0.4960 acc 0.3824\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 37 Iter 12700 loss=2.6275 elbo -4.2887 ll -1.5068 kl_fb 2.7819 kl 21.9046 kl_weight 0.1270 sf 0.4633 reward -0.0389 ll_mean -1.4679 ll_std 1.0000 selected 0.4798 prior_p1 0.9794 avg_p1 0.4949\n",
      "Epoch 37 Iter 12800 loss=2.8326 elbo -1.4253 ll -1.3871 kl_fb 0.0382 kl 0.2982 kl_weight 0.1280 sf -1.1375 reward 0.0822 ll_mean -1.4693 ll_std 1.0000 selected 0.5083 prior_p1 0.5768 avg_p1 0.4951\n",
      "Epoch 37 Iter 12900 loss=2.6758 elbo -1.4330 ll -1.4290 kl_fb 0.0040 kl 0.0311 kl_weight 0.1290 sf -0.4510 reward 0.0372 ll_mean -1.4662 ll_std 1.0000 selected 0.5173 prior_p1 0.5065 avg_p1 0.4962\n",
      "\n",
      "# epoch 37 iter 12958: dev loss -10.2819 elbo -8.7228 ll -1.4694 kl_fb 7.2534 kl 7.2534 kl_weight 1.0000 sf 19.0048 reward -1.4694 ll_mean 0.0000 ll_std 1.0000 selected 0.1967 prior_p1 0.5078 avg_p1 0.4929 acc 0.3569\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 38 Iter 13000 loss=2.7358 elbo -1.4680 ll -1.3794 kl_fb 0.0886 kl 0.6819 kl_weight 0.1300 sf -1.3301 reward 0.0882 ll_mean -1.4676 ll_std 1.0000 selected 0.5025 prior_p1 0.6155 avg_p1 0.4944\n",
      "Epoch 38 Iter 13100 loss=2.4792 elbo -3.8651 ll -1.4529 kl_fb 2.4122 kl 18.4134 kl_weight 0.1310 sf -0.2189 reward 0.0145 ll_mean -1.4674 ll_std 1.0000 selected 0.4579 prior_p1 0.9492 avg_p1 0.4934\n",
      "Epoch 38 Iter 13200 loss=2.9621 elbo -1.6334 ll -1.4051 kl_fb 0.2283 kl 1.7295 kl_weight 0.1320 sf -0.9717 reward 0.0630 ll_mean -1.4682 ll_std 1.0000 selected 0.5027 prior_p1 0.6818 avg_p1 0.4933\n",
      "\n",
      "# epoch 38 iter 13299: dev loss -12.7194 elbo -6.3585 ll -1.4818 kl_fb 4.8767 kl 4.8767 kl_weight 1.0000 sf 19.0779 reward -1.4818 ll_mean 0.0000 ll_std 1.0000 selected 0.1641 prior_p1 0.4150 avg_p1 0.4908 acc 0.3497\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 39 Iter 13300 loss=2.9102 elbo -6.9807 ll -1.4943 kl_fb 5.4864 kl 41.2509 kl_weight 0.1330 sf 0.2960 reward -0.0256 ll_mean -1.4687 ll_std 1.0000 selected 0.4871 prior_p1 0.0016 avg_p1 0.4910\n",
      "Shuffling training data\n",
      "Epoch 39 Iter 13400 loss=2.9452 elbo -1.4784 ll -1.4678 kl_fb 0.0106 kl 0.0792 kl_weight 0.1340 sf -0.0114 reward 0.0008 ll_mean -1.4686 ll_std 1.0000 selected 0.5506 prior_p1 0.5284 avg_p1 0.4935\n",
      "Epoch 39 Iter 13500 loss=3.0775 elbo -3.4988 ll -1.6407 kl_fb 1.8581 kl 13.7639 kl_weight 0.1350 sf 2.9760 reward -0.1756 ll_mean -1.4652 ll_std 1.0000 selected 0.4585 prior_p1 0.0865 avg_p1 0.4948\n",
      "Epoch 39 Iter 13600 loss=2.5684 elbo -2.3411 ll -1.3871 kl_fb 0.9541 kl 7.0152 kl_weight 0.1360 sf -0.8923 reward 0.0779 ll_mean -1.4650 ll_std 1.0000 selected 0.4972 prior_p1 0.8742 avg_p1 0.4944\n",
      "\n",
      "# epoch 39 iter 13640: dev loss -6.0148 elbo -13.0150 ll -1.4724 kl_fb 11.5426 kl 11.5426 kl_weight 1.0000 sf 19.0298 reward -1.4724 ll_mean 0.0000 ll_std 1.0000 selected 0.1818 prior_p1 0.4517 avg_p1 0.4924 acc 0.3524\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 40 Iter 13700 loss=2.9200 elbo -1.7617 ll -1.4768 kl_fb 0.2849 kl 2.0797 kl_weight 0.1370 sf 0.1612 reward -0.0123 ll_mean -1.4645 ll_std 1.0000 selected 0.4902 prior_p1 0.2733 avg_p1 0.4929\n",
      "Epoch 40 Iter 13800 loss=2.7396 elbo -3.1802 ll -1.4942 kl_fb 1.6860 kl 12.2175 kl_weight 0.1380 sf 0.3106 reward -0.0282 ll_mean -1.4660 ll_std 1.0000 selected 0.5208 prior_p1 0.0536 avg_p1 0.4898\n",
      "Epoch 40 Iter 13900 loss=3.0860 elbo -1.5218 ll -1.4628 kl_fb 0.0590 kl 0.4242 kl_weight 0.1390 sf -0.0628 reward 0.0045 ll_mean -1.4673 ll_std 1.0000 selected 0.4708 prior_p1 0.5900 avg_p1 0.4907\n",
      "\n",
      "# epoch 40 iter 13981: dev loss -5.5649 elbo -13.5171 ll -1.4777 kl_fb 12.0393 kl 12.0393 kl_weight 1.0000 sf 19.0820 reward -1.4777 ll_mean 0.0000 ll_std 1.0000 selected 0.1720 prior_p1 0.5750 avg_p1 0.4918 acc 0.3479\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 41 Iter 14000 loss=3.1896 elbo -4.6273 ll -1.3438 kl_fb 3.2835 kl 23.4534 kl_weight 0.1400 sf -1.7867 reward 0.1220 ll_mean -1.4659 ll_std 1.0000 selected 0.4900 prior_p1 0.9701 avg_p1 0.4907\n",
      "Shuffling training data\n",
      "Epoch 41 Iter 14100 loss=3.0998 elbo -3.1941 ll -1.5352 kl_fb 1.6589 kl 11.7651 kl_weight 0.1410 sf 1.0072 reward -0.0708 ll_mean -1.4644 ll_std 1.0000 selected 0.4654 prior_p1 0.0832 avg_p1 0.4904\n",
      "Epoch 41 Iter 14200 loss=2.6952 elbo -1.6196 ll -1.3091 kl_fb 0.3105 kl 2.1864 kl_weight 0.1420 sf -2.0064 reward 0.1543 ll_mean -1.4634 ll_std 1.0000 selected 0.4795 prior_p1 0.2658 avg_p1 0.4911\n",
      "Epoch 41 Iter 14300 loss=2.7439 elbo -1.7222 ll -1.3646 kl_fb 0.3576 kl 2.5006 kl_weight 0.1430 sf -1.2316 reward 0.0987 ll_mean -1.4633 ll_std 1.0000 selected 0.5531 prior_p1 0.7389 avg_p1 0.4936\n",
      "\n",
      "# epoch 41 iter 14322: dev loss -5.6675 elbo -13.4631 ll -1.4794 kl_fb 11.9838 kl 11.9838 kl_weight 1.0000 sf 19.1307 reward -1.4794 ll_mean 0.0000 ll_std 1.0000 selected 0.1774 prior_p1 0.4915 avg_p1 0.4922 acc 0.3488\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 42 Iter 14400 loss=3.2927 elbo -4.0370 ll -1.4486 kl_fb 2.5883 kl 17.9746 kl_weight 0.1440 sf -0.2065 reward 0.0140 ll_mean -1.4627 ll_std 1.0000 selected 0.5186 prior_p1 0.9496 avg_p1 0.4933\n",
      "Epoch 42 Iter 14500 loss=3.0858 elbo -1.4270 ll -1.4128 kl_fb 0.0142 kl 0.0979 kl_weight 0.1450 sf -0.7934 reward 0.0517 ll_mean -1.4646 ll_std 1.0000 selected 0.5090 prior_p1 0.5313 avg_p1 0.4920\n",
      "Epoch 42 Iter 14600 loss=2.7937 elbo -1.6258 ll -1.4352 kl_fb 0.1906 kl 1.3057 kl_weight 0.1460 sf -0.3632 reward 0.0308 ll_mean -1.4659 ll_std 1.0000 selected 0.4812 prior_p1 0.3036 avg_p1 0.4897\n",
      "\n",
      "# epoch 42 iter 14663: dev loss -2.8564 elbo -16.3364 ll -1.4917 kl_fb 14.8447 kl 14.8447 kl_weight 1.0000 sf 19.1928 reward -1.4917 ll_mean 0.0000 ll_std 1.0000 selected 0.1465 prior_p1 0.5775 avg_p1 0.4900 acc 0.3397\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 43 Iter 14700 loss=3.2391 elbo -10.8905 ll -1.2531 kl_fb 9.6375 kl 65.5611 kl_weight 0.1470 sf -3.2199 reward 0.2128 ll_mean -1.4659 ll_std 1.0000 selected 0.4892 prior_p1 0.9993 avg_p1 0.4909\n",
      "Shuffling training data\n",
      "Epoch 43 Iter 14800 loss=2.6956 elbo -1.7634 ll -1.2714 kl_fb 0.4921 kl 3.3249 kl_weight 0.1480 sf -2.8165 reward 0.1920 ll_mean -1.4634 ll_std 1.0000 selected 0.5172 prior_p1 0.2342 avg_p1 0.4916\n",
      "Epoch 43 Iter 14900 loss=2.7583 elbo -2.2274 ll -1.4569 kl_fb 0.7705 kl 5.1712 kl_weight 0.1490 sf -0.0935 reward 0.0068 ll_mean -1.4637 ll_std 1.0000 selected 0.4839 prior_p1 0.1765 avg_p1 0.4912\n",
      "Epoch 43 Iter 15000 loss=2.9370 elbo -1.4788 ll -1.4691 kl_fb 0.0097 kl 0.0644 kl_weight 0.1500 sf 0.0650 reward -0.0058 ll_mean -1.4633 ll_std 1.0000 selected 0.4995 prior_p1 0.4539 avg_p1 0.4911\n",
      "\n",
      "# epoch 43 iter 15004: dev loss -6.5874 elbo -12.6065 ll -1.4815 kl_fb 11.1250 kl 11.1250 kl_weight 1.0000 sf 19.1939 reward -1.4815 ll_mean 0.0000 ll_std 1.0000 selected 0.1793 prior_p1 0.4733 avg_p1 0.4928 acc 0.3488\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 44 Iter 15100 loss=3.0464 elbo -1.7504 ll -1.5860 kl_fb 0.1644 kl 1.0886 kl_weight 0.1510 sf 1.2832 reward -0.1221 ll_mean -1.4639 ll_std 1.0000 selected 0.4643 prior_p1 0.3098 avg_p1 0.4900\n",
      "Epoch 44 Iter 15200 loss=3.1603 elbo -1.5028 ll -1.3580 kl_fb 0.1448 kl 0.9529 kl_weight 0.1520 sf -1.4653 reward 0.1047 ll_mean -1.4627 ll_std 1.0000 selected 0.5286 prior_p1 0.6423 avg_p1 0.4937\n",
      "Epoch 44 Iter 15300 loss=2.7935 elbo -2.3212 ll -1.5092 kl_fb 0.8120 kl 5.3072 kl_weight 0.1530 sf 0.5307 reward -0.0449 ll_mean -1.4643 ll_std 1.0000 selected 0.4919 prior_p1 0.1560 avg_p1 0.4925\n",
      "\n",
      "# epoch 44 iter 15345: dev loss -9.2859 elbo -9.7924 ll -1.4684 kl_fb 8.3239 kl 8.3239 kl_weight 1.0000 sf 19.0783 reward -1.4684 ll_mean 0.0000 ll_std 1.0000 selected 0.2009 prior_p1 0.5608 avg_p1 0.4941 acc 0.3624\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 45 Iter 15400 loss=3.6265 elbo -1.7954 ll -1.2784 kl_fb 0.5170 kl 3.3571 kl_weight 0.1540 sf -2.4823 reward 0.1864 ll_mean -1.4648 ll_std 1.0000 selected 0.4972 prior_p1 0.2248 avg_p1 0.4935\n",
      "Epoch 45 Iter 15500 loss=3.1655 elbo -4.0851 ll -1.3799 kl_fb 2.7052 kl 17.4527 kl_weight 0.1550 sf -0.9733 reward 0.0844 ll_mean -1.4644 ll_std 1.0000 selected 0.4423 prior_p1 0.9664 avg_p1 0.4928\n",
      "Epoch 45 Iter 15600 loss=3.0056 elbo -1.5232 ll -1.5145 kl_fb 0.0087 kl 0.0559 kl_weight 0.1560 sf 0.6944 reward -0.0508 ll_mean -1.4637 ll_std 1.0000 selected 0.4636 prior_p1 0.4648 avg_p1 0.4934\n",
      "\n",
      "# epoch 45 iter 15686: dev loss -7.6600 elbo -11.4069 ll -1.4661 kl_fb 9.9409 kl 9.9409 kl_weight 1.0000 sf 19.0669 reward -1.4661 ll_mean 0.0000 ll_std 1.0000 selected 0.2033 prior_p1 0.3942 avg_p1 0.4946 acc 0.3533\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 46 Iter 15700 loss=3.0815 elbo -3.0277 ll -1.5798 kl_fb 1.4479 kl 9.2221 kl_weight 0.1570 sf 1.9494 reward -0.1172 ll_mean -1.4626 ll_std 1.0000 selected 0.5365 prior_p1 0.1325 avg_p1 0.4958\n",
      "Shuffling training data\n",
      "Epoch 46 Iter 15800 loss=3.6590 elbo -2.4626 ll -1.3848 kl_fb 1.0778 kl 6.8215 kl_weight 0.1580 sf -0.9565 reward 0.0787 ll_mean -1.4635 ll_std 1.0000 selected 0.5039 prior_p1 0.1294 avg_p1 0.4945\n",
      "Epoch 46 Iter 15900 loss=2.9149 elbo -1.7435 ll -1.3961 kl_fb 0.3474 kl 2.1847 kl_weight 0.1590 sf -0.7867 reward 0.0682 ll_mean -1.4643 ll_std 1.0000 selected 0.5385 prior_p1 0.2552 avg_p1 0.4945\n",
      "Epoch 46 Iter 16000 loss=3.4532 elbo -1.6026 ll -1.4698 kl_fb 0.1328 kl 0.8299 kl_weight 0.1600 sf 0.0700 reward -0.0057 ll_mean -1.4640 ll_std 1.0000 selected 0.4472 prior_p1 0.3458 avg_p1 0.4934\n",
      "\n",
      "# epoch 46 iter 16027: dev loss -9.4209 elbo -9.6815 ll -1.4704 kl_fb 8.2111 kl 8.2111 kl_weight 1.0000 sf 19.1024 reward -1.4704 ll_mean 0.0000 ll_std 1.0000 selected 0.1942 prior_p1 0.4576 avg_p1 0.4940 acc 0.3479\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch    46: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Shuffling training data\n",
      "Epoch 47 Iter 16100 loss=3.0691 elbo -1.5373 ll -1.5288 kl_fb 0.0086 kl 0.0534 kl_weight 0.1610 sf 0.8117 reward -0.0655 ll_mean -1.4632 ll_std 1.0000 selected 0.5170 prior_p1 0.4634 avg_p1 0.4945\n",
      "Epoch 47 Iter 16200 loss=3.4345 elbo -1.6424 ll -1.4619 kl_fb 0.1805 kl 1.1142 kl_weight 0.1620 sf -0.0535 reward 0.0034 ll_mean -1.4653 ll_std 1.0000 selected 0.4681 prior_p1 0.6453 avg_p1 0.4947\n",
      "Epoch 47 Iter 16300 loss=3.6807 elbo -1.8071 ll -1.2513 kl_fb 0.5558 kl 3.4098 kl_weight 0.1630 sf -2.9320 reward 0.2099 ll_mean -1.4613 ll_std 1.0000 selected 0.4721 prior_p1 0.2275 avg_p1 0.4933\n",
      "\n",
      "# epoch 47 iter 16368: dev loss -8.0645 elbo -11.0501 ll -1.4717 kl_fb 9.5784 kl 9.5784 kl_weight 1.0000 sf 19.1145 reward -1.4717 ll_mean 0.0000 ll_std 1.0000 selected 0.1892 prior_p1 0.5475 avg_p1 0.4938 acc 0.3479\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 48 Iter 16400 loss=2.9803 elbo -1.8346 ll -1.4875 kl_fb 0.3471 kl 2.1165 kl_weight 0.1640 sf 0.2971 reward -0.0241 ll_mean -1.4634 ll_std 1.0000 selected 0.5211 prior_p1 0.7260 avg_p1 0.4975\n",
      "Shuffling training data\n",
      "Epoch 48 Iter 16500 loss=3.3749 elbo -2.2589 ll -1.5744 kl_fb 0.6846 kl 4.1490 kl_weight 0.1650 sf 1.6593 reward -0.1109 ll_mean -1.4634 ll_std 1.0000 selected 0.4719 prior_p1 0.2136 avg_p1 0.4942\n",
      "Epoch 48 Iter 16600 loss=3.2230 elbo -3.3755 ll -1.4001 kl_fb 1.9754 kl 11.9002 kl_weight 0.1660 sf -0.8151 reward 0.0622 ll_mean -1.4623 ll_std 1.0000 selected 0.5321 prior_p1 0.0748 avg_p1 0.4942\n",
      "Epoch 48 Iter 16700 loss=3.1530 elbo -1.3589 ll -1.3558 kl_fb 0.0031 kl 0.0186 kl_weight 0.1670 sf -1.3286 reward 0.1067 ll_mean -1.4625 ll_std 1.0000 selected 0.4832 prior_p1 0.4912 avg_p1 0.4942\n",
      "\n",
      "# epoch 48 iter 16709: dev loss -6.9075 elbo -12.1423 ll -1.4645 kl_fb 10.6778 kl 10.6778 kl_weight 1.0000 sf 19.0498 reward -1.4645 ll_mean 0.0000 ll_std 1.0000 selected 0.2045 prior_p1 0.4749 avg_p1 0.4945 acc 0.3615\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 49 Iter 16800 loss=2.7954 elbo -1.5720 ll -1.5624 kl_fb 0.0096 kl 0.0574 kl_weight 0.1680 sf 1.4030 reward -0.1008 ll_mean -1.4616 ll_std 1.0000 selected 0.4718 prior_p1 0.4682 avg_p1 0.4967\n",
      "Epoch 49 Iter 16900 loss=3.6043 elbo -4.2369 ll -1.4553 kl_fb 2.7815 kl 16.4587 kl_weight 0.1690 sf -0.0423 reward 0.0041 ll_mean -1.4594 ll_std 1.0000 selected 0.5097 prior_p1 0.0276 avg_p1 0.4951\n",
      "Epoch 49 Iter 17000 loss=3.3808 elbo -1.3881 ll -1.2633 kl_fb 0.1248 kl 0.7341 kl_weight 0.1700 sf -2.9777 reward 0.1973 ll_mean -1.4606 ll_std 1.0000 selected 0.5159 prior_p1 0.3706 avg_p1 0.4960\n",
      "\n",
      "# epoch 49 iter 17050: dev loss -11.8822 elbo -7.0774 ll -1.4529 kl_fb 5.6245 kl 5.6245 kl_weight 1.0000 sf 18.9596 reward -1.4529 ll_mean 0.0000 ll_std 1.0000 selected 0.2310 prior_p1 0.4517 avg_p1 0.4959 acc 0.3588\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 50 Iter 17100 loss=3.3157 elbo -3.5404 ll -1.3500 kl_fb 2.1904 kl 12.8092 kl_weight 0.1710 sf -1.5067 reward 0.1093 ll_mean -1.4593 ll_std 1.0000 selected 0.5405 prior_p1 0.9233 avg_p1 0.4965\n",
      "Shuffling training data\n",
      "Epoch 50 Iter 17200 loss=3.9048 elbo -4.2489 ll -1.4037 kl_fb 2.8452 kl 16.5416 kl_weight 0.1720 sf -0.7122 reward 0.0528 ll_mean -1.4565 ll_std 1.0000 selected 0.5084 prior_p1 0.9503 avg_p1 0.4949\n",
      "Epoch 50 Iter 17300 loss=3.1272 elbo -1.6402 ll -1.3930 kl_fb 0.2472 kl 1.4288 kl_weight 0.1730 sf -0.8187 reward 0.0665 ll_mean -1.4596 ll_std 1.0000 selected 0.4942 prior_p1 0.6863 avg_p1 0.4941\n",
      "\n",
      "# epoch 50 iter 17391: dev loss -8.3080 elbo -10.5903 ll -1.4458 kl_fb 9.1445 kl 9.1445 kl_weight 1.0000 sf 18.8983 reward -1.4458 ll_mean 0.0000 ll_std 1.0000 selected 0.2568 prior_p1 0.4531 avg_p1 0.4966 acc 0.3651\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 51 Iter 17400 loss=3.0036 elbo -2.4423 ll -1.3744 kl_fb 1.0679 kl 6.1373 kl_weight 0.1740 sf -1.0147 reward 0.0849 ll_mean -1.4593 ll_std 1.0000 selected 0.4949 prior_p1 0.8554 avg_p1 0.4987\n",
      "Shuffling training data\n",
      "Epoch 51 Iter 17500 loss=4.4773 elbo -9.0556 ll -1.4003 kl_fb 7.6553 kl 43.7445 kl_weight 0.1750 sf -0.6565 reward 0.0580 ll_mean -1.4583 ll_std 1.0000 selected 0.4720 prior_p1 0.0012 avg_p1 0.4977\n",
      "Epoch 51 Iter 17600 loss=3.4948 elbo -2.1183 ll -1.3217 kl_fb 0.7965 kl 4.5258 kl_weight 0.1760 sf -1.6920 reward 0.1365 ll_mean -1.4582 ll_std 1.0000 selected 0.4989 prior_p1 0.8111 avg_p1 0.4952\n",
      "Epoch 51 Iter 17700 loss=3.0512 elbo -7.1056 ll -1.5310 kl_fb 5.5746 kl 31.4951 kl_weight 0.1770 sf 0.9939 reward -0.0717 ll_mean -1.4593 ll_std 1.0000 selected 0.4725 prior_p1 0.0106 avg_p1 0.4961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 51 iter 17732: dev loss -7.0009 elbo -11.9418 ll -1.4546 kl_fb 10.4871 kl 10.4871 kl_weight 1.0000 sf 18.9426 reward -1.4546 ll_mean 0.0000 ll_std 1.0000 selected 0.2147 prior_p1 0.5016 avg_p1 0.4950 acc 0.3615\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 52 Iter 17800 loss=3.3032 elbo -8.3631 ll -1.6030 kl_fb 6.7601 kl 37.9783 kl_weight 0.1780 sf 2.2548 reward -0.1427 ll_mean -1.4602 ll_std 1.0000 selected 0.5024 prior_p1 0.0085 avg_p1 0.4949\n",
      "Epoch 52 Iter 17900 loss=3.4659 elbo -1.4911 ll -1.4421 kl_fb 0.0490 kl 0.2737 kl_weight 0.1790 sf -0.2574 reward 0.0197 ll_mean -1.4617 ll_std 1.0000 selected 0.5141 prior_p1 0.4143 avg_p1 0.4954\n",
      "Epoch 52 Iter 18000 loss=3.3646 elbo -11.8719 ll -1.5105 kl_fb 10.3615 kl 57.5637 kl_weight 0.1800 sf 0.6753 reward -0.0501 ll_mean -1.4603 ll_std 1.0000 selected 0.5206 prior_p1 0.9993 avg_p1 0.4959\n",
      "\n",
      "# epoch 52 iter 18073: dev loss -10.0064 elbo -8.9145 ll -1.4529 kl_fb 7.4616 kl 7.4616 kl_weight 1.0000 sf 18.9209 reward -1.4529 ll_mean 0.0000 ll_std 1.0000 selected 0.2131 prior_p1 0.5138 avg_p1 0.4950 acc 0.3642\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 53 Iter 18100 loss=3.2469 elbo -1.7595 ll -1.4925 kl_fb 0.2671 kl 1.4754 kl_weight 0.1810 sf 0.3523 reward -0.0297 ll_mean -1.4628 ll_std 1.0000 selected 0.5055 prior_p1 0.2954 avg_p1 0.4922\n",
      "Shuffling training data\n",
      "Epoch 53 Iter 18200 loss=3.5749 elbo -6.0172 ll -1.5219 kl_fb 4.4953 kl 24.6994 kl_weight 0.1820 sf 0.7793 reward -0.0578 ll_mean -1.4641 ll_std 1.0000 selected 0.4733 prior_p1 0.9789 avg_p1 0.4942\n",
      "Epoch 53 Iter 18300 loss=3.6625 elbo -3.0023 ll -1.3222 kl_fb 1.6801 kl 9.1809 kl_weight 0.1830 sf -1.9820 reward 0.1409 ll_mean -1.4632 ll_std 1.0000 selected 0.4669 prior_p1 0.8811 avg_p1 0.4925\n",
      "Epoch 53 Iter 18400 loss=3.1520 elbo -2.4115 ll -1.3528 kl_fb 1.0587 kl 5.7538 kl_weight 0.1840 sf -1.3162 reward 0.1089 ll_mean -1.4617 ll_std 1.0000 selected 0.5189 prior_p1 0.1482 avg_p1 0.4934\n",
      "\n",
      "# epoch 53 iter 18414: dev loss -4.7287 elbo -14.3772 ll -1.4701 kl_fb 12.9071 kl 12.9071 kl_weight 1.0000 sf 19.1059 reward -1.4701 ll_mean 0.0000 ll_std 1.0000 selected 0.1856 prior_p1 0.5568 avg_p1 0.4940 acc 0.3442\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 54 Iter 18500 loss=3.0439 elbo -2.1882 ll -1.5166 kl_fb 0.6716 kl 3.6305 kl_weight 0.1850 sf 0.6423 reward -0.0530 ll_mean -1.4636 ll_std 1.0000 selected 0.5286 prior_p1 0.2040 avg_p1 0.4943\n",
      "Epoch 54 Iter 18600 loss=3.5211 elbo -2.0990 ll -1.4398 kl_fb 0.6592 kl 3.5442 kl_weight 0.1860 sf -0.2879 reward 0.0239 ll_mean -1.4637 ll_std 1.0000 selected 0.5037 prior_p1 0.7854 avg_p1 0.4956\n",
      "Epoch 54 Iter 18700 loss=3.0445 elbo -9.0852 ll -1.7231 kl_fb 7.3621 kl 39.3698 kl_weight 0.1870 sf 3.6232 reward -0.2591 ll_mean -1.4640 ll_std 1.0000 selected 0.5043 prior_p1 0.0048 avg_p1 0.4948\n",
      "\n",
      "# epoch 54 iter 18755: dev loss -4.3809 elbo -14.6315 ll -1.4605 kl_fb 13.1710 kl 13.1710 kl_weight 1.0000 sf 19.0124 reward -1.4605 ll_mean 0.0000 ll_std 1.0000 selected 0.2042 prior_p1 0.5706 avg_p1 0.4948 acc 0.3624\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 55 Iter 18800 loss=3.2491 elbo -3.3789 ll -1.4196 kl_fb 1.9594 kl 10.4221 kl_weight 0.1880 sf -0.5306 reward 0.0437 ll_mean -1.4632 ll_std 1.0000 selected 0.4678 prior_p1 0.0829 avg_p1 0.4977\n",
      "Shuffling training data\n",
      "Epoch 55 Iter 18900 loss=3.6210 elbo -7.1727 ll -1.4430 kl_fb 5.7297 kl 30.3159 kl_weight 0.1890 sf -0.2638 reward 0.0199 ll_mean -1.4628 ll_std 1.0000 selected 0.4857 prior_p1 0.0102 avg_p1 0.4952\n",
      "Epoch 55 Iter 19000 loss=3.8423 elbo -1.7421 ll -1.4067 kl_fb 0.3354 kl 1.7652 kl_weight 0.1900 sf -0.7054 reward 0.0561 ll_mean -1.4628 ll_std 1.0000 selected 0.5240 prior_p1 0.2874 avg_p1 0.4952\n",
      "\n",
      "# epoch 55 iter 19096: dev loss -5.9870 elbo -12.9407 ll -1.4501 kl_fb 11.4906 kl 11.4906 kl_weight 1.0000 sf 18.9277 reward -1.4501 ll_mean 0.0000 ll_std 1.0000 selected 0.2310 prior_p1 0.4818 avg_p1 0.4959 acc 0.3606\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 56 Iter 19100 loss=3.7723 elbo -2.3784 ll -1.5877 kl_fb 0.7908 kl 4.1401 kl_weight 0.1910 sf 1.5530 reward -0.1262 ll_mean -1.4615 ll_std 1.0000 selected 0.4990 prior_p1 0.1931 avg_p1 0.4969\n",
      "Shuffling training data\n",
      "Epoch 56 Iter 19200 loss=3.2114 elbo -2.2840 ll -1.3384 kl_fb 0.9455 kl 4.9247 kl_weight 0.1920 sf -1.6918 reward 0.1242 ll_mean -1.4626 ll_std 1.0000 selected 0.5328 prior_p1 0.8105 avg_p1 0.4963\n",
      "Epoch 56 Iter 19300 loss=4.2787 elbo -2.2394 ll -1.4763 kl_fb 0.7632 kl 3.9543 kl_weight 0.1930 sf 0.2028 reward -0.0151 ll_mean -1.4611 ll_std 1.0000 selected 0.5144 prior_p1 0.2096 avg_p1 0.4974\n",
      "Epoch 56 Iter 19400 loss=3.7827 elbo -1.9537 ll -1.4565 kl_fb 0.4971 kl 2.5625 kl_weight 0.1940 sf -0.0736 reward 0.0061 ll_mean -1.4627 ll_std 1.0000 selected 0.5504 prior_p1 0.7517 avg_p1 0.4991\n",
      "\n",
      "# epoch 56 iter 19437: dev loss -5.0219 elbo -13.7572 ll -1.4333 kl_fb 12.3240 kl 12.3240 kl_weight 1.0000 sf 18.7791 reward -1.4333 ll_mean 0.0000 ll_std 1.0000 selected 0.2814 prior_p1 0.5324 avg_p1 0.4978 acc 0.3806\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 57 Iter 19500 loss=3.3554 elbo -2.6636 ll -1.5663 kl_fb 1.0973 kl 5.6271 kl_weight 0.1950 sf 1.6315 reward -0.1050 ll_mean -1.4613 ll_std 1.0000 selected 0.4541 prior_p1 0.8125 avg_p1 0.4985\n",
      "Epoch 57 Iter 19600 loss=3.3353 elbo -1.8250 ll -1.4048 kl_fb 0.4202 kl 2.1437 kl_weight 0.1960 sf -0.8755 reward 0.0587 ll_mean -1.4635 ll_std 1.0000 selected 0.4956 prior_p1 0.7087 avg_p1 0.4969\n",
      "Epoch 57 Iter 19700 loss=3.2156 elbo -3.9746 ll -1.5897 kl_fb 2.3849 kl 12.1063 kl_weight 0.1970 sf 1.9251 reward -0.1273 ll_mean -1.4623 ll_std 1.0000 selected 0.4867 prior_p1 0.0896 avg_p1 0.4976\n",
      "\n",
      "# epoch 57 iter 19778: dev loss -7.5341 elbo -11.4200 ll -1.4523 kl_fb 9.9677 kl 9.9677 kl_weight 1.0000 sf 18.9541 reward -1.4523 ll_mean 0.0000 ll_std 1.0000 selected 0.2271 prior_p1 0.4941 avg_p1 0.4957 acc 0.3597\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 58 Iter 19800 loss=3.2363 elbo -2.9143 ll -1.5283 kl_fb 1.3860 kl 7.0001 kl_weight 0.1980 sf 0.7731 reward -0.0652 ll_mean -1.4631 ll_std 1.0000 selected 0.5208 prior_p1 0.8708 avg_p1 0.4965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 58 Iter 19900 loss=3.9244 elbo -3.3866 ll -1.2496 kl_fb 2.1370 kl 10.7387 kl_weight 0.1990 sf -3.1588 reward 0.2119 ll_mean -1.4615 ll_std 1.0000 selected 0.5031 prior_p1 0.1023 avg_p1 0.4988\n",
      "Epoch 58 Iter 20000 loss=3.6962 elbo -3.0833 ll -1.4653 kl_fb 1.6180 kl 8.0900 kl_weight 0.2000 sf 0.0349 reward -0.0028 ll_mean -1.4625 ll_std 1.0000 selected 0.4652 prior_p1 0.1125 avg_p1 0.4954\n",
      "Epoch 58 Iter 20100 loss=4.0284 elbo -5.1969 ll -1.4279 kl_fb 3.7690 kl 18.7514 kl_weight 0.2010 sf -0.4458 reward 0.0362 ll_mean -1.4641 ll_std 1.0000 selected 0.4769 prior_p1 0.0309 avg_p1 0.4962\n",
      "\n",
      "# epoch 58 iter 20119: dev loss -7.6156 elbo -11.3154 ll -1.4492 kl_fb 9.8662 kl 9.8662 kl_weight 1.0000 sf 18.9310 reward -1.4492 ll_mean 0.0000 ll_std 1.0000 selected 0.2319 prior_p1 0.4824 avg_p1 0.4961 acc 0.3633\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 59 Iter 20200 loss=3.7612 elbo -1.5828 ll -1.5132 kl_fb 0.0696 kl 0.3445 kl_weight 0.2020 sf 0.6672 reward -0.0496 ll_mean -1.4637 ll_std 1.0000 selected 0.4842 prior_p1 0.4052 avg_p1 0.4955\n",
      "Epoch 59 Iter 20300 loss=3.5951 elbo -19.4535 ll -1.4373 kl_fb 18.0161 kl 88.7495 kl_weight 0.2030 sf -0.3313 reward 0.0275 ll_mean -1.4649 ll_std 1.0000 selected 0.4558 prior_p1 0.0000 avg_p1 0.4967\n",
      "Epoch 59 Iter 20400 loss=3.5097 elbo -3.5859 ll -1.5610 kl_fb 2.0249 kl 9.9260 kl_weight 0.2040 sf 1.3523 reward -0.0960 ll_mean -1.4650 ll_std 1.0000 selected 0.5177 prior_p1 0.1051 avg_p1 0.4989\n",
      "\n",
      "# epoch 59 iter 20460: dev loss -5.9001 elbo -13.0111 ll -1.4457 kl_fb 11.5654 kl 11.5654 kl_weight 1.0000 sf 18.9112 reward -1.4457 ll_mean 0.0000 ll_std 1.0000 selected 0.2464 prior_p1 0.5032 avg_p1 0.4969 acc 0.3678\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 60 Iter 20500 loss=3.7502 elbo -5.3610 ll -1.5531 kl_fb 3.8079 kl 18.5751 kl_weight 0.2050 sf 1.2547 reward -0.0861 ll_mean -1.4670 ll_std 1.0000 selected 0.5032 prior_p1 0.9536 avg_p1 0.4965\n",
      "Shuffling training data\n",
      "Epoch 60 Iter 20600 loss=4.0194 elbo -3.6945 ll -1.3926 kl_fb 2.3018 kl 11.1739 kl_weight 0.2060 sf -1.0743 reward 0.0713 ll_mean -1.4639 ll_std 1.0000 selected 0.5007 prior_p1 0.8984 avg_p1 0.4955\n",
      "Epoch 60 Iter 20700 loss=3.8555 elbo -5.1395 ll -1.5162 kl_fb 3.6233 kl 17.5038 kl_weight 0.2070 sf 0.7573 reward -0.0511 ll_mean -1.4651 ll_std 1.0000 selected 0.4760 prior_p1 0.9477 avg_p1 0.4978\n",
      "Epoch 60 Iter 20800 loss=2.9313 elbo -1.3872 ll -1.3651 kl_fb 0.0221 kl 0.1062 kl_weight 0.2080 sf -1.3463 reward 0.1011 ll_mean -1.4662 ll_std 1.0000 selected 0.4825 prior_p1 0.5432 avg_p1 0.4965\n",
      "\n",
      "# epoch 60 iter 20801: dev loss -8.9692 elbo -9.9653 ll -1.4476 kl_fb 8.5177 kl 8.5177 kl_weight 1.0000 sf 18.9345 reward -1.4476 ll_mean 0.0000 ll_std 1.0000 selected 0.2481 prior_p1 0.4990 avg_p1 0.4967 acc 0.3678\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 61 Iter 20900 loss=4.4029 elbo -1.6659 ll -1.5474 kl_fb 0.1186 kl 0.5672 kl_weight 0.2090 sf 1.1882 reward -0.0793 ll_mean -1.4681 ll_std 1.0000 selected 0.5039 prior_p1 0.3859 avg_p1 0.4966\n",
      "Epoch 61 Iter 21000 loss=3.4192 elbo -2.5492 ll -1.3428 kl_fb 1.2065 kl 5.7450 kl_weight 0.2100 sf -1.7208 reward 0.1249 ll_mean -1.4677 ll_std 1.0000 selected 0.5525 prior_p1 0.8291 avg_p1 0.4971\n",
      "Epoch 61 Iter 21100 loss=3.3766 elbo -10.7435 ll -1.4514 kl_fb 9.2921 kl 44.0383 kl_weight 0.2110 sf -0.2305 reward 0.0162 ll_mean -1.4676 ll_std 1.0000 selected 0.5098 prior_p1 0.0033 avg_p1 0.4961\n",
      "\n",
      "# epoch 61 iter 21142: dev loss -2.6939 elbo -16.2392 ll -1.4494 kl_fb 14.7897 kl 14.7897 kl_weight 1.0000 sf 18.9330 reward -1.4494 ll_mean 0.0000 ll_std 1.0000 selected 0.2303 prior_p1 0.5399 avg_p1 0.4961 acc 0.3688\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 62 Iter 21200 loss=3.2114 elbo -3.6226 ll -1.4567 kl_fb 2.1659 kl 10.2167 kl_weight 0.2120 sf -0.1507 reward 0.0116 ll_mean -1.4683 ll_std 1.0000 selected 0.4831 prior_p1 0.9049 avg_p1 0.4959\n",
      "Shuffling training data\n",
      "Epoch 62 Iter 21300 loss=3.7044 elbo -6.5636 ll -1.6192 kl_fb 4.9445 kl 23.2135 kl_weight 0.2130 sf 2.0261 reward -0.1518 ll_mean -1.4673 ll_std 1.0000 selected 0.4952 prior_p1 0.9761 avg_p1 0.4953\n",
      "Epoch 62 Iter 21400 loss=3.8854 elbo -1.6301 ll -1.6246 kl_fb 0.0055 kl 0.0255 kl_weight 0.2140 sf 2.0192 reward -0.1592 ll_mean -1.4654 ll_std 1.0000 selected 0.5253 prior_p1 0.5101 avg_p1 0.4967\n",
      "\n",
      "# epoch 62 iter 21483: dev loss -10.2306 elbo -8.7066 ll -1.4484 kl_fb 7.2582 kl 7.2582 kl_weight 1.0000 sf 18.9372 reward -1.4484 ll_mean 0.0000 ll_std 1.0000 selected 0.2368 prior_p1 0.5523 avg_p1 0.4964 acc 0.3688\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 63 Iter 21500 loss=4.1159 elbo -13.1145 ll -1.5205 kl_fb 11.5940 kl 53.9256 kl_weight 0.2150 sf 0.7286 reward -0.0562 ll_mean -1.4642 ll_std 1.0000 selected 0.4922 prior_p1 0.9992 avg_p1 0.4987\n",
      "Shuffling training data\n",
      "Epoch 63 Iter 21600 loss=3.5689 elbo -3.0646 ll -1.3117 kl_fb 1.7529 kl 8.1152 kl_weight 0.2160 sf -1.9489 reward 0.1535 ll_mean -1.4652 ll_std 1.0000 selected 0.4708 prior_p1 0.8824 avg_p1 0.4993\n",
      "Epoch 63 Iter 21700 loss=3.7894 elbo -1.4497 ll -1.4394 kl_fb 0.0103 kl 0.0473 kl_weight 0.2170 sf -0.3675 reward 0.0249 ll_mean -1.4643 ll_std 1.0000 selected 0.4695 prior_p1 0.4706 avg_p1 0.4942\n",
      "Epoch 63 Iter 21800 loss=3.6020 elbo -1.5131 ll -1.4991 kl_fb 0.0139 kl 0.0639 kl_weight 0.2180 sf 0.4837 reward -0.0376 ll_mean -1.4615 ll_std 1.0000 selected 0.4685 prior_p1 0.5307 avg_p1 0.4954\n",
      "\n",
      "# epoch 63 iter 21824: dev loss -4.9524 elbo -14.1313 ll -1.4638 kl_fb 12.6676 kl 12.6676 kl_weight 1.0000 sf 19.0838 reward -1.4638 ll_mean 0.0000 ll_std 1.0000 selected 0.2069 prior_p1 0.5750 avg_p1 0.4950 acc 0.3551\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 64 Iter 21900 loss=3.9105 elbo -2.9846 ll -1.3233 kl_fb 1.6614 kl 7.5861 kl_weight 0.2190 sf -1.8357 reward 0.1372 ll_mean -1.4605 ll_std 1.0000 selected 0.5092 prior_p1 0.8644 avg_p1 0.4936\n",
      "Epoch 64 Iter 22000 loss=3.8891 elbo -3.1494 ll -1.5169 kl_fb 1.6325 kl 7.4205 kl_weight 0.2200 sf 0.6643 reward -0.0568 ll_mean -1.4601 ll_std 1.0000 selected 0.4545 prior_p1 0.1148 avg_p1 0.4943\n",
      "Epoch 64 Iter 22100 loss=4.2732 elbo -4.2255 ll -1.4979 kl_fb 2.7276 kl 12.3419 kl_weight 0.2210 sf 0.5013 reward -0.0390 ll_mean -1.4589 ll_std 1.0000 selected 0.5097 prior_p1 0.9260 avg_p1 0.4946\n",
      "\n",
      "# epoch 64 iter 22165: dev loss -8.4951 elbo -10.7311 ll -1.4776 kl_fb 9.2535 kl 9.2535 kl_weight 1.0000 sf 19.2262 reward -1.4776 ll_mean 0.0000 ll_std 1.0000 selected 0.1820 prior_p1 0.4194 avg_p1 0.4941 acc 0.3388\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Iter 22200 loss=4.2729 elbo -5.4005 ll -1.6258 kl_fb 3.7747 kl 17.0030 kl_weight 0.2220 sf 2.2262 reward -0.1674 ll_mean -1.4584 ll_std 1.0000 selected 0.4981 prior_p1 0.9527 avg_p1 0.4920\n",
      "Shuffling training data\n",
      "Epoch 65 Iter 22300 loss=3.8027 elbo -1.5324 ll -1.4424 kl_fb 0.0900 kl 0.4036 kl_weight 0.2230 sf -0.2098 reward 0.0173 ll_mean -1.4597 ll_std 1.0000 selected 0.4258 prior_p1 0.5970 avg_p1 0.4933\n",
      "Epoch 65 Iter 22400 loss=3.7849 elbo -1.5863 ll -1.5708 kl_fb 0.0155 kl 0.0690 kl_weight 0.2240 sf 1.3019 reward -0.1100 ll_mean -1.4608 ll_std 1.0000 selected 0.4689 prior_p1 0.5322 avg_p1 0.4938\n",
      "Epoch 65 Iter 22500 loss=3.7627 elbo -1.9441 ll -1.4450 kl_fb 0.4991 kl 2.2182 kl_weight 0.2250 sf -0.2055 reward 0.0149 ll_mean -1.4599 ll_std 1.0000 selected 0.5183 prior_p1 0.7171 avg_p1 0.4938\n",
      "\n",
      "# epoch 65 iter 22506: dev loss -6.4991 elbo -12.6782 ll -1.4734 kl_fb 11.2049 kl 11.2049 kl_weight 1.0000 sf 19.1773 reward -1.4734 ll_mean 0.0000 ll_std 1.0000 selected 0.1819 prior_p1 0.5992 avg_p1 0.4942 acc 0.3460\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 66 Iter 22600 loss=4.1418 elbo -1.7638 ll -1.5263 kl_fb 0.2375 kl 1.0507 kl_weight 0.2260 sf 0.7963 reward -0.0676 ll_mean -1.4587 ll_std 1.0000 selected 0.5139 prior_p1 0.3282 avg_p1 0.4969\n",
      "Epoch 66 Iter 22700 loss=3.7944 elbo -2.9430 ll -1.3432 kl_fb 1.5998 kl 7.0475 kl_weight 0.2270 sf -1.7087 reward 0.1168 ll_mean -1.4600 ll_std 1.0000 selected 0.4650 prior_p1 0.8451 avg_p1 0.4950\n",
      "Epoch 66 Iter 22800 loss=4.5931 elbo -2.7867 ll -1.3249 kl_fb 1.4618 kl 6.4113 kl_weight 0.2280 sf -1.6993 reward 0.1350 ll_mean -1.4599 ll_std 1.0000 selected 0.5104 prior_p1 0.1434 avg_p1 0.4976\n",
      "\n",
      "# epoch 66 iter 22847: dev loss -6.7599 elbo -12.2883 ll -1.4588 kl_fb 10.8294 kl 10.8294 kl_weight 1.0000 sf 19.0481 reward -1.4588 ll_mean 0.0000 ll_std 1.0000 selected 0.2164 prior_p1 0.4549 avg_p1 0.4956 acc 0.3669\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 67 Iter 22900 loss=2.9387 elbo -1.5020 ll -1.2885 kl_fb 0.2135 kl 0.9325 kl_weight 0.2290 sf -2.3449 reward 0.1724 ll_mean -1.4609 ll_std 1.0000 selected 0.5415 prior_p1 0.3468 avg_p1 0.4954\n",
      "Shuffling training data\n",
      "Epoch 67 Iter 23000 loss=3.7547 elbo -1.5418 ll -1.4726 kl_fb 0.0693 kl 0.3011 kl_weight 0.2300 sf 0.1389 reward -0.0098 ll_mean -1.4627 ll_std 1.0000 selected 0.5058 prior_p1 0.5792 avg_p1 0.4970\n",
      "Epoch 67 Iter 23100 loss=3.5846 elbo -2.4874 ll -1.3701 kl_fb 1.1173 kl 4.8368 kl_weight 0.2310 sf -1.1366 reward 0.0930 ll_mean -1.4631 ll_std 1.0000 selected 0.5022 prior_p1 0.1718 avg_p1 0.4945\n",
      "\n",
      "# epoch 67 iter 23188: dev loss -7.8921 elbo -11.1777 ll -1.4619 kl_fb 9.7157 kl 9.7157 kl_weight 1.0000 sf 19.0698 reward -1.4619 ll_mean 0.0000 ll_std 1.0000 selected 0.2051 prior_p1 0.4221 avg_p1 0.4951 acc 0.3597\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 68 Iter 23200 loss=3.9477 elbo -1.4378 ll -1.4298 kl_fb 0.0080 kl 0.0343 kl_weight 0.2320 sf -0.3970 reward 0.0354 ll_mean -1.4652 ll_std 1.0000 selected 0.4606 prior_p1 0.5198 avg_p1 0.4965\n",
      "Shuffling training data\n",
      "Epoch 68 Iter 23300 loss=3.8627 elbo -8.2027 ll -1.3225 kl_fb 6.8802 kl 29.5286 kl_weight 0.2330 sf -1.8948 reward 0.1416 ll_mean -1.4642 ll_std 1.0000 selected 0.5194 prior_p1 0.9876 avg_p1 0.4946\n",
      "Epoch 68 Iter 23400 loss=3.6816 elbo -1.7486 ll -1.4539 kl_fb 0.2948 kl 1.2596 kl_weight 0.2340 sf -0.1691 reward 0.0116 ll_mean -1.4655 ll_std 1.0000 selected 0.4649 prior_p1 0.6600 avg_p1 0.4931\n",
      "Epoch 68 Iter 23500 loss=4.4191 elbo -7.1312 ll -1.5297 kl_fb 5.6015 kl 23.8361 kl_weight 0.2350 sf 0.8920 reward -0.0636 ll_mean -1.4661 ll_std 1.0000 selected 0.4886 prior_p1 0.0233 avg_p1 0.4928\n",
      "\n",
      "# epoch 68 iter 23529: dev loss -8.7279 elbo -10.5439 ll -1.4806 kl_fb 9.0633 kl 9.0633 kl_weight 1.0000 sf 19.2718 reward -1.4806 ll_mean 0.0000 ll_std 1.0000 selected 0.1793 prior_p1 0.4956 avg_p1 0.4941 acc 0.3415\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 69 Iter 23600 loss=4.3575 elbo -3.8547 ll -1.5768 kl_fb 2.2778 kl 9.6519 kl_weight 0.2360 sf 1.5072 reward -0.1103 ll_mean -1.4666 ll_std 1.0000 selected 0.5113 prior_p1 0.8911 avg_p1 0.4927\n",
      "Epoch 69 Iter 23700 loss=4.0486 elbo -8.7350 ll -1.6020 kl_fb 7.1330 kl 30.0969 kl_weight 0.2370 sf 1.8230 reward -0.1362 ll_mean -1.4658 ll_std 1.0000 selected 0.4809 prior_p1 0.0105 avg_p1 0.4923\n",
      "Epoch 69 Iter 23800 loss=4.1183 elbo -3.0576 ll -1.6271 kl_fb 1.4305 kl 6.0105 kl_weight 0.2380 sf 2.5174 reward -0.1613 ll_mean -1.4658 ll_std 1.0000 selected 0.5196 prior_p1 0.1755 avg_p1 0.4957\n",
      "\n",
      "# epoch 69 iter 23870: dev loss -5.5370 elbo -13.7322 ll -1.4807 kl_fb 12.2514 kl 12.2514 kl_weight 1.0000 sf 19.2692 reward -1.4807 ll_mean 0.0000 ll_std 1.0000 selected 0.1761 prior_p1 0.4469 avg_p1 0.4939 acc 0.3379\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 70 Iter 23900 loss=3.7616 elbo -5.3789 ll -1.7484 kl_fb 3.6306 kl 15.1907 kl_weight 0.2390 sf 3.4159 reward -0.2837 ll_mean -1.4646 ll_std 1.0000 selected 0.4955 prior_p1 0.0440 avg_p1 0.4940\n",
      "Shuffling training data\n",
      "Epoch 70 Iter 24000 loss=3.6368 elbo -2.0130 ll -1.5176 kl_fb 0.4954 kl 2.0640 kl_weight 0.2400 sf 0.8059 reward -0.0518 ll_mean -1.4658 ll_std 1.0000 selected 0.4921 prior_p1 0.6980 avg_p1 0.4931\n",
      "Epoch 70 Iter 24100 loss=4.0559 elbo -1.5061 ll -1.3232 kl_fb 0.1829 kl 0.7588 kl_weight 0.2410 sf -1.8714 reward 0.1412 ll_mean -1.4644 ll_std 1.0000 selected 0.4855 prior_p1 0.6302 avg_p1 0.4934\n",
      "Epoch 70 Iter 24200 loss=3.6973 elbo -3.6538 ll -1.4355 kl_fb 2.2183 kl 9.1667 kl_weight 0.2420 sf -0.3338 reward 0.0259 ll_mean -1.4614 ll_std 1.0000 selected 0.5070 prior_p1 0.1017 avg_p1 0.4941\n",
      "\n",
      "# epoch 70 iter 24211: dev loss -12.6352 elbo -6.5585 ll -1.4740 kl_fb 5.0845 kl 5.0845 kl_weight 1.0000 sf 19.1936 reward -1.4740 ll_mean 0.0000 ll_std 1.0000 selected 0.1833 prior_p1 0.4877 avg_p1 0.4943 acc 0.3433\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 71 Iter 24300 loss=4.2914 elbo -4.9162 ll -1.5246 kl_fb 3.3916 kl 13.9572 kl_weight 0.2430 sf 0.6249 reward -0.0618 ll_mean -1.4629 ll_std 1.0000 selected 0.4430 prior_p1 0.0372 avg_p1 0.4939\n",
      "Epoch 71 Iter 24400 loss=4.0014 elbo -4.6399 ll -1.5240 kl_fb 3.1159 kl 12.7701 kl_weight 0.2440 sf 0.8229 reward -0.0622 ll_mean -1.4618 ll_std 1.0000 selected 0.4872 prior_p1 0.9260 avg_p1 0.4932\n",
      "Epoch 71 Iter 24500 loss=4.3575 elbo -1.9707 ll -1.5521 kl_fb 0.4186 kl 1.7088 kl_weight 0.2450 sf 1.0103 reward -0.0903 ll_mean -1.4618 ll_std 1.0000 selected 0.4886 prior_p1 0.2790 avg_p1 0.4962\n",
      "\n",
      "# epoch 71 iter 24552: dev loss -2.5731 elbo -16.6957 ll -1.4814 kl_fb 15.2143 kl 15.2143 kl_weight 1.0000 sf 19.2688 reward -1.4814 ll_mean 0.0000 ll_std 1.0000 selected 0.1750 prior_p1 0.6661 avg_p1 0.4937 acc 0.3397\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Iter 24600 loss=3.7289 elbo -1.7070 ll -1.4859 kl_fb 0.2211 kl 0.8986 kl_weight 0.2460 sf 0.3285 reward -0.0224 ll_mean -1.4635 ll_std 1.0000 selected 0.4708 prior_p1 0.6344 avg_p1 0.4933\n",
      "Shuffling training data\n",
      "Epoch 72 Iter 24700 loss=4.3810 elbo -1.5332 ll -1.3364 kl_fb 0.1968 kl 0.7968 kl_weight 0.2470 sf -1.6223 reward 0.1259 ll_mean -1.4623 ll_std 1.0000 selected 0.5073 prior_p1 0.3533 avg_p1 0.4949\n",
      "Epoch 72 Iter 24800 loss=3.4580 elbo -2.0120 ll -1.4074 kl_fb 0.6046 kl 2.4378 kl_weight 0.2480 sf -0.6961 reward 0.0558 ll_mean -1.4632 ll_std 1.0000 selected 0.5002 prior_p1 0.2521 avg_p1 0.4931\n",
      "\n",
      "# epoch 72 iter 24893: dev loss -9.0610 elbo -10.1462 ll -1.4754 kl_fb 8.6708 kl 8.6708 kl_weight 1.0000 sf 19.2072 reward -1.4754 ll_mean 0.0000 ll_std 1.0000 selected 0.1820 prior_p1 0.4582 avg_p1 0.4941 acc 0.3415\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 73 Iter 24900 loss=4.7667 elbo -1.3929 ll -1.3887 kl_fb 0.0043 kl 0.0171 kl_weight 0.2490 sf -1.0434 reward 0.0746 ll_mean -1.4632 ll_std 1.0000 selected 0.4495 prior_p1 0.4973 avg_p1 0.4947\n",
      "Shuffling training data\n",
      "Epoch 73 Iter 25000 loss=4.2216 elbo -6.8780 ll -1.5328 kl_fb 5.3452 kl 21.3809 kl_weight 0.2500 sf 0.9729 reward -0.0712 ll_mean -1.4616 ll_std 1.0000 selected 0.5247 prior_p1 0.9698 avg_p1 0.4954\n",
      "Epoch 73 Iter 25100 loss=4.1304 elbo -5.5301 ll -1.3684 kl_fb 4.1617 kl 16.5804 kl_weight 0.2510 sf -1.1627 reward 0.0940 ll_mean -1.4624 ll_std 1.0000 selected 0.4889 prior_p1 0.0390 avg_p1 0.4937\n",
      "Epoch 73 Iter 25200 loss=4.3330 elbo -1.5612 ll -1.4031 kl_fb 0.1581 kl 0.6275 kl_weight 0.2520 sf -0.8773 reward 0.0602 ll_mean -1.4633 ll_std 1.0000 selected 0.5308 prior_p1 0.6119 avg_p1 0.4932\n",
      "\n",
      "# epoch 73 iter 25234: dev loss -5.5992 elbo -13.6424 ll -1.4776 kl_fb 12.1648 kl 12.1648 kl_weight 1.0000 sf 19.2416 reward -1.4776 ll_mean 0.0000 ll_std 1.0000 selected 0.1806 prior_p1 0.4772 avg_p1 0.4942 acc 0.3451\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 74 Iter 25300 loss=4.1529 elbo -1.4463 ll -1.4409 kl_fb 0.0054 kl 0.0213 kl_weight 0.2530 sf -0.2614 reward 0.0216 ll_mean -1.4625 ll_std 1.0000 selected 0.4908 prior_p1 0.4835 avg_p1 0.4946\n",
      "Shuffling training data\n",
      "Epoch 74 Iter 25400 loss=4.4957 elbo -1.3445 ll -1.3000 kl_fb 0.0445 kl 0.1750 kl_weight 0.2540 sf -2.2466 reward 0.1627 ll_mean -1.4627 ll_std 1.0000 selected 0.4950 prior_p1 0.4332 avg_p1 0.4957\n",
      "Epoch 74 Iter 25500 loss=4.0626 elbo -1.7783 ll -1.3818 kl_fb 0.3965 kl 1.5549 kl_weight 0.2550 sf -1.0629 reward 0.0807 ll_mean -1.4625 ll_std 1.0000 selected 0.4859 prior_p1 0.3030 avg_p1 0.4954\n",
      "\n",
      "# epoch 74 iter 25575: dev loss -5.9168 elbo -13.1090 ll -1.4567 kl_fb 11.6523 kl 11.6523 kl_weight 1.0000 sf 19.0258 reward -1.4567 ll_mean 0.0000 ll_std 1.0000 selected 0.2121 prior_p1 0.5325 avg_p1 0.4955 acc 0.3642\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 75 Iter 25600 loss=4.2133 elbo -2.7148 ll -1.4306 kl_fb 1.2841 kl 5.0162 kl_weight 0.2560 sf -0.3694 reward 0.0325 ll_mean -1.4632 ll_std 1.0000 selected 0.4980 prior_p1 0.8346 avg_p1 0.4956\n",
      "Shuffling training data\n",
      "Epoch 75 Iter 25700 loss=3.5254 elbo -1.9408 ll -1.3778 kl_fb 0.5630 kl 2.1905 kl_weight 0.2570 sf -1.1055 reward 0.0863 ll_mean -1.4641 ll_std 1.0000 selected 0.5040 prior_p1 0.7263 avg_p1 0.4972\n",
      "Epoch 75 Iter 25800 loss=4.2718 elbo -3.1920 ll -1.3515 kl_fb 1.8405 kl 7.1337 kl_weight 0.2580 sf -1.4524 reward 0.1123 ll_mean -1.4638 ll_std 1.0000 selected 0.4708 prior_p1 0.8628 avg_p1 0.4965\n",
      "Epoch 75 Iter 25900 loss=4.2245 elbo -2.7653 ll -1.5778 kl_fb 1.1875 kl 4.5850 kl_weight 0.2590 sf 1.6897 reward -0.1126 ll_mean -1.4652 ll_std 1.0000 selected 0.5098 prior_p1 0.2051 avg_p1 0.4973\n",
      "\n",
      "# epoch 75 iter 25916: dev loss -6.8347 elbo -12.0661 ll -1.4424 kl_fb 10.6237 kl 10.6237 kl_weight 1.0000 sf 18.9008 reward -1.4424 ll_mean 0.0000 ll_std 1.0000 selected 0.2504 prior_p1 0.4646 avg_p1 0.4972 acc 0.3697\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 76 Iter 26000 loss=4.3183 elbo -5.2368 ll -1.3773 kl_fb 3.8595 kl 14.8441 kl_weight 0.2600 sf -0.9213 reward 0.0875 ll_mean -1.4648 ll_std 1.0000 selected 0.4536 prior_p1 0.9625 avg_p1 0.4983\n",
      "Epoch 76 Iter 26100 loss=4.7434 elbo -2.0710 ll -1.3864 kl_fb 0.6846 kl 2.6230 kl_weight 0.2610 sf -1.0891 reward 0.0794 ll_mean -1.4657 ll_std 1.0000 selected 0.5507 prior_p1 0.7373 avg_p1 0.4966\n",
      "Epoch 76 Iter 26200 loss=3.9745 elbo -1.8607 ll -1.4177 kl_fb 0.4429 kl 1.6906 kl_weight 0.2620 sf -0.7129 reward 0.0474 ll_mean -1.4651 ll_std 1.0000 selected 0.4746 prior_p1 0.3084 avg_p1 0.4973\n",
      "\n",
      "# epoch 76 iter 26257: dev loss -7.7722 elbo -10.8477 ll -1.4185 kl_fb 9.4292 kl 9.4292 kl_weight 1.0000 sf 18.6199 reward -1.4185 ll_mean 0.0000 ll_std 1.0000 selected 0.3501 prior_p1 0.5613 avg_p1 0.4989 acc 0.3869\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 77 Iter 26300 loss=4.5326 elbo -1.5415 ll -1.3886 kl_fb 0.1529 kl 0.5816 kl_weight 0.2630 sf -1.0110 reward 0.0770 ll_mean -1.4656 ll_std 1.0000 selected 0.4712 prior_p1 0.3795 avg_p1 0.4998\n",
      "Shuffling training data\n",
      "Epoch 77 Iter 26400 loss=4.3920 elbo -8.1536 ll -1.3115 kl_fb 6.8420 kl 25.9168 kl_weight 0.2640 sf -2.0590 reward 0.1536 ll_mean -1.4651 ll_std 1.0000 selected 0.5125 prior_p1 0.0176 avg_p1 0.4995\n",
      "Epoch 77 Iter 26500 loss=3.5352 elbo -2.3983 ll -1.5120 kl_fb 0.8864 kl 3.3447 kl_weight 0.2650 sf 0.5279 reward -0.0459 ll_mean -1.4660 ll_std 1.0000 selected 0.4994 prior_p1 0.2121 avg_p1 0.4993\n",
      "\n",
      "# epoch 77 iter 26598: dev loss -10.3128 elbo -8.2502 ll -1.4129 kl_fb 6.8373 kl 6.8373 kl_weight 1.0000 sf 18.5630 reward -1.4129 ll_mean 0.0000 ll_std 1.0000 selected 0.3690 prior_p1 0.4971 avg_p1 0.4998 acc 0.4069\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 78 Iter 26600 loss=3.9803 elbo -2.0489 ll -1.4273 kl_fb 0.6217 kl 2.3371 kl_weight 0.2660 sf -0.5117 reward 0.0372 ll_mean -1.4645 ll_std 1.0000 selected 0.4873 prior_p1 0.2726 avg_p1 0.5008\n",
      "Shuffling training data\n",
      "Epoch 78 Iter 26700 loss=3.8138 elbo -1.7378 ll -1.4810 kl_fb 0.2568 kl 0.9618 kl_weight 0.2670 sf 0.2276 reward -0.0178 ll_mean -1.4632 ll_std 1.0000 selected 0.4696 prior_p1 0.3427 avg_p1 0.4980\n",
      "Epoch 78 Iter 26800 loss=4.2144 elbo -1.4687 ll -1.4480 kl_fb 0.0207 kl 0.0773 kl_weight 0.2680 sf -0.1864 reward 0.0164 ll_mean -1.4644 ll_std 1.0000 selected 0.4758 prior_p1 0.4559 avg_p1 0.4987\n",
      "Epoch 78 Iter 26900 loss=5.2986 elbo -7.2437 ll -1.5151 kl_fb 5.7285 kl 21.2957 kl_weight 0.2690 sf 0.6096 reward -0.0514 ll_mean -1.4637 ll_std 1.0000 selected 0.5096 prior_p1 0.9783 avg_p1 0.4984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 78 iter 26939: dev loss -11.6278 elbo -6.9511 ll -1.4141 kl_fb 5.5371 kl 5.5371 kl_weight 1.0000 sf 18.5790 reward -1.4141 ll_mean 0.0000 ll_std 1.0000 selected 0.3708 prior_p1 0.4932 avg_p1 0.4998 acc 0.4015\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 79 Iter 27000 loss=4.3184 elbo -1.8866 ll -1.3661 kl_fb 0.5205 kl 1.9280 kl_weight 0.2700 sf -1.2727 reward 0.0968 ll_mean -1.4628 ll_std 1.0000 selected 0.5380 prior_p1 0.7131 avg_p1 0.4993\n",
      "Shuffling training data\n",
      "Epoch 79 Iter 27100 loss=4.0786 elbo -2.2002 ll -1.8238 kl_fb 0.3763 kl 1.3887 kl_weight 0.2710 sf 4.9773 reward -0.3623 ll_mean -1.4615 ll_std 1.0000 selected 0.5029 prior_p1 0.3205 avg_p1 0.5001\n",
      "Epoch 79 Iter 27200 loss=5.0002 elbo -1.3184 ll -1.3001 kl_fb 0.0183 kl 0.0672 kl_weight 0.2720 sf -2.1128 reward 0.1643 ll_mean -1.4644 ll_std 1.0000 selected 0.5203 prior_p1 0.5351 avg_p1 0.4987\n",
      "\n",
      "# epoch 79 iter 27280: dev loss -7.4656 elbo -11.1414 ll -1.4168 kl_fb 9.7246 kl 9.7246 kl_weight 1.0000 sf 18.6070 reward -1.4168 ll_mean 0.0000 ll_std 1.0000 selected 0.3637 prior_p1 0.5010 avg_p1 0.4993 acc 0.3969\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 80 Iter 27300 loss=4.2807 elbo -1.5166 ll -1.4681 kl_fb 0.0485 kl 0.1778 kl_weight 0.2730 sf 0.0583 reward -0.0043 ll_mean -1.4638 ll_std 1.0000 selected 0.4778 prior_p1 0.4378 avg_p1 0.5013\n",
      "Shuffling training data\n",
      "Epoch 80 Iter 27400 loss=4.5003 elbo -11.8276 ll -1.5551 kl_fb 10.2725 kl 37.4909 kl_weight 0.2740 sf 1.1471 reward -0.0915 ll_mean -1.4635 ll_std 1.0000 selected 0.5655 prior_p1 0.0040 avg_p1 0.4995\n",
      "Epoch 80 Iter 27500 loss=4.1944 elbo -1.4051 ll -1.3967 kl_fb 0.0084 kl 0.0306 kl_weight 0.2750 sf -0.9446 reward 0.0669 ll_mean -1.4636 ll_std 1.0000 selected 0.5165 prior_p1 0.4813 avg_p1 0.4990\n",
      "Epoch 80 Iter 27600 loss=4.5150 elbo -6.6988 ll -1.4456 kl_fb 5.2532 kl 19.0333 kl_weight 0.2760 sf -0.2152 reward 0.0185 ll_mean -1.4641 ll_std 1.0000 selected 0.4909 prior_p1 0.9730 avg_p1 0.4986\n",
      "\n",
      "# epoch 80 iter 27621: dev loss -9.2605 elbo -9.3278 ll -1.4152 kl_fb 7.9126 kl 7.9126 kl_weight 1.0000 sf 18.5883 reward -1.4152 ll_mean 0.0000 ll_std 1.0000 selected 0.3642 prior_p1 0.5422 avg_p1 0.4994 acc 0.3996\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 81 Iter 27700 loss=4.9363 elbo -8.4343 ll -1.4789 kl_fb 6.9553 kl 25.1095 kl_weight 0.2770 sf 0.1608 reward -0.0137 ll_mean -1.4652 ll_std 1.0000 selected 0.5270 prior_p1 0.9871 avg_p1 0.4992\n",
      "Shuffling training data\n",
      "Epoch 81 Iter 27800 loss=4.3475 elbo -1.3558 ll -1.3501 kl_fb 0.0056 kl 0.0203 kl_weight 0.2780 sf -1.6029 reward 0.1143 ll_mean -1.4644 ll_std 1.0000 selected 0.4782 prior_p1 0.5074 avg_p1 0.5004\n",
      "Epoch 81 Iter 27900 loss=4.7629 elbo -1.5769 ll -1.5673 kl_fb 0.0097 kl 0.0346 kl_weight 0.2790 sf 1.6104 reward -0.1037 ll_mean -1.4636 ll_std 1.0000 selected 0.4799 prior_p1 0.4814 avg_p1 0.4984\n",
      "\n",
      "# epoch 81 iter 27962: dev loss -7.3986 elbo -11.1876 ll -1.4152 kl_fb 9.7724 kl 9.7724 kl_weight 1.0000 sf 18.5862 reward -1.4152 ll_mean 0.0000 ll_std 1.0000 selected 0.3450 prior_p1 0.5036 avg_p1 0.4990 acc 0.3960\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 82 Iter 28000 loss=4.3980 elbo -2.8553 ll -1.4430 kl_fb 1.4123 kl 5.0439 kl_weight 0.2800 sf -0.2731 reward 0.0223 ll_mean -1.4654 ll_std 1.0000 selected 0.5137 prior_p1 0.1689 avg_p1 0.4981\n",
      "Shuffling training data\n",
      "Epoch 82 Iter 28100 loss=5.0854 elbo -3.0635 ll -1.4823 kl_fb 1.5813 kl 5.6273 kl_weight 0.2810 sf 0.2198 reward -0.0155 ll_mean -1.4668 ll_std 1.0000 selected 0.5057 prior_p1 0.8249 avg_p1 0.5002\n",
      "Epoch 82 Iter 28200 loss=4.7451 elbo -8.4242 ll -1.4562 kl_fb 6.9680 kl 24.7091 kl_weight 0.2820 sf -0.0907 reward 0.0073 ll_mean -1.4635 ll_std 1.0000 selected 0.5292 prior_p1 0.0162 avg_p1 0.4991\n",
      "Epoch 82 Iter 28300 loss=4.7807 elbo -2.4617 ll -1.4999 kl_fb 0.9619 kl 3.3988 kl_weight 0.2830 sf 0.4991 reward -0.0361 ll_mean -1.4638 ll_std 1.0000 selected 0.4826 prior_p1 0.7659 avg_p1 0.4976\n",
      "\n",
      "# epoch 82 iter 28303: dev loss -5.5050 elbo -13.1822 ll -1.4232 kl_fb 11.7590 kl 11.7590 kl_weight 1.0000 sf 18.6873 reward -1.4232 ll_mean 0.0000 ll_std 1.0000 selected 0.3174 prior_p1 0.5552 avg_p1 0.4986 acc 0.3860\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 83 Iter 28400 loss=4.5965 elbo -6.2596 ll -1.6342 kl_fb 4.6254 kl 16.2866 kl_weight 0.2840 sf 2.2288 reward -0.1703 ll_mean -1.4639 ll_std 1.0000 selected 0.5006 prior_p1 0.9531 avg_p1 0.5002\n",
      "Epoch 83 Iter 28500 loss=4.5469 elbo -2.1484 ll -1.4709 kl_fb 0.6774 kl 2.3769 kl_weight 0.2850 sf 0.0930 reward -0.0075 ll_mean -1.4634 ll_std 1.0000 selected 0.4702 prior_p1 0.2572 avg_p1 0.4981\n",
      "Epoch 83 Iter 28600 loss=4.1770 elbo -1.5851 ll -1.5295 kl_fb 0.0556 kl 0.1944 kl_weight 0.2860 sf 0.9448 reward -0.0671 ll_mean -1.4624 ll_std 1.0000 selected 0.4858 prior_p1 0.5654 avg_p1 0.5000\n",
      "\n",
      "# epoch 83 iter 28644: dev loss 1.2335 elbo -19.9220 ll -1.4233 kl_fb 18.4988 kl 18.4988 kl_weight 1.0000 sf 18.6886 reward -1.4233 ll_mean 0.0000 ll_std 1.0000 selected 0.3205 prior_p1 0.4975 avg_p1 0.4987 acc 0.3915\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 84 Iter 28700 loss=4.3891 elbo -7.6964 ll -1.6309 kl_fb 6.0655 kl 21.1342 kl_weight 0.2870 sf 1.9623 reward -0.1664 ll_mean -1.4644 ll_std 1.0000 selected 0.4725 prior_p1 0.9785 avg_p1 0.4996\n",
      "Shuffling training data\n",
      "Epoch 84 Iter 28800 loss=4.3448 elbo -2.7030 ll -1.4540 kl_fb 1.2490 kl 4.3369 kl_weight 0.2880 sf -0.0955 reward 0.0096 ll_mean -1.4636 ll_std 1.0000 selected 0.4342 prior_p1 0.1629 avg_p1 0.4993\n",
      "Epoch 84 Iter 28900 loss=4.8249 elbo -1.4271 ll -1.4212 kl_fb 0.0059 kl 0.0204 kl_weight 0.2890 sf -0.5238 reward 0.0428 ll_mean -1.4640 ll_std 1.0000 selected 0.5150 prior_p1 0.5095 avg_p1 0.4982\n",
      "\n",
      "# epoch 84 iter 28985: dev loss -7.5998 elbo -11.3060 ll -1.4413 kl_fb 9.8647 kl 9.8647 kl_weight 1.0000 sf 18.9058 reward -1.4413 ll_mean 0.0000 ll_std 1.0000 selected 0.2492 prior_p1 0.5622 avg_p1 0.4974 acc 0.3706\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 85 Iter 29000 loss=4.7141 elbo -5.3419 ll -1.4493 kl_fb 3.8926 kl 13.4229 kl_weight 0.2900 sf -0.1315 reward 0.0129 ll_mean -1.4622 ll_std 1.0000 selected 0.5019 prior_p1 0.9572 avg_p1 0.4970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 85 Iter 29100 loss=3.7976 elbo -1.7880 ll -1.5357 kl_fb 0.2522 kl 0.8668 kl_weight 0.2910 sf 1.0023 reward -0.0729 ll_mean -1.4628 ll_std 1.0000 selected 0.4858 prior_p1 0.3537 avg_p1 0.4964\n",
      "Epoch 85 Iter 29200 loss=4.3479 elbo -13.9334 ll -1.3144 kl_fb 12.6190 kl 43.2158 kl_weight 0.2920 sf -1.9456 reward 0.1493 ll_mean -1.4637 ll_std 1.0000 selected 0.5534 prior_p1 0.9973 avg_p1 0.4970\n",
      "Epoch 85 Iter 29300 loss=4.4674 elbo -4.7718 ll -1.3666 kl_fb 3.4052 kl 11.6218 kl_weight 0.2930 sf -1.1538 reward 0.0975 ll_mean -1.4641 ll_std 1.0000 selected 0.5010 prior_p1 0.0679 avg_p1 0.4966\n",
      "\n",
      "# epoch 85 iter 29326: dev loss -7.0643 elbo -11.8296 ll -1.4411 kl_fb 10.3885 kl 10.3885 kl_weight 1.0000 sf 18.8939 reward -1.4411 ll_mean 0.0000 ll_std 1.0000 selected 0.2436 prior_p1 0.4709 avg_p1 0.4972 acc 0.3733\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 86 Iter 29400 loss=4.1593 elbo -1.9336 ll -1.4978 kl_fb 0.4358 kl 1.4822 kl_weight 0.2940 sf 0.3681 reward -0.0335 ll_mean -1.4643 ll_std 1.0000 selected 0.5641 prior_p1 0.2920 avg_p1 0.4970\n",
      "Shuffling training data\n",
      "Epoch 86 Iter 29500 loss=4.5116 elbo -4.1964 ll -1.4526 kl_fb 2.7438 kl 9.3010 kl_weight 0.2950 sf -0.1670 reward 0.0119 ll_mean -1.4645 ll_std 1.0000 selected 0.4948 prior_p1 0.8837 avg_p1 0.4943\n",
      "Epoch 86 Iter 29600 loss=4.8888 elbo -2.6085 ll -1.5405 kl_fb 1.0679 kl 3.6079 kl_weight 0.2960 sf 0.9225 reward -0.0770 ll_mean -1.4636 ll_std 1.0000 selected 0.5308 prior_p1 0.2033 avg_p1 0.4929\n",
      "\n",
      "# epoch 86 iter 29667: dev loss -10.1098 elbo -9.0347 ll -1.4664 kl_fb 7.5682 kl 7.5682 kl_weight 1.0000 sf 19.1444 reward -1.4664 ll_mean 0.0000 ll_std 1.0000 selected 0.1902 prior_p1 0.4366 avg_p1 0.4951 acc 0.3533\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 87 Iter 29700 loss=4.2122 elbo -4.3225 ll -1.3830 kl_fb 2.9395 kl 9.8973 kl_weight 0.2970 sf -1.0387 reward 0.0791 ll_mean -1.4621 ll_std 1.0000 selected 0.4540 prior_p1 0.0952 avg_p1 0.4948\n",
      "Shuffling training data\n",
      "Epoch 87 Iter 29800 loss=4.5224 elbo -1.6545 ll -1.5083 kl_fb 0.1462 kl 0.4906 kl_weight 0.2980 sf 0.6407 reward -0.0449 ll_mean -1.4634 ll_std 1.0000 selected 0.4820 prior_p1 0.3918 avg_p1 0.4975\n",
      "Epoch 87 Iter 29900 loss=4.8219 elbo -1.6301 ll -1.5175 kl_fb 0.1126 kl 0.3764 kl_weight 0.2990 sf 0.7117 reward -0.0541 ll_mean -1.4634 ll_std 1.0000 selected 0.5054 prior_p1 0.5945 avg_p1 0.4980\n",
      "Epoch 87 Iter 30000 loss=4.9284 elbo -5.1149 ll -1.4776 kl_fb 3.6373 kl 12.1242 kl_weight 0.3000 sf 0.1683 reward -0.0133 ll_mean -1.4644 ll_std 1.0000 selected 0.5123 prior_p1 0.0707 avg_p1 0.4979\n",
      "\n",
      "# epoch 87 iter 30008: dev loss -2.6550 elbo -16.1973 ll -1.4349 kl_fb 14.7625 kl 14.7625 kl_weight 1.0000 sf 18.8523 reward -1.4349 ll_mean 0.0000 ll_std 1.0000 selected 0.2827 prior_p1 0.4851 avg_p1 0.4982 acc 0.3697\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 88 Iter 30100 loss=4.2066 elbo -3.9202 ll -1.3524 kl_fb 2.5678 kl 8.5308 kl_weight 0.3010 sf -1.6308 reward 0.1119 ll_mean -1.4643 ll_std 1.0000 selected 0.4796 prior_p1 0.1272 avg_p1 0.4989\n",
      "Epoch 88 Iter 30200 loss=5.0558 elbo -2.2676 ll -1.4107 kl_fb 0.8569 kl 2.8373 kl_weight 0.3020 sf -0.6000 reward 0.0514 ll_mean -1.4622 ll_std 1.0000 selected 0.4267 prior_p1 0.2324 avg_p1 0.4990\n",
      "Epoch 88 Iter 30300 loss=3.9639 elbo -1.7182 ll -1.3996 kl_fb 0.3186 kl 1.0514 kl_weight 0.3030 sf -0.9121 reward 0.0626 ll_mean -1.4622 ll_std 1.0000 selected 0.5235 prior_p1 0.3466 avg_p1 0.4995\n",
      "\n",
      "# epoch 88 iter 30349: dev loss -8.0410 elbo -10.5751 ll -1.4169 kl_fb 9.1582 kl 9.1582 kl_weight 1.0000 sf 18.6162 reward -1.4169 ll_mean 0.0000 ll_std 1.0000 selected 0.3285 prior_p1 0.4412 avg_p1 0.4988 acc 0.3860\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 89 Iter 30400 loss=5.6297 elbo -1.8432 ll -1.3984 kl_fb 0.4448 kl 1.4632 kl_weight 0.3040 sf -0.8140 reward 0.0611 ll_mean -1.4595 ll_std 1.0000 selected 0.4806 prior_p1 0.6860 avg_p1 0.4993\n",
      "Shuffling training data\n",
      "Epoch 89 Iter 30500 loss=4.1824 elbo -1.4792 ll -1.4364 kl_fb 0.0429 kl 0.1406 kl_weight 0.3050 sf -0.3271 reward 0.0209 ll_mean -1.4573 ll_std 1.0000 selected 0.4811 prior_p1 0.4475 avg_p1 0.4992\n",
      "Epoch 89 Iter 30600 loss=3.9820 elbo -11.5688 ll -1.6118 kl_fb 9.9570 kl 32.5393 kl_weight 0.3060 sf 1.7783 reward -0.1525 ll_mean -1.4593 ll_std 1.0000 selected 0.4952 prior_p1 0.0053 avg_p1 0.4990\n",
      "\n",
      "# epoch 89 iter 30690: dev loss -6.7956 elbo -11.7804 ll -1.4128 kl_fb 10.3676 kl 10.3676 kl_weight 1.0000 sf 18.5760 reward -1.4128 ll_mean 0.0000 ll_std 1.0000 selected 0.3642 prior_p1 0.4753 avg_p1 0.4995 acc 0.4015\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 90 Iter 30700 loss=4.5949 elbo -3.7551 ll -1.4495 kl_fb 2.3056 kl 7.5102 kl_weight 0.3070 sf -0.1302 reward 0.0104 ll_mean -1.4598 ll_std 1.0000 selected 0.4583 prior_p1 0.1245 avg_p1 0.5003\n",
      "Shuffling training data\n",
      "Epoch 90 Iter 30800 loss=4.7829 elbo -6.4796 ll -1.3825 kl_fb 5.0971 kl 16.5492 kl_weight 0.3080 sf -0.8169 reward 0.0774 ll_mean -1.4598 ll_std 1.0000 selected 0.5221 prior_p1 0.0292 avg_p1 0.4992\n",
      "Epoch 90 Iter 30900 loss=4.4747 elbo -1.4436 ll -1.3994 kl_fb 0.0441 kl 0.1428 kl_weight 0.3090 sf -0.7485 reward 0.0621 ll_mean -1.4615 ll_std 1.0000 selected 0.4826 prior_p1 0.5583 avg_p1 0.4983\n",
      "Epoch 90 Iter 31000 loss=4.4340 elbo -2.6461 ll -1.4727 kl_fb 1.1734 kl 3.7851 kl_weight 0.3100 sf 0.1521 reward -0.0112 ll_mean -1.4615 ll_std 1.0000 selected 0.4571 prior_p1 0.2152 avg_p1 0.4976\n",
      "\n",
      "# epoch 90 iter 31031: dev loss -8.9427 elbo -9.9195 ll -1.4361 kl_fb 8.4834 kl 8.4834 kl_weight 1.0000 sf 18.8621 reward -1.4361 ll_mean 0.0000 ll_std 1.0000 selected 0.2805 prior_p1 0.4671 avg_p1 0.4979 acc 0.3724\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 91 Iter 31100 loss=4.7512 elbo -1.5726 ll -1.4247 kl_fb 0.1479 kl 0.4756 kl_weight 0.3110 sf -0.4097 reward 0.0353 ll_mean -1.4600 ll_std 1.0000 selected 0.4901 prior_p1 0.3839 avg_p1 0.4993\n",
      "Shuffling training data\n",
      "Epoch 91 Iter 31200 loss=5.4537 elbo -12.0402 ll -1.5649 kl_fb 10.4753 kl 33.5747 kl_weight 0.3120 sf 1.4262 reward -0.1029 ll_mean -1.4619 ll_std 1.0000 selected 0.5060 prior_p1 0.0088 avg_p1 0.4975\n",
      "Epoch 91 Iter 31300 loss=5.2643 elbo -5.2715 ll -1.5267 kl_fb 3.7448 kl 11.9642 kl_weight 0.3130 sf 0.8972 reward -0.0670 ll_mean -1.4597 ll_std 1.0000 selected 0.5095 prior_p1 0.9198 avg_p1 0.4961\n",
      "\n",
      "# epoch 91 iter 31372: dev loss -6.7811 elbo -12.2009 ll -1.4495 kl_fb 10.7514 kl 10.7514 kl_weight 1.0000 sf 18.9821 reward -1.4495 ll_mean 0.0000 ll_std 1.0000 selected 0.2281 prior_p1 0.5143 avg_p1 0.4963 acc 0.3688\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Iter 31400 loss=5.1858 elbo -2.6707 ll -1.5014 kl_fb 1.1693 kl 3.7240 kl_weight 0.3140 sf 0.5648 reward -0.0391 ll_mean -1.4623 ll_std 1.0000 selected 0.5207 prior_p1 0.7712 avg_p1 0.4975\n",
      "Shuffling training data\n",
      "Epoch 92 Iter 31500 loss=5.0097 elbo -1.4049 ll -1.3812 kl_fb 0.0237 kl 0.0753 kl_weight 0.3150 sf -1.0995 reward 0.0829 ll_mean -1.4640 ll_std 1.0000 selected 0.4604 prior_p1 0.4591 avg_p1 0.4987\n",
      "Epoch 92 Iter 31600 loss=4.8026 elbo -1.3288 ll -1.3184 kl_fb 0.0104 kl 0.0328 kl_weight 0.3160 sf -1.8441 reward 0.1449 ll_mean -1.4633 ll_std 1.0000 selected 0.5081 prior_p1 0.4740 avg_p1 0.4950\n",
      "Epoch 92 Iter 31700 loss=4.1476 elbo -8.9344 ll -1.5486 kl_fb 7.3858 kl 23.2991 kl_weight 0.3170 sf 0.9870 reward -0.0871 ll_mean -1.4615 ll_std 1.0000 selected 0.5132 prior_p1 0.9847 avg_p1 0.4961\n",
      "\n",
      "# epoch 92 iter 31713: dev loss -3.9833 elbo -15.0333 ll -1.4513 kl_fb 13.5820 kl 13.5820 kl_weight 1.0000 sf 19.0166 reward -1.4513 ll_mean 0.0000 ll_std 1.0000 selected 0.2301 prior_p1 0.5243 avg_p1 0.4966 acc 0.3706\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 93 Iter 31800 loss=4.5228 elbo -2.7007 ll -1.4688 kl_fb 1.2319 kl 3.8738 kl_weight 0.3180 sf 0.1063 reward -0.0079 ll_mean -1.4609 ll_std 1.0000 selected 0.5127 prior_p1 0.2120 avg_p1 0.4966\n",
      "Shuffling training data\n",
      "Epoch 93 Iter 31900 loss=5.6688 elbo -8.3701 ll -1.4332 kl_fb 6.9368 kl 21.7456 kl_weight 0.3190 sf -0.3208 reward 0.0259 ll_mean -1.4591 ll_std 1.0000 selected 0.4843 prior_p1 0.0219 avg_p1 0.4965\n",
      "Epoch 93 Iter 32000 loss=5.0696 elbo -8.9710 ll -1.5117 kl_fb 7.4593 kl 23.3103 kl_weight 0.3200 sf 0.7546 reward -0.0519 ll_mean -1.4598 ll_std 1.0000 selected 0.5160 prior_p1 0.0269 avg_p1 0.4949\n",
      "\n",
      "# epoch 93 iter 32054: dev loss -11.8097 elbo -7.2401 ll -1.4556 kl_fb 5.7845 kl 5.7845 kl_weight 1.0000 sf 19.0499 reward -1.4556 ll_mean 0.0000 ll_std 1.0000 selected 0.2145 prior_p1 0.4475 avg_p1 0.4959 acc 0.3615\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 94 Iter 32100 loss=4.7787 elbo -1.5686 ll -1.5060 kl_fb 0.0626 kl 0.1950 kl_weight 0.3210 sf 0.5466 reward -0.0464 ll_mean -1.4596 ll_std 1.0000 selected 0.5475 prior_p1 0.4231 avg_p1 0.4952\n",
      "Shuffling training data\n",
      "Epoch 94 Iter 32200 loss=4.9955 elbo -5.0812 ll -1.7778 kl_fb 3.3034 kl 10.2590 kl_weight 0.3220 sf 4.4347 reward -0.3183 ll_mean -1.4595 ll_std 1.0000 selected 0.4814 prior_p1 0.8976 avg_p1 0.4961\n",
      "Epoch 94 Iter 32300 loss=4.8321 elbo -3.5751 ll -1.5409 kl_fb 2.0342 kl 6.2978 kl_weight 0.3230 sf 0.9423 reward -0.0796 ll_mean -1.4613 ll_std 1.0000 selected 0.4399 prior_p1 0.8580 avg_p1 0.4958\n",
      "\n",
      "# epoch 94 iter 32395: dev loss -4.2042 elbo -14.8047 ll -1.4513 kl_fb 13.3534 kl 13.3534 kl_weight 1.0000 sf 19.0089 reward -1.4513 ll_mean 0.0000 ll_std 1.0000 selected 0.2279 prior_p1 0.4414 avg_p1 0.4963 acc 0.3678\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 95 Iter 32400 loss=5.3498 elbo -15.6454 ll -1.4881 kl_fb 14.1572 kl 43.6952 kl_weight 0.3240 sf 0.3401 reward -0.0277 ll_mean -1.4605 ll_std 1.0000 selected 0.4763 prior_p1 0.0017 avg_p1 0.4980\n",
      "Shuffling training data\n",
      "Epoch 95 Iter 32500 loss=4.4674 elbo -15.6021 ll -1.4242 kl_fb 14.1779 kl 43.6243 kl_weight 0.3250 sf -0.5032 reward 0.0369 ll_mean -1.4611 ll_std 1.0000 selected 0.4903 prior_p1 0.0029 avg_p1 0.4970\n",
      "Epoch 95 Iter 32600 loss=5.0597 elbo -4.0075 ll -1.4467 kl_fb 2.5608 kl 7.8551 kl_weight 0.3260 sf -0.1919 reward 0.0152 ll_mean -1.4620 ll_std 1.0000 selected 0.5325 prior_p1 0.8774 avg_p1 0.4959\n",
      "Epoch 95 Iter 32700 loss=5.5216 elbo -1.7439 ll -1.4041 kl_fb 0.3398 kl 1.0392 kl_weight 0.3270 sf -0.7967 reward 0.0577 ll_mean -1.4617 ll_std 1.0000 selected 0.4806 prior_p1 0.6522 avg_p1 0.4957\n",
      "\n",
      "# epoch 95 iter 32736: dev loss -7.2431 elbo -11.9393 ll -1.4690 kl_fb 10.4703 kl 10.4703 kl_weight 1.0000 sf 19.1824 reward -1.4690 ll_mean 0.0000 ll_std 1.0000 selected 0.1862 prior_p1 0.4286 avg_p1 0.4949 acc 0.3542\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 96 Iter 32800 loss=4.7163 elbo -1.5251 ll -1.4133 kl_fb 0.1118 kl 0.3408 kl_weight 0.3280 sf -0.6686 reward 0.0488 ll_mean -1.4622 ll_std 1.0000 selected 0.4586 prior_p1 0.5849 avg_p1 0.4950\n",
      "Shuffling training data\n",
      "Epoch 96 Iter 32900 loss=4.7765 elbo -1.5484 ll -1.4892 kl_fb 0.0592 kl 0.1800 kl_weight 0.3290 sf 0.3546 reward -0.0264 ll_mean -1.4628 ll_std 1.0000 selected 0.5205 prior_p1 0.4316 avg_p1 0.4961\n",
      "Epoch 96 Iter 33000 loss=4.3383 elbo -2.5523 ll -1.5129 kl_fb 1.0394 kl 3.1496 kl_weight 0.3300 sf 0.6947 reward -0.0495 ll_mean -1.4635 ll_std 1.0000 selected 0.4797 prior_p1 0.7540 avg_p1 0.4955\n",
      "\n",
      "# epoch 96 iter 33077: dev loss -6.1729 elbo -12.8605 ll -1.4536 kl_fb 11.4069 kl 11.4069 kl_weight 1.0000 sf 19.0335 reward -1.4536 ll_mean 0.0000 ll_std 1.0000 selected 0.2203 prior_p1 0.5360 avg_p1 0.4961 acc 0.3660\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 97 Iter 33100 loss=4.7227 elbo -1.3402 ll -1.3324 kl_fb 0.0078 kl 0.0235 kl_weight 0.3310 sf -1.4744 reward 0.1313 ll_mean -1.4637 ll_std 1.0000 selected 0.4885 prior_p1 0.5140 avg_p1 0.4962\n",
      "Shuffling training data\n",
      "Epoch 97 Iter 33200 loss=5.0991 elbo -1.5727 ll -1.5661 kl_fb 0.0066 kl 0.0198 kl_weight 0.3320 sf 1.4641 reward -0.1048 ll_mean -1.4613 ll_std 1.0000 selected 0.5043 prior_p1 0.4865 avg_p1 0.4970\n",
      "Epoch 97 Iter 33300 loss=5.4029 elbo -11.0401 ll -1.4514 kl_fb 9.5887 kl 28.7950 kl_weight 0.3330 sf -0.1041 reward 0.0083 ll_mean -1.4597 ll_std 1.0000 selected 0.4722 prior_p1 0.9891 avg_p1 0.4963\n",
      "Epoch 97 Iter 33400 loss=5.4174 elbo -2.3407 ll -1.4094 kl_fb 0.9313 kl 2.7884 kl_weight 0.3340 sf -0.6806 reward 0.0529 ll_mean -1.4624 ll_std 1.0000 selected 0.4930 prior_p1 0.2414 avg_p1 0.4948\n",
      "\n",
      "# epoch 97 iter 33418: dev loss -7.2456 elbo -11.8346 ll -1.4582 kl_fb 10.3765 kl 10.3765 kl_weight 1.0000 sf 19.0802 reward -1.4582 ll_mean 0.0000 ll_std 1.0000 selected 0.2062 prior_p1 0.5541 avg_p1 0.4958 acc 0.3633\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 98 Iter 33500 loss=5.1517 elbo -1.6698 ll -1.2846 kl_fb 0.3852 kl 1.1498 kl_weight 0.3350 sf -1.8290 reward 0.1777 ll_mean -1.4623 ll_std 1.0000 selected 0.5193 prior_p1 0.3091 avg_p1 0.4971\n",
      "Shuffling training data\n",
      "Epoch 98 Iter 33600 loss=4.7259 elbo -1.3890 ll -1.3809 kl_fb 0.0081 kl 0.0242 kl_weight 0.3360 sf -0.8522 reward 0.0800 ll_mean -1.4609 ll_std 1.0000 selected 0.5298 prior_p1 0.5121 avg_p1 0.4938\n",
      "Epoch 98 Iter 33700 loss=4.6095 elbo -3.6981 ll -1.5330 kl_fb 2.1651 kl 6.4246 kl_weight 0.3370 sf 0.9176 reward -0.0708 ll_mean -1.4622 ll_std 1.0000 selected 0.5101 prior_p1 0.8496 avg_p1 0.4965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 98 iter 33759: dev loss -8.8822 elbo -10.1272 ll -1.4513 kl_fb 8.6759 kl 8.6759 kl_weight 1.0000 sf 19.0094 reward -1.4513 ll_mean 0.0000 ll_std 1.0000 selected 0.2220 prior_p1 0.4119 avg_p1 0.4962 acc 0.3660\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 99 Iter 33800 loss=5.4842 elbo -9.7389 ll -1.3594 kl_fb 8.3795 kl 24.7915 kl_weight 0.3380 sf -1.4791 reward 0.1031 ll_mean -1.4625 ll_std 1.0000 selected 0.5026 prior_p1 0.9762 avg_p1 0.4976\n",
      "Shuffling training data\n",
      "Epoch 99 Iter 33900 loss=6.2157 elbo -4.0251 ll -1.3920 kl_fb 2.6330 kl 7.7670 kl_weight 0.3390 sf -0.8431 reward 0.0693 ll_mean -1.4614 ll_std 1.0000 selected 0.4487 prior_p1 0.8798 avg_p1 0.4949\n",
      "Epoch 99 Iter 34000 loss=4.9254 elbo -5.4896 ll -1.4779 kl_fb 4.0116 kl 11.7990 kl_weight 0.3400 sf 0.2591 reward -0.0179 ll_mean -1.4600 ll_std 1.0000 selected 0.5093 prior_p1 0.0872 avg_p1 0.4966\n",
      "Epoch 99 Iter 34100 loss=4.8976 elbo -1.6720 ll -1.4010 kl_fb 0.2710 kl 0.7949 kl_weight 0.3410 sf -0.6457 reward 0.0591 ll_mean -1.4601 ll_std 1.0000 selected 0.4866 prior_p1 0.6505 avg_p1 0.4965\n",
      "\n",
      "# epoch 99 iter 34100: dev loss -12.0949 elbo -6.8188 ll -1.4430 kl_fb 5.3757 kl 5.3757 kl_weight 1.0000 sf 18.9136 reward -1.4430 ll_mean 0.0000 ll_std 1.0000 selected 0.2352 prior_p1 0.4721 avg_p1 0.4967 acc 0.3733\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 100 Iter 34200 loss=4.8657 elbo -3.2713 ll -1.4804 kl_fb 1.7909 kl 5.2364 kl_weight 0.3420 sf 0.2669 reward -0.0184 ll_mean -1.4620 ll_std 1.0000 selected 0.4853 prior_p1 0.1821 avg_p1 0.4939\n",
      "Shuffling training data\n",
      "Epoch 100 Iter 34300 loss=4.9346 elbo -1.5887 ll -1.5680 kl_fb 0.0207 kl 0.0604 kl_weight 0.3430 sf 1.5378 reward -0.1041 ll_mean -1.4639 ll_std 1.0000 selected 0.4947 prior_p1 0.5287 avg_p1 0.4968\n",
      "Epoch 100 Iter 34400 loss=5.1351 elbo -3.5627 ll -1.4964 kl_fb 2.0663 kl 6.0066 kl_weight 0.3440 sf 0.5060 reward -0.0339 ll_mean -1.4626 ll_std 1.0000 selected 0.4699 prior_p1 0.1715 avg_p1 0.4966\n",
      "\n",
      "# epoch 100 iter 34441: dev loss -7.8699 elbo -11.0269 ll -1.4407 kl_fb 9.5862 kl 9.5862 kl_weight 1.0000 sf 18.8968 reward -1.4407 ll_mean 0.0000 ll_std 1.0000 selected 0.2433 prior_p1 0.4612 avg_p1 0.4970 acc 0.3697\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 101 Iter 34500 loss=5.1451 elbo -14.9902 ll -1.4123 kl_fb 13.5778 kl 39.3560 kl_weight 0.3450 sf -0.6838 reward 0.0492 ll_mean -1.4615 ll_std 1.0000 selected 0.5235 prior_p1 0.9949 avg_p1 0.4975\n",
      "Shuffling training data\n",
      "Epoch 101 Iter 34600 loss=5.8028 elbo -11.2724 ll -1.5404 kl_fb 9.7320 kl 28.1272 kl_weight 0.3460 sf 0.9830 reward -0.0783 ll_mean -1.4621 ll_std 1.0000 selected 0.5081 prior_p1 0.9885 avg_p1 0.4978\n",
      "Epoch 101 Iter 34700 loss=5.1173 elbo -1.5980 ll -1.5843 kl_fb 0.0137 kl 0.0395 kl_weight 0.3470 sf 1.7996 reward -0.1237 ll_mean -1.4606 ll_std 1.0000 selected 0.5226 prior_p1 0.4741 avg_p1 0.4977\n",
      "\n",
      "# epoch 101 iter 34782: dev loss -3.0993 elbo -15.7580 ll -1.4369 kl_fb 14.3211 kl 14.3211 kl_weight 1.0000 sf 18.8573 reward -1.4369 ll_mean 0.0000 ll_std 1.0000 selected 0.2486 prior_p1 0.4798 avg_p1 0.4974 acc 0.3751\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 102 Iter 34800 loss=5.0045 elbo -1.5172 ll -1.4390 kl_fb 0.0782 kl 0.2246 kl_weight 0.3480 sf -0.3076 reward 0.0218 ll_mean -1.4608 ll_std 1.0000 selected 0.5141 prior_p1 0.4264 avg_p1 0.4972\n",
      "Shuffling training data\n",
      "Epoch 102 Iter 34900 loss=5.2778 elbo -5.3030 ll -1.3441 kl_fb 3.9589 kl 11.3435 kl_weight 0.3490 sf -1.5119 reward 0.1174 ll_mean -1.4615 ll_std 1.0000 selected 0.5010 prior_p1 0.0796 avg_p1 0.4986\n",
      "Epoch 102 Iter 35000 loss=4.7838 elbo -9.9237 ll -1.5870 kl_fb 8.3367 kl 23.8190 kl_weight 0.3500 sf 1.6616 reward -0.1253 ll_mean -1.4617 ll_std 1.0000 selected 0.4943 prior_p1 0.9783 avg_p1 0.4969\n",
      "Epoch 102 Iter 35100 loss=5.6115 elbo -2.7009 ll -1.5314 kl_fb 1.1695 kl 3.3319 kl_weight 0.3510 sf 1.1795 reward -0.0691 ll_mean -1.4623 ll_std 1.0000 selected 0.4302 prior_p1 0.7409 avg_p1 0.4980\n",
      "\n",
      "# epoch 102 iter 35123: dev loss -6.9731 elbo -11.7531 ll -1.4257 kl_fb 10.3273 kl 10.3273 kl_weight 1.0000 sf 18.7262 reward -1.4257 ll_mean 0.0000 ll_std 1.0000 selected 0.3028 prior_p1 0.3929 avg_p1 0.4981 acc 0.3824\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved to tears **by** a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 103 Iter 35200 loss=6.3081 elbo -10.5898 ll -1.4115 kl_fb 9.1783 kl 26.0747 kl_weight 0.3520 sf -0.6713 reward 0.0511 ll_mean -1.4625 ll_std 1.0000 selected 0.4948 prior_p1 0.0160 avg_p1 0.4975\n",
      "Shuffling training data\n",
      "Epoch 103 Iter 35300 loss=4.8838 elbo -10.9049 ll -1.5095 kl_fb 9.3954 kl 26.6158 kl_weight 0.3530 sf 0.6108 reward -0.0475 ll_mean -1.4620 ll_std 1.0000 selected 0.5185 prior_p1 0.0140 avg_p1 0.4976\n",
      "Epoch 103 Iter 35400 loss=4.8504 elbo -4.5954 ll -1.4155 kl_fb 3.1799 kl 8.9828 kl_weight 0.3540 sf -0.6819 reward 0.0474 ll_mean -1.4629 ll_std 1.0000 selected 0.5087 prior_p1 0.8782 avg_p1 0.4968\n",
      "\n",
      "# epoch 103 iter 35464: dev loss -6.8075 elbo -11.9904 ll -1.4309 kl_fb 10.5595 kl 10.5595 kl_weight 1.0000 sf 18.7979 reward -1.4309 ll_mean 0.0000 ll_std 1.0000 selected 0.2585 prior_p1 0.4662 avg_p1 0.4978 acc 0.3842\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 104 Iter 35500 loss=5.6120 elbo -1.4782 ll -1.4687 kl_fb 0.0095 kl 0.0267 kl_weight 0.3550 sf 0.0651 reward -0.0046 ll_mean -1.4641 ll_std 1.0000 selected 0.5169 prior_p1 0.5143 avg_p1 0.4972\n",
      "Shuffling training data\n",
      "Epoch 104 Iter 35600 loss=5.0259 elbo -3.2240 ll -1.4770 kl_fb 1.7470 kl 4.9073 kl_weight 0.3560 sf 0.1605 reward -0.0131 ll_mean -1.4639 ll_std 1.0000 selected 0.4900 prior_p1 0.8255 avg_p1 0.4997\n",
      "Epoch 104 Iter 35700 loss=6.1439 elbo -3.0943 ll -1.4944 kl_fb 1.5999 kl 4.4816 kl_weight 0.3570 sf 0.4221 reward -0.0300 ll_mean -1.4644 ll_std 1.0000 selected 0.4886 prior_p1 0.2004 avg_p1 0.4978\n",
      "Epoch 104 Iter 35800 loss=5.7736 elbo -24.5601 ll -1.6362 kl_fb 22.9239 kl 64.0332 kl_weight 0.3580 sf 2.5173 reward -0.1729 ll_mean -1.4633 ll_std 1.0000 selected 0.5232 prior_p1 0.9994 avg_p1 0.4981\n",
      "\n",
      "# epoch 104 iter 35805: dev loss -6.4012 elbo -12.4190 ll -1.4321 kl_fb 10.9869 kl 10.9869 kl_weight 1.0000 sf 18.8202 reward -1.4321 ll_mean 0.0000 ll_std 1.0000 selected 0.2605 prior_p1 0.4173 avg_p1 0.4979 acc 0.3806\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Iter 35900 loss=5.6847 elbo -6.4695 ll -1.4881 kl_fb 4.9814 kl 13.8758 kl_weight 0.3590 sf 0.3266 reward -0.0243 ll_mean -1.4638 ll_std 1.0000 selected 0.4905 prior_p1 0.9360 avg_p1 0.4988\n",
      "Shuffling training data\n",
      "Epoch 105 Iter 36000 loss=4.9171 elbo -1.8421 ll -1.5171 kl_fb 0.3250 kl 0.9028 kl_weight 0.3600 sf 0.7894 reward -0.0537 ll_mean -1.4634 ll_std 1.0000 selected 0.5178 prior_p1 0.6411 avg_p1 0.4997\n",
      "Epoch 105 Iter 36100 loss=5.8786 elbo -5.3338 ll -1.3759 kl_fb 3.9579 kl 10.9637 kl_weight 0.3610 sf -1.1516 reward 0.0862 ll_mean -1.4621 ll_std 1.0000 selected 0.4712 prior_p1 0.0874 avg_p1 0.4982\n",
      "\n",
      "# epoch 105 iter 36146: dev loss -8.1157 elbo -10.7740 ll -1.4400 kl_fb 9.3340 kl 9.3340 kl_weight 1.0000 sf 18.8897 reward -1.4400 ll_mean 0.0000 ll_std 1.0000 selected 0.2360 prior_p1 0.4655 avg_p1 0.4970 acc 0.3806\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 106 Iter 36200 loss=5.6391 elbo -5.0674 ll -1.4699 kl_fb 3.5975 kl 9.9379 kl_weight 0.3620 sf 0.0895 reward -0.0074 ll_mean -1.4624 ll_std 1.0000 selected 0.4619 prior_p1 0.0855 avg_p1 0.4972\n",
      "Shuffling training data\n",
      "Epoch 106 Iter 36300 loss=5.1721 elbo -1.7463 ll -1.6034 kl_fb 0.1428 kl 0.3935 kl_weight 0.3630 sf 1.9388 reward -0.1404 ll_mean -1.4630 ll_std 1.0000 selected 0.5105 prior_p1 0.3997 avg_p1 0.4962\n",
      "Epoch 106 Iter 36400 loss=5.2936 elbo -1.6331 ll -1.5580 kl_fb 0.0751 kl 0.2064 kl_weight 0.3640 sf 1.2354 reward -0.0959 ll_mean -1.4621 ll_std 1.0000 selected 0.4731 prior_p1 0.5691 avg_p1 0.4974\n",
      "\n",
      "# epoch 106 iter 36487: dev loss -4.2480 elbo -14.6143 ll -1.4369 kl_fb 13.1774 kl 13.1774 kl_weight 1.0000 sf 18.8624 reward -1.4369 ll_mean 0.0000 ll_std 1.0000 selected 0.2420 prior_p1 0.4072 avg_p1 0.4973 acc 0.3833\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 107 Iter 36500 loss=5.3530 elbo -1.3756 ll -1.3466 kl_fb 0.0291 kl 0.0796 kl_weight 0.3650 sf -1.1998 reward 0.1128 ll_mean -1.4593 ll_std 1.0000 selected 0.4781 prior_p1 0.4512 avg_p1 0.4977\n",
      "Shuffling training data\n",
      "Epoch 107 Iter 36600 loss=5.6216 elbo -6.1765 ll -1.4709 kl_fb 4.7056 kl 12.8567 kl_weight 0.3660 sf 0.1616 reward -0.0097 ll_mean -1.4612 ll_std 1.0000 selected 0.5448 prior_p1 0.0931 avg_p1 0.4974\n",
      "Epoch 107 Iter 36700 loss=5.5877 elbo -3.6415 ll -1.3931 kl_fb 2.2485 kl 6.1266 kl_weight 0.3670 sf -0.9328 reward 0.0704 ll_mean -1.4634 ll_std 1.0000 selected 0.4604 prior_p1 0.1551 avg_p1 0.4977\n",
      "Epoch 107 Iter 36800 loss=5.9398 elbo -3.2295 ll -1.4521 kl_fb 1.7774 kl 4.8299 kl_weight 0.3680 sf -0.1431 reward 0.0107 ll_mean -1.4627 ll_std 1.0000 selected 0.5143 prior_p1 0.1859 avg_p1 0.4978\n",
      "\n",
      "# epoch 107 iter 36828: dev loss -5.8844 elbo -13.0110 ll -1.4398 kl_fb 11.5712 kl 11.5712 kl_weight 1.0000 sf 18.8954 reward -1.4398 ll_mean 0.0000 ll_std 1.0000 selected 0.2379 prior_p1 0.5142 avg_p1 0.4972 acc 0.3760\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 108 Iter 36900 loss=5.0283 elbo -1.5886 ll -1.5674 kl_fb 0.0212 kl 0.0575 kl_weight 0.3690 sf 1.3195 reward -0.1056 ll_mean -1.4618 ll_std 1.0000 selected 0.5160 prior_p1 0.5311 avg_p1 0.4970\n",
      "Shuffling training data\n",
      "Epoch 108 Iter 37000 loss=5.0117 elbo -2.4675 ll -1.5330 kl_fb 0.9345 kl 2.5256 kl_weight 0.3700 sf 0.9005 reward -0.0700 ll_mean -1.4630 ll_std 1.0000 selected 0.4981 prior_p1 0.7400 avg_p1 0.4961\n",
      "Epoch 108 Iter 37100 loss=6.0855 elbo -1.8450 ll -1.6655 kl_fb 0.1795 kl 0.4839 kl_weight 0.3710 sf 2.6007 reward -0.2026 ll_mean -1.4628 ll_std 1.0000 selected 0.5176 prior_p1 0.3848 avg_p1 0.4963\n",
      "\n",
      "# epoch 108 iter 37169: dev loss -5.4391 elbo -13.5161 ll -1.4449 kl_fb 12.0711 kl 12.0711 kl_weight 1.0000 sf 18.9551 reward -1.4449 ll_mean 0.0000 ll_std 1.0000 selected 0.2319 prior_p1 0.4874 avg_p1 0.4968 acc 0.3760\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 109 Iter 37200 loss=6.0534 elbo -3.3101 ll -1.4228 kl_fb 1.8872 kl 5.0732 kl_weight 0.3720 sf -0.4992 reward 0.0395 ll_mean -1.4624 ll_std 1.0000 selected 0.5192 prior_p1 0.8238 avg_p1 0.4971\n",
      "Shuffling training data\n",
      "Epoch 109 Iter 37300 loss=5.2599 elbo -1.8302 ll -1.3790 kl_fb 0.4512 kl 1.2096 kl_weight 0.3730 sf -1.2082 reward 0.0852 ll_mean -1.4642 ll_std 1.0000 selected 0.5119 prior_p1 0.3333 avg_p1 0.4988\n",
      "Epoch 109 Iter 37400 loss=5.5499 elbo -18.2116 ll -1.5395 kl_fb 16.6721 kl 44.5779 kl_weight 0.3740 sf 0.9593 reward -0.0757 ll_mean -1.4638 ll_std 1.0000 selected 0.4654 prior_p1 0.0018 avg_p1 0.4969\n",
      "Epoch 109 Iter 37500 loss=5.6552 elbo -3.4907 ll -1.5186 kl_fb 1.9721 kl 5.2588 kl_weight 0.3750 sf 0.7224 reward -0.0519 ll_mean -1.4668 ll_std 1.0000 selected 0.4815 prior_p1 0.8167 avg_p1 0.4975\n",
      "\n",
      "# epoch 109 iter 37510: dev loss -4.6567 elbo -14.2036 ll -1.4346 kl_fb 12.7690 kl 12.7690 kl_weight 1.0000 sf 18.8603 reward -1.4346 ll_mean 0.0000 ll_std 1.0000 selected 0.2609 prior_p1 0.5283 avg_p1 0.4979 acc 0.3787\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 110 Iter 37600 loss=5.3196 elbo -4.1540 ll -1.4731 kl_fb 2.6809 kl 7.1300 kl_weight 0.3760 sf 0.1007 reward -0.0080 ll_mean -1.4651 ll_std 1.0000 selected 0.5155 prior_p1 0.8670 avg_p1 0.4983\n",
      "Shuffling training data\n",
      "Epoch 110 Iter 37700 loss=6.4481 elbo -7.1298 ll -1.4684 kl_fb 5.6614 kl 15.0170 kl_weight 0.3770 sf 0.0934 reward -0.0064 ll_mean -1.4620 ll_std 1.0000 selected 0.4824 prior_p1 0.0647 avg_p1 0.5002\n",
      "Epoch 110 Iter 37800 loss=5.5767 elbo -1.3282 ll -1.3200 kl_fb 0.0082 kl 0.0218 kl_weight 0.3780 sf -2.1695 reward 0.1440 ll_mean -1.4640 ll_std 1.0000 selected 0.5128 prior_p1 0.5084 avg_p1 0.4998\n",
      "\n",
      "# epoch 110 iter 37851: dev loss -1.5066 elbo -17.1166 ll -1.4148 kl_fb 15.7018 kl 15.7018 kl_weight 1.0000 sf 18.6231 reward -1.4148 ll_mean 0.0000 ll_std 1.0000 selected 0.3408 prior_p1 0.5480 avg_p1 0.4994 acc 0.3933\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances **by** **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved to tears **by** a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 111 Iter 37900 loss=4.2878 elbo -1.5268 ll -1.3756 kl_fb 0.1513 kl 0.3991 kl_weight 0.3790 sf -1.1496 reward 0.0889 ll_mean -1.4644 ll_std 1.0000 selected 0.4696 prior_p1 0.5991 avg_p1 0.4988\n",
      "Shuffling training data\n",
      "Epoch 111 Iter 38000 loss=6.3142 elbo -8.1967 ll -1.7016 kl_fb 6.4950 kl 17.0922 kl_weight 0.3800 sf 2.9222 reward -0.2378 ll_mean -1.4638 ll_std 1.0000 selected 0.4934 prior_p1 0.9620 avg_p1 0.5007\n",
      "Epoch 111 Iter 38100 loss=5.7018 elbo -7.9891 ll -1.4225 kl_fb 6.5666 kl 17.2353 kl_weight 0.3810 sf -0.5950 reward 0.0424 ll_mean -1.4649 ll_std 1.0000 selected 0.4772 prior_p1 0.9518 avg_p1 0.4983\n",
      "\n",
      "# epoch 111 iter 38192: dev loss -8.0960 elbo -10.6864 ll -1.4288 kl_fb 9.2576 kl 9.2576 kl_weight 1.0000 sf 18.7825 reward -1.4288 ll_mean 0.0000 ll_std 1.0000 selected 0.2963 prior_p1 0.5512 avg_p1 0.4981 acc 0.3842\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances **by** buy **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved to tears **by** a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 112 Iter 38200 loss=5.5498 elbo -9.6273 ll -1.4572 kl_fb 8.1700 kl 21.3875 kl_weight 0.3820 sf -0.0920 reward 0.0073 ll_mean -1.4645 ll_std 1.0000 selected 0.4646 prior_p1 0.0245 avg_p1 0.4979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 Iter 38300 loss=4.6008 elbo -1.4855 ll -1.3932 kl_fb 0.0923 kl 0.2409 kl_weight 0.3830 sf -1.0022 reward 0.0687 ll_mean -1.4619 ll_std 1.0000 selected 0.5177 prior_p1 0.5713 avg_p1 0.4982\n",
      "Shuffling training data\n",
      "Epoch 112 Iter 38400 loss=5.6154 elbo -7.1746 ll -1.4669 kl_fb 5.7077 kl 14.8638 kl_weight 0.3840 sf 0.0715 reward -0.0059 ll_mean -1.4610 ll_std 1.0000 selected 0.5196 prior_p1 0.9507 avg_p1 0.4965\n",
      "Epoch 112 Iter 38500 loss=6.0404 elbo -5.1848 ll -1.4659 kl_fb 3.7190 kl 9.6596 kl_weight 0.3850 sf 0.0745 reward -0.0053 ll_mean -1.4606 ll_std 1.0000 selected 0.4952 prior_p1 0.8899 avg_p1 0.4982\n",
      "\n",
      "# epoch 112 iter 38533: dev loss -7.6422 elbo -11.2872 ll -1.4405 kl_fb 9.8467 kl 9.8467 kl_weight 1.0000 sf 18.9294 reward -1.4405 ll_mean 0.0000 ll_std 1.0000 selected 0.2437 prior_p1 0.5303 avg_p1 0.4976 acc 0.3769\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've **got** **ice** **water** in your veins .\n",
      "\n",
      "Epoch 113 Iter 38600 loss=4.4026 elbo -3.7629 ll -1.4205 kl_fb 2.3424 kl 6.0684 kl_weight 0.3860 sf -0.5012 reward 0.0408 ll_mean -1.4613 ll_std 1.0000 selected 0.5096 prior_p1 0.8499 avg_p1 0.4969\n",
      "Shuffling training data\n",
      "Epoch 113 Iter 38700 loss=5.2613 elbo -1.5844 ll -1.3349 kl_fb 0.2495 kl 0.6446 kl_weight 0.3870 sf -1.7247 reward 0.1273 ll_mean -1.4622 ll_std 1.0000 selected 0.5033 prior_p1 0.6221 avg_p1 0.4973\n",
      "Epoch 113 Iter 38800 loss=5.9847 elbo -4.2829 ll -1.6548 kl_fb 2.6282 kl 6.7736 kl_weight 0.3880 sf 2.2340 reward -0.1931 ll_mean -1.4616 ll_std 1.0000 selected 0.4934 prior_p1 0.8700 avg_p1 0.4965\n",
      "\n",
      "# epoch 113 iter 38874: dev loss -9.8660 elbo -9.2114 ll -1.4547 kl_fb 7.7567 kl 7.7567 kl_weight 1.0000 sf 19.0774 reward -1.4547 ll_mean 0.0000 ll_std 1.0000 selected 0.2240 prior_p1 0.4730 avg_p1 0.4965 acc 0.3669\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 114 Iter 38900 loss=4.7277 elbo -1.8180 ll -1.3377 kl_fb 0.4802 kl 1.2345 kl_weight 0.3890 sf -1.5557 reward 0.1238 ll_mean -1.4615 ll_std 1.0000 selected 0.4741 prior_p1 0.6733 avg_p1 0.4959\n",
      "Shuffling training data\n",
      "Epoch 114 Iter 39000 loss=5.0664 elbo -1.6289 ll -1.3586 kl_fb 0.2703 kl 0.6930 kl_weight 0.3900 sf -1.4444 reward 0.1035 ll_mean -1.4621 ll_std 1.0000 selected 0.4629 prior_p1 0.6238 avg_p1 0.4963\n",
      "Epoch 114 Iter 39100 loss=5.7189 elbo -18.4547 ll -1.4925 kl_fb 16.9622 kl 43.3815 kl_weight 0.3910 sf 0.3922 reward -0.0298 ll_mean -1.4627 ll_std 1.0000 selected 0.4759 prior_p1 0.9973 avg_p1 0.4975\n",
      "Epoch 114 Iter 39200 loss=5.3260 elbo -12.0018 ll -1.4902 kl_fb 10.5117 kl 26.8155 kl_weight 0.3920 sf 0.3570 reward -0.0265 ll_mean -1.4637 ll_std 1.0000 selected 0.4954 prior_p1 0.0155 avg_p1 0.4951\n",
      "\n",
      "# epoch 114 iter 39215: dev loss -5.4764 elbo -13.6322 ll -1.4572 kl_fb 12.1750 kl 12.1750 kl_weight 1.0000 sf 19.1086 reward -1.4572 ll_mean 0.0000 ll_std 1.0000 selected 0.2161 prior_p1 0.5098 avg_p1 0.4964 acc 0.3651\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 115 Iter 39300 loss=4.9908 elbo -1.6637 ll -1.4480 kl_fb 0.2157 kl 0.5489 kl_weight 0.3930 sf -0.1850 reward 0.0159 ll_mean -1.4639 ll_std 1.0000 selected 0.5069 prior_p1 0.3736 avg_p1 0.4979\n",
      "Shuffling training data\n",
      "Epoch 115 Iter 39400 loss=5.2851 elbo -6.1161 ll -1.4413 kl_fb 4.6747 kl 11.8648 kl_weight 0.3940 sf -0.3422 reward 0.0237 ll_mean -1.4650 ll_std 1.0000 selected 0.5079 prior_p1 0.9101 avg_p1 0.4957\n",
      "Epoch 115 Iter 39500 loss=5.0635 elbo -6.2048 ll -1.4814 kl_fb 4.7233 kl 11.9578 kl_weight 0.3950 sf 0.1962 reward -0.0160 ll_mean -1.4655 ll_std 1.0000 selected 0.5339 prior_p1 0.0684 avg_p1 0.4964\n",
      "\n",
      "# epoch 115 iter 39556: dev loss -5.0651 elbo -14.1218 ll -1.4655 kl_fb 12.6564 kl 12.6564 kl_weight 1.0000 sf 19.1870 reward -1.4655 ll_mean 0.0000 ll_std 1.0000 selected 0.1951 prior_p1 0.5796 avg_p1 0.4957 acc 0.3588\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 116 Iter 39600 loss=7.4410 elbo -1.4290 ll -1.4222 kl_fb 0.0068 kl 0.0171 kl_weight 0.3960 sf -0.6258 reward 0.0435 ll_mean -1.4657 ll_std 1.0000 selected 0.4996 prior_p1 0.4861 avg_p1 0.4955\n",
      "Shuffling training data\n",
      "Epoch 116 Iter 39700 loss=6.2631 elbo -4.0743 ll -1.3983 kl_fb 2.6760 kl 6.7405 kl_weight 0.3970 sf -0.8040 reward 0.0662 ll_mean -1.4645 ll_std 1.0000 selected 0.4968 prior_p1 0.8637 avg_p1 0.4960\n",
      "Epoch 116 Iter 39800 loss=5.9211 elbo -6.8897 ll -1.4032 kl_fb 5.4865 kl 13.7851 kl_weight 0.3980 sf -0.8601 reward 0.0616 ll_mean -1.4649 ll_std 1.0000 selected 0.5040 prior_p1 0.0665 avg_p1 0.4944\n",
      "\n",
      "# epoch 116 iter 39897: dev loss -10.4782 elbo -8.6423 ll -1.4590 kl_fb 7.1834 kl 7.1834 kl_weight 1.0000 sf 19.1205 reward -1.4590 ll_mean 0.0000 ll_std 1.0000 selected 0.2073 prior_p1 0.4755 avg_p1 0.4961 acc 0.3606\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 117 Iter 39900 loss=5.4723 elbo -1.7095 ll -1.4675 kl_fb 0.2421 kl 0.6066 kl_weight 0.3990 sf 0.0212 reward -0.0016 ll_mean -1.4658 ll_std 1.0000 selected 0.4524 prior_p1 0.3716 avg_p1 0.4956\n",
      "Epoch 117 Iter 40000 loss=5.6925 elbo -2.1826 ll -1.6342 kl_fb 0.5484 kl 1.3709 kl_weight 0.4000 sf 1.9224 reward -0.1695 ll_mean -1.4647 ll_std 1.0000 selected 0.5030 prior_p1 0.3011 avg_p1 0.4968\n",
      "Shuffling training data\n",
      "Epoch 117 Iter 40100 loss=5.3721 elbo -1.5317 ll -1.3876 kl_fb 0.1441 kl 0.3592 kl_weight 0.4010 sf -0.8209 reward 0.0756 ll_mean -1.4633 ll_std 1.0000 selected 0.4820 prior_p1 0.6006 avg_p1 0.4971\n",
      "Epoch 117 Iter 40200 loss=4.4763 elbo -2.6041 ll -1.3643 kl_fb 1.2398 kl 3.0842 kl_weight 0.4020 sf -1.3885 reward 0.0996 ll_mean -1.4639 ll_std 1.0000 selected 0.4654 prior_p1 0.7532 avg_p1 0.4965\n",
      "\n",
      "# epoch 117 iter 40238: dev loss -5.4511 elbo -13.7306 ll -1.4646 kl_fb 12.2660 kl 12.2660 kl_weight 1.0000 sf 19.1817 reward -1.4646 ll_mean 0.0000 ll_std 1.0000 selected 0.1956 prior_p1 0.4214 avg_p1 0.4959 acc 0.3606\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Epoch 118 Iter 40300 loss=6.4213 elbo -8.0278 ll -1.3699 kl_fb 6.6578 kl 16.5207 kl_weight 0.4030 sf -1.1927 reward 0.0927 ll_mean -1.4626 ll_std 1.0000 selected 0.4900 prior_p1 0.9547 avg_p1 0.4967\n",
      "Shuffling training data\n",
      "Epoch 118 Iter 40400 loss=6.9067 elbo -2.0256 ll -1.3885 kl_fb 0.6371 kl 1.5771 kl_weight 0.4040 sf -1.2386 reward 0.0742 ll_mean -1.4626 ll_std 1.0000 selected 0.5182 prior_p1 0.3216 avg_p1 0.4953\n",
      "Epoch 118 Iter 40500 loss=6.1074 elbo -2.9955 ll -1.4223 kl_fb 1.5732 kl 3.8845 kl_weight 0.4050 sf -0.4836 reward 0.0389 ll_mean -1.4612 ll_std 1.0000 selected 0.4932 prior_p1 0.7931 avg_p1 0.4954\n",
      "\n",
      "# epoch 118 iter 40579: dev loss -10.2416 elbo -8.9548 ll -1.4653 kl_fb 7.4894 kl 7.4894 kl_weight 1.0000 sf 19.1963 reward -1.4653 ll_mean 0.0000 ll_std 1.0000 selected 0.1920 prior_p1 0.4593 avg_p1 0.4959 acc 0.3633\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes **unindicted** here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got **ice** **water** in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 Iter 40600 loss=6.0622 elbo -2.4868 ll -1.4568 kl_fb 1.0300 kl 2.5368 kl_weight 0.4060 sf -0.0433 reward 0.0039 ll_mean -1.4607 ll_std 1.0000 selected 0.5255 prior_p1 0.7567 avg_p1 0.4974\n",
      "Shuffling training data\n",
      "Epoch 119 Iter 40700 loss=5.4523 elbo -5.1743 ll -1.4255 kl_fb 3.7488 kl 9.2108 kl_weight 0.4070 sf -0.4704 reward 0.0362 ll_mean -1.4617 ll_std 1.0000 selected 0.5163 prior_p1 0.8928 avg_p1 0.4952\n",
      "Epoch 119 Iter 40800 loss=5.8021 elbo -1.4745 ll -1.4372 kl_fb 0.0374 kl 0.0916 kl_weight 0.4080 sf -0.2562 reward 0.0228 ll_mean -1.4600 ll_std 1.0000 selected 0.4987 prior_p1 0.4470 avg_p1 0.4959\n",
      "Epoch 119 Iter 40900 loss=5.9218 elbo -9.8316 ll -1.4168 kl_fb 8.4148 kl 20.5740 kl_weight 0.4090 sf -0.5980 reward 0.0444 ll_mean -1.4612 ll_std 1.0000 selected 0.4984 prior_p1 0.9677 avg_p1 0.4958\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:24",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-6d37a8a22bd2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mll_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mll_moving_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0mll_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mll_moving_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                     iter_i=iter_i)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3b60663e7c87>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, py, targets, q_z, z, mask, iter_i, kl_weight, min_kl, ll_mean, ll_std, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mp_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_p1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Compute the log density of the sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:24"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
